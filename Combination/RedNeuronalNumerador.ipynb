{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Interpolation/InterpolatedNumWeekCHKP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATES</th>\n",
       "      <th>U Revenue</th>\n",
       "      <th>D CR</th>\n",
       "      <th>U OE</th>\n",
       "      <th>D NOI</th>\n",
       "      <th>D CAPEX</th>\n",
       "      <th>D WK</th>\n",
       "      <th>U FCF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>30.805666</td>\n",
       "      <td>2.940805</td>\n",
       "      <td>12.909275</td>\n",
       "      <td>0.712114</td>\n",
       "      <td>0.504437</td>\n",
       "      <td>43.111030</td>\n",
       "      <td>47.761994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>30.587938</td>\n",
       "      <td>2.912218</td>\n",
       "      <td>12.878833</td>\n",
       "      <td>0.704023</td>\n",
       "      <td>0.507104</td>\n",
       "      <td>43.079053</td>\n",
       "      <td>48.678626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>30.370211</td>\n",
       "      <td>2.883631</td>\n",
       "      <td>12.848391</td>\n",
       "      <td>0.695931</td>\n",
       "      <td>0.509772</td>\n",
       "      <td>43.047075</td>\n",
       "      <td>49.595258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>30.152483</td>\n",
       "      <td>2.855045</td>\n",
       "      <td>12.817948</td>\n",
       "      <td>0.687839</td>\n",
       "      <td>0.512439</td>\n",
       "      <td>43.015097</td>\n",
       "      <td>50.511889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-29</td>\n",
       "      <td>29.934756</td>\n",
       "      <td>2.826458</td>\n",
       "      <td>12.787506</td>\n",
       "      <td>0.679747</td>\n",
       "      <td>0.515107</td>\n",
       "      <td>42.983119</td>\n",
       "      <td>51.428521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2020-06-07</td>\n",
       "      <td>21.504941</td>\n",
       "      <td>2.276720</td>\n",
       "      <td>7.507832</td>\n",
       "      <td>1.443173</td>\n",
       "      <td>0.800919</td>\n",
       "      <td>75.054562</td>\n",
       "      <td>120.747119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2020-06-14</td>\n",
       "      <td>21.376252</td>\n",
       "      <td>2.282313</td>\n",
       "      <td>7.485222</td>\n",
       "      <td>1.437200</td>\n",
       "      <td>0.794644</td>\n",
       "      <td>75.219587</td>\n",
       "      <td>120.860407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>21.247562</td>\n",
       "      <td>2.287906</td>\n",
       "      <td>7.462612</td>\n",
       "      <td>1.431226</td>\n",
       "      <td>0.788369</td>\n",
       "      <td>75.384612</td>\n",
       "      <td>120.973696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2020-06-28</td>\n",
       "      <td>21.118873</td>\n",
       "      <td>2.293498</td>\n",
       "      <td>7.440002</td>\n",
       "      <td>1.425253</td>\n",
       "      <td>0.782094</td>\n",
       "      <td>75.549637</td>\n",
       "      <td>121.086984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2020-07-05</td>\n",
       "      <td>20.990183</td>\n",
       "      <td>2.299091</td>\n",
       "      <td>7.417393</td>\n",
       "      <td>1.419280</td>\n",
       "      <td>0.775819</td>\n",
       "      <td>75.714662</td>\n",
       "      <td>121.200272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATES  U Revenue      D CR       U OE     D NOI   D CAPEX  \\\n",
       "0    2017-01-01  30.805666  2.940805  12.909275  0.712114  0.504437   \n",
       "1    2017-01-08  30.587938  2.912218  12.878833  0.704023  0.507104   \n",
       "2    2017-01-15  30.370211  2.883631  12.848391  0.695931  0.509772   \n",
       "3    2017-01-22  30.152483  2.855045  12.817948  0.687839  0.512439   \n",
       "4    2017-01-29  29.934756  2.826458  12.787506  0.679747  0.515107   \n",
       "..          ...        ...       ...        ...       ...       ...   \n",
       "179  2020-06-07  21.504941  2.276720   7.507832  1.443173  0.800919   \n",
       "180  2020-06-14  21.376252  2.282313   7.485222  1.437200  0.794644   \n",
       "181  2020-06-21  21.247562  2.287906   7.462612  1.431226  0.788369   \n",
       "182  2020-06-28  21.118873  2.293498   7.440002  1.425253  0.782094   \n",
       "183  2020-07-05  20.990183  2.299091   7.417393  1.419280  0.775819   \n",
       "\n",
       "          D WK       U FCF  \n",
       "0    43.111030   47.761994  \n",
       "1    43.079053   48.678626  \n",
       "2    43.047075   49.595258  \n",
       "3    43.015097   50.511889  \n",
       "4    42.983119   51.428521  \n",
       "..         ...         ...  \n",
       "179  75.054562  120.747119  \n",
       "180  75.219587  120.860407  \n",
       "181  75.384612  120.973696  \n",
       "182  75.549637  121.086984  \n",
       "183  75.714662  121.200272  \n",
       "\n",
       "[184 rows x 8 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.37982763717106"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"U FCF\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2017-01-01', 30.8056659998843, 2.94080485487297, ...,\n",
       "        0.504436566874371, 43.11103044981, 47.761993854947214],\n",
       "       ['2017-01-08', 30.587938438328816, 2.9122181658805983, ...,\n",
       "        0.507104209917995, 43.07905267846236, 48.678625714090614],\n",
       "       ['2017-01-15', 30.370210876773328, 2.883631476888227, ...,\n",
       "        0.509771852961619, 43.04707490711473, 49.59525757323404],\n",
       "       ...,\n",
       "       ['2020-06-21', 21.247562128136686, 2.2879057321217253, ...,\n",
       "        0.7883692603865214, 75.38461207654238, 120.97369552791645],\n",
       "       ['2020-06-28', 21.118872545795494, 2.293498409114968, ...,\n",
       "        0.7820942236278302, 75.54963715687524, 121.08698375524523],\n",
       "       ['2020-07-05', 20.990182963454302, 2.29909108610821, ...,\n",
       "        0.7758191868691391, 75.71466223720809, 121.20027198257401]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.761993854947214 48.678625714090614 49.59525757323404 50.51188943237745\n",
      " 51.428521291520866 52.34515315066428 53.2617850098077 54.17841686895111\n",
      " 55.09504872809453 56.01168058723794 56.92831244638136 57.84494430552477\n",
      " 58.76157616466818 59.6782080238116 61.275368008638594 62.872527993465575\n",
      " 64.46968797829257 66.06684796311957 67.66400794794656 69.26116793277356\n",
      " 70.85832791760055 72.45548790242755 74.05264788725454 75.64980787208152\n",
      " 77.24696785690851 78.84412784173551 80.4412878265625 80.63916658972062\n",
      " 80.83704535287876 81.03492411603689 81.232802879195 81.43068164235315\n",
      " 81.62856040551128 81.82643916866942 82.02431793182754 82.22219669498568\n",
      " 82.42007545814381 82.61795422130194 82.81583298446006 83.0137117476182\n",
      " 82.91304006251654 82.81236837741487 82.7116966923132 82.61102500721154\n",
      " 82.51035332210989 82.40968163700823 82.30900995190656 82.2083382668049\n",
      " 82.10766658170323 82.00699489660158 81.90632321149991 81.80565152639825\n",
      " 81.70497984129659 81.70909763618786 81.71321543107916 81.71733322597042\n",
      " 81.7214510208617 81.72556881575298 81.72968661064426 81.73380440553555\n",
      " 81.73792220042682 81.7420399953181 81.74615779020938 81.75027558510067\n",
      " 81.75439337999194 81.75851117488321 82.40493439619748 83.05135761751177\n",
      " 83.69778083882602 84.34420406014031 84.99062728145459 85.63705050276887\n",
      " 86.28347372408314 86.92989694539742 87.57632016671171 88.22274338802599\n",
      " 88.86916660934023 89.5155898306545 90.1620130519688 91.64324592932587\n",
      " 93.124478806683 94.60571168404007 96.08694456139715 97.56817743875428\n",
      " 99.04941031611135 100.53064319346844 102.01187607082555\n",
      " 103.49310894818264 104.97434182553974 106.45557470289684\n",
      " 107.93680758025393 109.41804045761101 110.70145398767887\n",
      " 111.98486751774672 113.26828104781458 114.55169457788244\n",
      " 115.83510810795029 117.11852163801815 118.401935168086 119.68534869815386\n",
      " 120.96876222822172 122.25217575828957 123.53558928835743\n",
      " 124.81900281842528 126.10241634849314 127.385829878561 127.510220128272\n",
      " 127.634610377983 127.759000627694 127.88339087740499 128.007781127116\n",
      " 128.132171376827 128.256561626538 128.38095187624901 128.50534212596\n",
      " 128.629732375671 128.754122625382 128.878512875093 128.6331154068363\n",
      " 128.38771793857958 128.14232047032294 127.89692300206623\n",
      " 127.65152553380956 127.40612806555285 127.16073059729617\n",
      " 126.91533312903948 126.66993566078276 126.42453819252607\n",
      " 126.1791407242694 125.9337432560127 125.688345787756 125.60228880721813\n",
      " 125.5162318266803 125.43017484614245 125.34411786560456\n",
      " 125.25806088506673 125.17200390452886 125.08594692399099\n",
      " 124.99988994345314 124.91383296291531 124.82777598237743\n",
      " 124.74171900183956 124.65566202130172 124.56960504076386 124.483548060226\n",
      " 124.34794989509993 124.21235172997385 124.07675356484778\n",
      " 123.9411553997217 123.80555723459558 123.66995906946954\n",
      " 123.53436090434346 123.39876273921742 123.2631645740913\n",
      " 123.12756640896522 122.99196824383915 122.85637007871307 122.720771913587\n",
      " 122.49052215310337 122.26027239261977 122.03002263213615\n",
      " 121.79977287165255 121.56952311116892 121.33927335068529\n",
      " 121.10902359020169 120.87877382971807 120.64852406923443\n",
      " 120.41827430875084 120.18802454826721 119.95777478778358\n",
      " 119.72752502729999 119.84081325462877 119.95410148195755\n",
      " 120.06738970928629 120.18067793661508 120.29396616394385\n",
      " 120.40725439127262 120.52054261860138 120.63383084593016\n",
      " 120.74711907325892 120.86040730058771 120.97369552791645\n",
      " 121.08698375524523 121.20027198257401]\n"
     ]
    }
   ],
   "source": [
    "X = dataset[:,1:7]\n",
    "Y = dataset[:,7]\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.87999902, 0.67808388, 0.05798712, 0.        ,\n",
       "        0.01258992],\n",
       "       [0.982285  , 0.85386014, 0.67442657, 0.05352657, 0.00493242,\n",
       "        0.01162147],\n",
       "       [0.96457   , 0.82772127, 0.67076925, 0.04906603, 0.00986485,\n",
       "        0.01065301],\n",
       "       ...,\n",
       "       [0.22232265, 0.28300625, 0.02372385, 0.45439402, 0.52498634,\n",
       "        0.99000434],\n",
       "       [0.21185207, 0.28812004, 0.02100752, 0.45110129, 0.51338391,\n",
       "        0.99500217],\n",
       "       [0.20138148, 0.29323383, 0.01829119, 0.44780856, 0.50178148,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.87999902, 0.67808388, 0.05798712, 0.        ,\n",
       "       0.01258992])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47.761993854947214,\n",
       " 48.678625714090614,\n",
       " 49.59525757323404,\n",
       " 50.51188943237745,\n",
       " 51.428521291520866,\n",
       " 52.34515315066428,\n",
       " 53.2617850098077,\n",
       " 54.17841686895111,\n",
       " 55.09504872809453,\n",
       " 56.01168058723794,\n",
       " 56.92831244638136,\n",
       " 57.84494430552477,\n",
       " 58.76157616466818,\n",
       " 59.6782080238116,\n",
       " 61.275368008638594,\n",
       " 62.872527993465575,\n",
       " 64.46968797829257,\n",
       " 66.06684796311957,\n",
       " 67.66400794794656,\n",
       " 69.26116793277356,\n",
       " 70.85832791760055,\n",
       " 72.45548790242755,\n",
       " 74.05264788725454,\n",
       " 75.64980787208152,\n",
       " 77.24696785690851,\n",
       " 78.84412784173551,\n",
       " 80.4412878265625,\n",
       " 80.63916658972062,\n",
       " 80.83704535287876,\n",
       " 81.03492411603689,\n",
       " 81.232802879195,\n",
       " 81.43068164235315,\n",
       " 81.62856040551128,\n",
       " 81.82643916866942,\n",
       " 82.02431793182754,\n",
       " 82.22219669498568,\n",
       " 82.42007545814381,\n",
       " 82.61795422130194,\n",
       " 82.81583298446006,\n",
       " 83.0137117476182,\n",
       " 82.91304006251654,\n",
       " 82.81236837741487,\n",
       " 82.7116966923132,\n",
       " 82.61102500721154,\n",
       " 82.51035332210989,\n",
       " 82.40968163700823,\n",
       " 82.30900995190656,\n",
       " 82.2083382668049,\n",
       " 82.10766658170323,\n",
       " 82.00699489660158,\n",
       " 81.90632321149991,\n",
       " 81.80565152639825,\n",
       " 81.70497984129659,\n",
       " 81.70909763618786,\n",
       " 81.71321543107916,\n",
       " 81.71733322597042,\n",
       " 81.7214510208617,\n",
       " 81.72556881575298,\n",
       " 81.72968661064426,\n",
       " 81.73380440553555,\n",
       " 81.73792220042682,\n",
       " 81.7420399953181,\n",
       " 81.74615779020938,\n",
       " 81.75027558510067,\n",
       " 81.75439337999194,\n",
       " 81.75851117488321,\n",
       " 82.40493439619748,\n",
       " 83.05135761751177,\n",
       " 83.69778083882602,\n",
       " 84.34420406014031,\n",
       " 84.99062728145459,\n",
       " 85.63705050276887,\n",
       " 86.28347372408314,\n",
       " 86.92989694539742,\n",
       " 87.57632016671171,\n",
       " 88.22274338802599,\n",
       " 88.86916660934023,\n",
       " 89.5155898306545,\n",
       " 90.1620130519688,\n",
       " 91.64324592932587,\n",
       " 93.124478806683,\n",
       " 94.60571168404007,\n",
       " 96.08694456139715,\n",
       " 97.56817743875428,\n",
       " 99.04941031611135,\n",
       " 100.53064319346844,\n",
       " 102.01187607082555,\n",
       " 103.49310894818264,\n",
       " 104.97434182553974,\n",
       " 106.45557470289684,\n",
       " 107.93680758025393,\n",
       " 109.41804045761101,\n",
       " 110.70145398767887,\n",
       " 111.98486751774672,\n",
       " 113.26828104781458,\n",
       " 114.55169457788244,\n",
       " 115.83510810795029,\n",
       " 117.11852163801815,\n",
       " 118.401935168086,\n",
       " 119.68534869815386,\n",
       " 120.96876222822172,\n",
       " 122.25217575828957,\n",
       " 123.53558928835743,\n",
       " 124.81900281842528,\n",
       " 126.10241634849314,\n",
       " 127.385829878561,\n",
       " 127.510220128272,\n",
       " 127.634610377983,\n",
       " 127.759000627694,\n",
       " 127.88339087740499,\n",
       " 128.007781127116,\n",
       " 128.132171376827,\n",
       " 128.256561626538,\n",
       " 128.38095187624901,\n",
       " 128.50534212596,\n",
       " 128.629732375671,\n",
       " 128.754122625382,\n",
       " 128.878512875093,\n",
       " 128.6331154068363,\n",
       " 128.38771793857958,\n",
       " 128.14232047032294,\n",
       " 127.89692300206623,\n",
       " 127.65152553380956,\n",
       " 127.40612806555285,\n",
       " 127.16073059729617,\n",
       " 126.91533312903948,\n",
       " 126.66993566078276,\n",
       " 126.42453819252607,\n",
       " 126.1791407242694,\n",
       " 125.9337432560127,\n",
       " 125.688345787756,\n",
       " 125.60228880721813,\n",
       " 125.5162318266803,\n",
       " 125.43017484614245,\n",
       " 125.34411786560456,\n",
       " 125.25806088506673,\n",
       " 125.17200390452886,\n",
       " 125.08594692399099,\n",
       " 124.99988994345314,\n",
       " 124.91383296291531,\n",
       " 124.82777598237743,\n",
       " 124.74171900183956,\n",
       " 124.65566202130172,\n",
       " 124.56960504076386,\n",
       " 124.483548060226,\n",
       " 124.34794989509993,\n",
       " 124.21235172997385,\n",
       " 124.07675356484778,\n",
       " 123.9411553997217,\n",
       " 123.80555723459558,\n",
       " 123.66995906946954,\n",
       " 123.53436090434346,\n",
       " 123.39876273921742,\n",
       " 123.2631645740913,\n",
       " 123.12756640896522,\n",
       " 122.99196824383915,\n",
       " 122.85637007871307,\n",
       " 122.720771913587,\n",
       " 122.49052215310337,\n",
       " 122.26027239261977,\n",
       " 122.03002263213615,\n",
       " 121.79977287165255,\n",
       " 121.56952311116892,\n",
       " 121.33927335068529,\n",
       " 121.10902359020169,\n",
       " 120.87877382971807,\n",
       " 120.64852406923443,\n",
       " 120.41827430875084,\n",
       " 120.18802454826721,\n",
       " 119.95777478778358,\n",
       " 119.72752502729999,\n",
       " 119.84081325462877,\n",
       " 119.95410148195755,\n",
       " 120.06738970928629,\n",
       " 120.18067793661508,\n",
       " 120.29396616394385,\n",
       " 120.40725439127262,\n",
       " 120.52054261860138,\n",
       " 120.63383084593016,\n",
       " 120.74711907325892,\n",
       " 120.86040730058771,\n",
       " 120.97369552791645,\n",
       " 121.08698375524523,\n",
       " 121.20027198257401]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147, 6) (18, 6) (19, 6) (147,) (18,) (19,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.2)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(6, activation='elu', input_shape=(6,)),\n",
    "    Dense(256, activation='elu'),\n",
    "    Dense(256, activation='elu'),\n",
    "    Dense(256, activation='elu'),\n",
    "    Dense(256, activation='elu'),\n",
    "    Dense(256, activation='elu'),\n",
    "    Dense(256, activation='elu'),\n",
    "    Dense(1, activation='elu'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 147 samples, validate on 18 samples\n",
      "Epoch 1/400\n",
      "147/147 [==============================] - 1s 9ms/step - loss: 28.1225 - val_loss: 13.2968\n",
      "Epoch 2/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 15.3480 - val_loss: 8.7078\n",
      "Epoch 3/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 15.0804 - val_loss: 9.9273\n",
      "Epoch 4/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 12.0562 - val_loss: 13.3875\n",
      "Epoch 5/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 13.1928 - val_loss: 12.5706\n",
      "Epoch 6/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 11.5248 - val_loss: 15.8892\n",
      "Epoch 7/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 11.2008 - val_loss: 9.3724\n",
      "Epoch 8/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 10.7093 - val_loss: 13.8988\n",
      "Epoch 9/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 11.1561 - val_loss: 7.0330\n",
      "Epoch 10/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 10.0704 - val_loss: 6.5908\n",
      "Epoch 11/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 8.6641 - val_loss: 15.5925\n",
      "Epoch 12/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 9.1503 - val_loss: 16.2361\n",
      "Epoch 13/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 8.5277 - val_loss: 20.0477\n",
      "Epoch 14/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 8.3712 - val_loss: 4.2289TA: 0s - loss: 8.255 - ETA: 0s - loss: 8.3\n",
      "Epoch 15/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 7.9802 - val_loss: 6.4567\n",
      "Epoch 16/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 7.8598 - val_loss: 12.3934\n",
      "Epoch 17/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 7.2649 - val_loss: 11.6404\n",
      "Epoch 18/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 6.4673 - val_loss: 5.7824\n",
      "Epoch 19/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 5.9048 - val_loss: 3.3646\n",
      "Epoch 20/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 5.7642 - val_loss: 10.1705\n",
      "Epoch 21/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 5.6269 - val_loss: 10.2357\n",
      "Epoch 22/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 5.6522 - val_loss: 11.0224\n",
      "Epoch 23/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 5.2296 - val_loss: 5.0963\n",
      "Epoch 24/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 5.6899 - val_loss: 2.6861\n",
      "Epoch 25/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 5.0369 - val_loss: 2.6664\n",
      "Epoch 26/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 4.5664 - val_loss: 14.3592\n",
      "Epoch 27/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 5.2606 - val_loss: 4.6122\n",
      "Epoch 28/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 4.8364 - val_loss: 3.0221\n",
      "Epoch 29/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 4.5950 - val_loss: 12.0726\n",
      "Epoch 30/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 5.2780 - val_loss: 4.5418\n",
      "Epoch 31/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 4.6688 - val_loss: 4.4233\n",
      "Epoch 32/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 4.2857 - val_loss: 2.2855\n",
      "Epoch 33/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.9329 - val_loss: 2.8164\n",
      "Epoch 34/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 4.4380 - val_loss: 5.5321\n",
      "Epoch 35/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 4.1856 - val_loss: 3.8258\n",
      "Epoch 36/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 5.2973 - val_loss: 9.3557\n",
      "Epoch 37/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 6.0070 - val_loss: 3.9673\n",
      "Epoch 38/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 4.0199 - val_loss: 13.5420\n",
      "Epoch 39/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 4.3226 - val_loss: 7.8194\n",
      "Epoch 40/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 7.3415 - val_loss: 6.8912\n",
      "Epoch 41/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 4.5120 - val_loss: 3.6878\n",
      "Epoch 42/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 4.0714 - val_loss: 4.7528\n",
      "Epoch 43/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 4.0834 - val_loss: 3.1613\n",
      "Epoch 44/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 4.0915 - val_loss: 4.8225\n",
      "Epoch 45/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 3.2663 - val_loss: 4.1234\n",
      "Epoch 46/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 3.8603 - val_loss: 5.4053\n",
      "Epoch 47/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.6839 - val_loss: 3.2248\n",
      "Epoch 48/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 3.7880 - val_loss: 2.0329\n",
      "Epoch 49/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.4464 - val_loss: 4.5029\n",
      "Epoch 50/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.7766 - val_loss: 1.3899\n",
      "Epoch 51/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 3.3436 - val_loss: 2.0535\n",
      "Epoch 52/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.5134 - val_loss: 3.0957\n",
      "Epoch 53/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 3.3903 - val_loss: 5.1296\n",
      "Epoch 54/400\n",
      "147/147 [==============================] - ETA: 0s - loss: 3.758 - 1s 5ms/step - loss: 3.7942 - val_loss: 4.5971\n",
      "Epoch 55/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.1429 - val_loss: 3.9471\n",
      "Epoch 56/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.3455 - val_loss: 4.2790\n",
      "Epoch 57/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.3156 - val_loss: 6.0128\n",
      "Epoch 58/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.4597 - val_loss: 3.1146\n",
      "Epoch 59/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 3.3850 - val_loss: 5.1428\n",
      "Epoch 60/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 3.2946 - val_loss: 3.9701\n",
      "Epoch 61/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 3.2106 - val_loss: 2.3839\n",
      "Epoch 62/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 3.1978 - val_loss: 1.9409\n",
      "Epoch 63/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.8782 - val_loss: 7.5495\n",
      "Epoch 64/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 3.2027 - val_loss: 3.1857\n",
      "Epoch 65/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 3.2593 - val_loss: 4.1630\n",
      "Epoch 66/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.3583 - val_loss: 2.4422\n",
      "Epoch 67/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.9996 - val_loss: 3.2316\n",
      "Epoch 68/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.9828 - val_loss: 2.1205\n",
      "Epoch 69/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.4360 - val_loss: 2.6760\n",
      "Epoch 70/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 3.8505 - val_loss: 10.1147\n",
      "Epoch 71/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 4.7879 - val_loss: 2.6601\n",
      "Epoch 72/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.0064 - val_loss: 3.8546\n",
      "Epoch 73/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.8794 - val_loss: 6.7463\n",
      "Epoch 74/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.8495 - val_loss: 3.4799\n",
      "Epoch 75/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.4341 - val_loss: 5.2905\n",
      "Epoch 76/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.9346 - val_loss: 5.4294\n",
      "Epoch 77/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.9807 - val_loss: 3.7286\n",
      "Epoch 78/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.6920 - val_loss: 2.9232\n",
      "Epoch 79/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.9073 - val_loss: 3.5214\n",
      "Epoch 80/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147/147 [==============================] - 1s 6ms/step - loss: 2.9270 - val_loss: 3.3676\n",
      "Epoch 81/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.8504 - val_loss: 3.3506\n",
      "Epoch 82/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 2.6884 - val_loss: 2.2509\n",
      "Epoch 83/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.8438 - val_loss: 0.8990\n",
      "Epoch 84/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.7373 - val_loss: 4.6918\n",
      "Epoch 85/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.9641 - val_loss: 6.3988\n",
      "Epoch 86/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.7358 - val_loss: 3.7603\n",
      "Epoch 87/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.9116 - val_loss: 2.2042\n",
      "Epoch 88/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.6519 - val_loss: 2.2405\n",
      "Epoch 89/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.6486 - val_loss: 2.0709\n",
      "Epoch 90/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.7798 - val_loss: 3.8133\n",
      "Epoch 91/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.6263 - val_loss: 2.3220\n",
      "Epoch 92/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.7029 - val_loss: 1.3530\n",
      "Epoch 93/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.7044 - val_loss: 1.8745\n",
      "Epoch 94/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.4916 - val_loss: 2.9820\n",
      "Epoch 95/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.4376 - val_loss: 6.1655\n",
      "Epoch 96/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.9528 - val_loss: 1.5072\n",
      "Epoch 97/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.5670 - val_loss: 2.3232\n",
      "Epoch 98/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.5392 - val_loss: 5.2535\n",
      "Epoch 99/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.6734 - val_loss: 2.6070\n",
      "Epoch 100/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.5179 - val_loss: 2.4067\n",
      "Epoch 101/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.7249 - val_loss: 2.5165\n",
      "Epoch 102/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.6404 - val_loss: 1.6732\n",
      "Epoch 103/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.5285 - val_loss: 3.8748 - ETA: 0s - loss: 2.5\n",
      "Epoch 104/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.4193 - val_loss: 2.0614\n",
      "Epoch 105/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.5062 - val_loss: 2.9601\n",
      "Epoch 106/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.7066 - val_loss: 2.4529\n",
      "Epoch 107/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.1456 - val_loss: 2.8520\n",
      "Epoch 108/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.4987 - val_loss: 4.1257\n",
      "Epoch 109/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.5582 - val_loss: 4.6519\n",
      "Epoch 110/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.0782 - val_loss: 1.9412\n",
      "Epoch 111/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.4151 - val_loss: 5.1641\n",
      "Epoch 112/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.5922 - val_loss: 2.3474\n",
      "Epoch 113/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.4990 - val_loss: 1.9181\n",
      "Epoch 114/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.2577 - val_loss: 4.4044\n",
      "Epoch 115/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.6058 - val_loss: 1.1702\n",
      "Epoch 116/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.1974 - val_loss: 1.2359\n",
      "Epoch 117/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.4178 - val_loss: 1.4362\n",
      "Epoch 118/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.3662 - val_loss: 2.3939\n",
      "Epoch 119/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.2901 - val_loss: 3.5394\n",
      "Epoch 120/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.5165 - val_loss: 3.1950\n",
      "Epoch 121/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.4747 - val_loss: 0.9895ETA: 0s - loss: 3.614\n",
      "Epoch 122/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.9912 - val_loss: 3.1392\n",
      "Epoch 123/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 2.1572 - val_loss: 3.6140\n",
      "Epoch 124/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.1539 - val_loss: 2.4990\n",
      "Epoch 125/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.3021 - val_loss: 4.1700\n",
      "Epoch 126/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.3058 - val_loss: 2.4271\n",
      "Epoch 127/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.1452 - val_loss: 4.4792\n",
      "Epoch 128/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.4193 - val_loss: 1.2425\n",
      "Epoch 129/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.3488 - val_loss: 2.1260\n",
      "Epoch 130/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.1318 - val_loss: 2.3437\n",
      "Epoch 131/400\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 2.3290 - val_loss: 1.7413\n",
      "Epoch 132/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.1651 - val_loss: 3.3407\n",
      "Epoch 133/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.2422 - val_loss: 2.4023\n",
      "Epoch 134/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.1975 - val_loss: 4.4771\n",
      "Epoch 135/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.2188 - val_loss: 2.9337\n",
      "Epoch 136/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.2018 - val_loss: 1.6264\n",
      "Epoch 137/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.1869 - val_loss: 3.0742\n",
      "Epoch 138/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.2291 - val_loss: 1.7789\n",
      "Epoch 139/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.2170 - val_loss: 1.7889\n",
      "Epoch 140/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.1504 - val_loss: 1.8930\n",
      "Epoch 141/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.1069 - val_loss: 3.6633\n",
      "Epoch 142/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.0416 - val_loss: 3.4233\n",
      "Epoch 143/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.1448 - val_loss: 4.1456\n",
      "Epoch 144/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.9466 - val_loss: 2.0657\n",
      "Epoch 145/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.1112 - val_loss: 2.1508\n",
      "Epoch 146/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.2671 - val_loss: 1.9283\n",
      "Epoch 147/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.1057 - val_loss: 3.5225\n",
      "Epoch 148/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.0896 - val_loss: 2.0296\n",
      "Epoch 149/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.0864 - val_loss: 3.8937\n",
      "Epoch 150/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.0299 - val_loss: 0.9717 ETA: 0s - loss: 2.1 - ETA: 0s - loss: 1.9\n",
      "Epoch 151/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.1562 - val_loss: 2.0716\n",
      "Epoch 152/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.2319 - val_loss: 2.0608\n",
      "Epoch 153/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.1549 - val_loss: 0.9115\n",
      "Epoch 154/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.9695 - val_loss: 3.2998\n",
      "Epoch 155/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.2571 - val_loss: 1.8665\n",
      "Epoch 156/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.5192 - val_loss: 1.5562\n",
      "Epoch 157/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 2.0094 - val_loss: 4.3504\n",
      "Epoch 158/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.1441 - val_loss: 1.2571\n",
      "Epoch 159/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147/147 [==============================] - 1s 5ms/step - loss: 1.9892 - val_loss: 1.2789\n",
      "Epoch 160/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.0895 - val_loss: 3.2674\n",
      "Epoch 161/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.4737 - val_loss: 1.9376\n",
      "Epoch 162/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.0487 - val_loss: 1.9348\n",
      "Epoch 163/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.8749 - val_loss: 1.9604\n",
      "Epoch 164/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.0273 - val_loss: 2.1165\n",
      "Epoch 165/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.9122 - val_loss: 1.9185\n",
      "Epoch 166/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.1691 - val_loss: 1.9052\n",
      "Epoch 167/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.9386 - val_loss: 2.2563\n",
      "Epoch 168/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.1524 - val_loss: 3.1923\n",
      "Epoch 169/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.9265 - val_loss: 2.2446\n",
      "Epoch 170/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.8857 - val_loss: 1.6944\n",
      "Epoch 171/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.8656 - val_loss: 2.8621\n",
      "Epoch 172/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.2287 - val_loss: 1.5013\n",
      "Epoch 173/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.7637 - val_loss: 1.1275\n",
      "Epoch 174/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.8705 - val_loss: 2.1569\n",
      "Epoch 175/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.9581 - val_loss: 0.9680\n",
      "Epoch 176/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.9666 - val_loss: 1.5099\n",
      "Epoch 177/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.8190 - val_loss: 1.2346\n",
      "Epoch 178/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.8856 - val_loss: 2.2473 - ETA: 0s - loss: 1.75 - ETA: 0s - loss: 1.\n",
      "Epoch 179/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.9107 - val_loss: 4.9152\n",
      "Epoch 180/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.9151 - val_loss: 1.2828\n",
      "Epoch 181/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.9372 - val_loss: 1.4340\n",
      "Epoch 182/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.9373 - val_loss: 2.5517\n",
      "Epoch 183/400\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.9657- ETA: 0s - loss: 2 - 1s 5ms/step - loss: 2.0276 - val_loss: 1.9562\n",
      "Epoch 184/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.0278 - val_loss: 1.2489 ETA: 0s - loss: 1\n",
      "Epoch 185/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.8944 - val_loss: 2.4260\n",
      "Epoch 186/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.9162 - val_loss: 2.2043\n",
      "Epoch 187/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.9762 - val_loss: 2.2408\n",
      "Epoch 188/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.0644 - val_loss: 0.7263\n",
      "Epoch 189/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.8137 - val_loss: 4.0835\n",
      "Epoch 190/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.0043 - val_loss: 1.2810\n",
      "Epoch 191/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.9985 - val_loss: 1.1250\n",
      "Epoch 192/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.8245 - val_loss: 1.3960\n",
      "Epoch 193/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.8997 - val_loss: 2.2961\n",
      "Epoch 194/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.8765 - val_loss: 3.7108\n",
      "Epoch 195/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.1562 - val_loss: 6.6028\n",
      "Epoch 196/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.5233 - val_loss: 2.2024\n",
      "Epoch 197/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.0836 - val_loss: 0.7816\n",
      "Epoch 198/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6729 - val_loss: 3.0789\n",
      "Epoch 199/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.8044 - val_loss: 3.0616\n",
      "Epoch 200/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.3760 - val_loss: 4.6139\n",
      "Epoch 201/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 4.0230 - val_loss: 6.9199\n",
      "Epoch 202/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.0482 - val_loss: 4.6572\n",
      "Epoch 203/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.5242 - val_loss: 4.5595\n",
      "Epoch 204/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.1567 - val_loss: 3.5800\n",
      "Epoch 205/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.3926 - val_loss: 1.6977\n",
      "Epoch 206/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 3.2553 - val_loss: 4.7758\n",
      "Epoch 207/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 3.6793 - val_loss: 1.3564\n",
      "Epoch 208/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.6563 - val_loss: 1.2674\n",
      "Epoch 209/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6975 - val_loss: 1.0991\n",
      "Epoch 210/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.7685 - val_loss: 2.0190\n",
      "Epoch 211/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.8763 - val_loss: 1.2259\n",
      "Epoch 212/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.7958 - val_loss: 1.6893\n",
      "Epoch 213/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.8047 - val_loss: 1.4398\n",
      "Epoch 214/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.8759 - val_loss: 1.4449\n",
      "Epoch 215/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.7606 - val_loss: 1.4472\n",
      "Epoch 216/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.7276 - val_loss: 1.7186\n",
      "Epoch 217/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.8399 - val_loss: 2.7874\n",
      "Epoch 218/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.8939 - val_loss: 1.3573\n",
      "Epoch 219/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6871 - val_loss: 4.5598\n",
      "Epoch 220/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.0674 - val_loss: 2.6040\n",
      "Epoch 221/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.8297 - val_loss: 1.6496\n",
      "Epoch 222/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.7667 - val_loss: 1.6136\n",
      "Epoch 223/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.8178 - val_loss: 1.8068\n",
      "Epoch 224/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.5649 - val_loss: 3.3866\n",
      "Epoch 225/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.7683 - val_loss: 1.7690\n",
      "Epoch 226/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.0141 - val_loss: 2.2366\n",
      "Epoch 227/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.7608 - val_loss: 1.5429\n",
      "Epoch 228/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.7308 - val_loss: 1.2937\n",
      "Epoch 229/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.7104 - val_loss: 1.0501\n",
      "Epoch 230/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.8493 - val_loss: 1.4333\n",
      "Epoch 231/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.7981 - val_loss: 2.6090\n",
      "Epoch 232/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.7072 - val_loss: 1.4542\n",
      "Epoch 233/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.7264 - val_loss: 1.4942\n",
      "Epoch 234/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.7142 - val_loss: 1.9700\n",
      "Epoch 235/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6867 - val_loss: 1.6399\n",
      "Epoch 236/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.8303 - val_loss: 1.8114\n",
      "Epoch 237/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147/147 [==============================] - 1s 5ms/step - loss: 1.7972 - val_loss: 0.9961\n",
      "Epoch 238/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6909 - val_loss: 2.5141\n",
      "Epoch 239/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.7573 - val_loss: 1.1949\n",
      "Epoch 240/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.7039 - val_loss: 1.2124\n",
      "Epoch 241/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6847 - val_loss: 2.7983\n",
      "Epoch 242/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.1186 - val_loss: 1.5324\n",
      "Epoch 243/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6765 - val_loss: 1.5216\n",
      "Epoch 244/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.6743 - val_loss: 1.9207\n",
      "Epoch 245/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.7668 - val_loss: 1.3871\n",
      "Epoch 246/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.8779 - val_loss: 1.9114\n",
      "Epoch 247/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.6862 - val_loss: 3.6796\n",
      "Epoch 248/400\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 1.7472 - val_loss: 1.3039\n",
      "Epoch 249/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.6397 - val_loss: 0.8900\n",
      "Epoch 250/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.6296 - val_loss: 1.5171\n",
      "Epoch 251/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.6843 - val_loss: 3.7465\n",
      "Epoch 252/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.7409 - val_loss: 1.6753\n",
      "Epoch 253/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.7839 - val_loss: 0.8264\n",
      "Epoch 254/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6880 - val_loss: 1.2477\n",
      "Epoch 255/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.6859 - val_loss: 1.7881\n",
      "Epoch 256/400\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 1.7806 - val_loss: 1.9575\n",
      "Epoch 257/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.6766 - val_loss: 3.6010\n",
      "Epoch 258/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.7875 - val_loss: 1.8476\n",
      "Epoch 259/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.7364 - val_loss: 1.5252\n",
      "Epoch 260/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 4.5242 - val_loss: 1.1961\n",
      "Epoch 261/400\n",
      " 24/147 [===>..........................] - ETA: 1s - loss: 1.4778"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alejandra\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks\\callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.100519). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147/147 [==============================] - 1s 8ms/step - loss: 1.6857 - val_loss: 2.5688\n",
      "Epoch 262/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.6709 - val_loss: 1.3968\n",
      "Epoch 263/400\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 1.6887 - val_loss: 2.5112\n",
      "Epoch 264/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6819 - val_loss: 1.2439\n",
      "Epoch 265/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.7723 - val_loss: 1.0839\n",
      "Epoch 266/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.5078 - val_loss: 0.7726\n",
      "Epoch 267/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.6689 - val_loss: 2.5169\n",
      "Epoch 268/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.7157 - val_loss: 2.7336\n",
      "Epoch 269/400\n",
      "147/147 [==============================] - 1s 3ms/step - loss: 1.6339 - val_loss: 2.1666\n",
      "Epoch 270/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.7443 - val_loss: 0.7219\n",
      "Epoch 271/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.5896 - val_loss: 1.6062\n",
      "Epoch 272/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.5296 - val_loss: 0.6827\n",
      "Epoch 273/400\n",
      "147/147 [==============================] - 1s 3ms/step - loss: 1.6360 - val_loss: 0.9262\n",
      "Epoch 274/400\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 1.6787 - val_loss: 1.3743\n",
      "Epoch 275/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.6962 - val_loss: 1.3640\n",
      "Epoch 276/400\n",
      "147/147 [==============================] - 1s 3ms/step - loss: 1.7453 - val_loss: 1.4323\n",
      "Epoch 277/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.5758 - val_loss: 1.1209\n",
      "Epoch 278/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.7425 - val_loss: 1.6165\n",
      "Epoch 279/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 4.9873 - val_loss: 1.2493\n",
      "Epoch 280/400\n",
      "147/147 [==============================] - 1s 3ms/step - loss: 1.4148 - val_loss: 1.0973\n",
      "Epoch 281/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.4176 - val_loss: 1.2956\n",
      "Epoch 282/400\n",
      "147/147 [==============================] - 1s 3ms/step - loss: 1.5875 - val_loss: 1.9424\n",
      "Epoch 283/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.5477 - val_loss: 1.2900\n",
      "Epoch 284/400\n",
      "147/147 [==============================] - ETA: 0s - loss: 1.748 - ETA: 0s - loss: 1.752 - 1s 4ms/step - loss: 1.7407 - val_loss: 1.0760\n",
      "Epoch 285/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.6399 - val_loss: 2.5194\n",
      "Epoch 286/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.9006 - val_loss: 1.0371\n",
      "Epoch 287/400\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 1.5555 - val_loss: 1.2768\n",
      "Epoch 288/400\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 1.6487 - val_loss: 2.3526\n",
      "Epoch 289/400\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 1.6375 - val_loss: 0.9722\n",
      "Epoch 290/400\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 1.4981 - val_loss: 1.3384\n",
      "Epoch 291/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6534 - val_loss: 1.5463\n",
      "Epoch 292/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.7097 - val_loss: 1.5906\n",
      "Epoch 293/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.6286 - val_loss: 0.9049\n",
      "Epoch 294/400\n",
      "147/147 [==============================] - 1s 3ms/step - loss: 1.3782 - val_loss: 3.1946\n",
      "Epoch 295/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.7292 - val_loss: 2.7080\n",
      "Epoch 296/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.6223 - val_loss: 1.3809\n",
      "Epoch 297/400\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 1.5789 - val_loss: 1.5951\n",
      "Epoch 298/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6519 - val_loss: 2.4407\n",
      "Epoch 299/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.5496 - val_loss: 2.7154\n",
      "Epoch 300/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.6299 - val_loss: 3.0341\n",
      "Epoch 301/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.6032 - val_loss: 1.5706\n",
      "Epoch 302/400\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 1.5186 - val_loss: 2.4480\n",
      "Epoch 303/400\n",
      "147/147 [==============================] - 0s 3ms/step - loss: 1.6969 - val_loss: 1.8478\n",
      "Epoch 304/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.6742 - val_loss: 2.8723\n",
      "Epoch 305/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.7213 - val_loss: 2.0777\n",
      "Epoch 306/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.7209 - val_loss: 1.7751\n",
      "Epoch 307/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.5502 - val_loss: 2.3289\n",
      "Epoch 308/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.6018 - val_loss: 1.5759\n",
      "Epoch 309/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.9539 - val_loss: 0.7463\n",
      "Epoch 310/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.4904 - val_loss: 1.5884\n",
      "Epoch 311/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.5087 - val_loss: 2.0262\n",
      "Epoch 312/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.5606 - val_loss: 1.2043\n",
      "Epoch 313/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.4741 - val_loss: 2.2146\n",
      "Epoch 314/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6602 - val_loss: 1.1827\n",
      "Epoch 315/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.4535 - val_loss: 1.3968\n",
      "Epoch 316/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.5712 - val_loss: 1.2916\n",
      "Epoch 317/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.5315 - val_loss: 1.5279\n",
      "Epoch 318/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6097 - val_loss: 1.4463\n",
      "Epoch 319/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.5381 - val_loss: 2.8072\n",
      "Epoch 320/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6650 - val_loss: 0.9785\n",
      "Epoch 321/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.6155 - val_loss: 2.3719\n",
      "Epoch 322/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.5472 - val_loss: 1.4421\n",
      "Epoch 323/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.5778 - val_loss: 3.6556\n",
      "Epoch 324/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.5962 - val_loss: 1.2217\n",
      "Epoch 325/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.4922 - val_loss: 1.2110\n",
      "Epoch 326/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6456 - val_loss: 1.1933\n",
      "Epoch 327/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.5633 - val_loss: 1.0000\n",
      "Epoch 328/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.4948 - val_loss: 2.1792\n",
      "Epoch 329/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6102 - val_loss: 1.4504\n",
      "Epoch 330/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.5588 - val_loss: 2.5989\n",
      "Epoch 331/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.4789 - val_loss: 1.9174\n",
      "Epoch 332/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6063 - val_loss: 0.7500\n",
      "Epoch 333/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.5459 - val_loss: 1.5738\n",
      "Epoch 334/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.7022 - val_loss: 1.1119\n",
      "Epoch 335/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.4182 - val_loss: 1.5982\n",
      "Epoch 336/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.5284 - val_loss: 1.7309\n",
      "Epoch 337/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.4908 - val_loss: 2.6588\n",
      "Epoch 338/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6095 - val_loss: 0.9752\n",
      "Epoch 339/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147/147 [==============================] - 1s 5ms/step - loss: 1.5363 - val_loss: 0.9158 ETA: 0s - loss: 1\n",
      "Epoch 340/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.6002 - val_loss: 3.1972\n",
      "Epoch 341/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 2.1634 - val_loss: 0.8779\n",
      "Epoch 342/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.5863 - val_loss: 2.2831\n",
      "Epoch 343/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.6140 - val_loss: 1.2972\n",
      "Epoch 344/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.4685 - val_loss: 2.0994\n",
      "Epoch 345/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.5715 - val_loss: 1.3749\n",
      "Epoch 346/400\n",
      "147/147 [==============================] - 1s 4ms/step - loss: 1.6749 - val_loss: 1.2318\n",
      "Epoch 347/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.3862 - val_loss: 2.9178\n",
      "Epoch 348/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.5344 - val_loss: 1.2081\n",
      "Epoch 349/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.5627 - val_loss: 1.1788\n",
      "Epoch 350/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.5341 - val_loss: 0.9519\n",
      "Epoch 351/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.4369 - val_loss: 1.3464\n",
      "Epoch 352/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.4793 - val_loss: 1.5405\n",
      "Epoch 353/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.4809 - val_loss: 1.5599\n",
      "Epoch 354/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.5129 - val_loss: 2.0871\n",
      "Epoch 355/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.4959 - val_loss: 0.4907\n",
      "Epoch 356/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.6090 - val_loss: 2.1304\n",
      "Epoch 357/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.3811 - val_loss: 0.7238\n",
      "Epoch 358/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.4640 - val_loss: 2.0980\n",
      "Epoch 359/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.6371 - val_loss: 0.7692\n",
      "Epoch 360/400\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 1.5000 - val_loss: 2.8068\n",
      "Epoch 361/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.4915 - val_loss: 1.9410\n",
      "Epoch 362/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.4097 - val_loss: 0.8864\n",
      "Epoch 363/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.5639 - val_loss: 1.3210\n",
      "Epoch 364/400\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 1.5140 - val_loss: 1.2621\n",
      "Epoch 365/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.5439 - val_loss: 0.9791\n",
      "Epoch 366/400\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 1.4805 - val_loss: 1.7840\n",
      "Epoch 367/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.5544 - val_loss: 0.7195\n",
      "Epoch 368/400\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 1.3533 - val_loss: 1.5022\n",
      "Epoch 369/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.4587 - val_loss: 2.0515\n",
      "Epoch 370/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.4774 - val_loss: 1.8390\n",
      "Epoch 371/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.5551 - val_loss: 1.6744\n",
      "Epoch 372/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.5092 - val_loss: 1.3823\n",
      "Epoch 373/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.6253 - val_loss: 1.7869\n",
      "Epoch 374/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.4372 - val_loss: 1.7516\n",
      "Epoch 375/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.5489 - val_loss: 2.0559\n",
      "Epoch 376/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.3842 - val_loss: 1.3826\n",
      "Epoch 377/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.4366 - val_loss: 2.5355\n",
      "Epoch 378/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.4404 - val_loss: 2.0488\n",
      "Epoch 379/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.4856 - val_loss: 0.7302\n",
      "Epoch 380/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.4374 - val_loss: 1.9381\n",
      "Epoch 381/400\n",
      "147/147 [==============================] - 1s 7ms/step - loss: 1.3918 - val_loss: 1.5645\n",
      "Epoch 382/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.5483 - val_loss: 1.7910\n",
      "Epoch 383/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.5365 - val_loss: 1.8844\n",
      "Epoch 384/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.5322 - val_loss: 1.0771\n",
      "Epoch 385/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.3724 - val_loss: 1.0853\n",
      "Epoch 386/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.3802 - val_loss: 0.7289\n",
      "Epoch 387/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.4605 - val_loss: 0.8470\n",
      "Epoch 388/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.4115 - val_loss: 3.0731\n",
      "Epoch 389/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.3799 - val_loss: 2.3681\n",
      "Epoch 390/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.4868 - val_loss: 3.4079\n",
      "Epoch 391/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.5258 - val_loss: 0.7670\n",
      "Epoch 392/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.4516 - val_loss: 2.4142\n",
      "Epoch 393/400\n",
      "147/147 [==============================] - 1s 5ms/step - loss: 1.4323 - val_loss: 0.8362\n",
      "Epoch 394/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.4073 - val_loss: 4.0878\n",
      "Epoch 395/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.4474 - val_loss: 0.6896\n",
      "Epoch 396/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.2564 - val_loss: 2.1007\n",
      "Epoch 397/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.3744 - val_loss: 2.4489A: 0s - loss: 1.369 - ETA: 0s - loss: 1.337\n",
      "Epoch 398/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.5691 - val_loss: 2.6222\n",
      "Epoch 399/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.3069 - val_loss: 1.2303\n",
      "Epoch 400/400\n",
      "147/147 [==============================] - 1s 6ms/step - loss: 1.4002 - val_loss: 1.9727\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train, batch_size=4, epochs=400, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"modelnum.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"modelnum.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[0.38259114 0.2897271  0.61579353 0.10559242 0.36690397 0.99604307], Predicted=[124.15221]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "Xnew = array([[0.38259114, 0.2897271 , 0.61579353, 0.10559242, 0.36690397,\n",
    "        0.99604307]])\n",
    "# make a prediction\n",
    "ynew = model.predict(Xnew)\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\"%(Xnew[0], ynew[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[0.38259114 0.2897271  0.61579353 0.10559242 0.36690397 0.99604307], Predicted=[124.15221]\n"
     ]
    }
   ],
   "source": [
    "Xnew = array([[0.38259114, 0.2897271 , 0.61579353, 0.10559242, 0.36690397,\n",
    "        0.99604307]])\n",
    "# make a prediction\n",
    "ynew = model.predict(Xnew)\n",
    "# show the inputs and predicted outputs\n",
    "print(\"X=%s, Predicted=%s\"%(Xnew[0], ynew[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.38259114 0.2897271  0.61579353 0.10559242 0.36690397 0.99604307]]\n"
     ]
    }
   ],
   "source": [
    "print(Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.87999902 0.67808388 0.05798712 0.         0.01258992]]\n",
      "184\n"
     ]
    }
   ],
   "source": [
    "Xnew = array([[X_scale[0][0], X_scale[0][1] , X_scale[0][2], X_scale[0][3], X_scale[0][4],\n",
    "        X_scale[0][5]]])\n",
    "print(Xnew)\n",
    "print(len(X_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "arr = []\n",
    "for x in range(len(X_scale)):\n",
    "    Xnew = array([[X_scale[x][0], X_scale[x][1] , X_scale[x][2], X_scale[x][3], X_scale[x][4], X_scale[x][5]]])\n",
    "    ynew = model.predict(Xnew)\n",
    "    #print(ynew[0][0])\n",
    "    arr.append(ynew[0][0])\n",
    "array = np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[52.186004638671875,\n",
       " 52.404911041259766,\n",
       " 52.73331832885742,\n",
       " 53.16535186767578,\n",
       " 53.76326370239258,\n",
       " 54.76945495605469,\n",
       " 56.35335159301758,\n",
       " 58.12604904174805,\n",
       " 59.887969970703125,\n",
       " 61.64373016357422,\n",
       " 63.367767333984375,\n",
       " 64.4114990234375,\n",
       " 65.11245727539062,\n",
       " 65.74150848388672,\n",
       " 66.97767639160156,\n",
       " 68.27629089355469,\n",
       " 69.60210418701172,\n",
       " 70.87998962402344,\n",
       " 72.10466766357422,\n",
       " 73.32054138183594,\n",
       " 74.51152801513672,\n",
       " 75.68570709228516,\n",
       " 76.911376953125,\n",
       " 78.17269897460938,\n",
       " 79.4612808227539,\n",
       " 80.59812927246094,\n",
       " 81.1373062133789,\n",
       " 81.46444702148438,\n",
       " 81.73710632324219,\n",
       " 81.9652328491211,\n",
       " 82.16862487792969,\n",
       " 82.35494232177734,\n",
       " 82.53008270263672,\n",
       " 82.70018768310547,\n",
       " 82.86742401123047,\n",
       " 82.98351287841797,\n",
       " 83.0445785522461,\n",
       " 83.07095336914062,\n",
       " 83.073974609375,\n",
       " 83.0648193359375,\n",
       " 83.09750366210938,\n",
       " 83.13076782226562,\n",
       " 83.16524505615234,\n",
       " 83.2011947631836,\n",
       " 83.2356948852539,\n",
       " 83.25695037841797,\n",
       " 83.20870208740234,\n",
       " 83.0950927734375,\n",
       " 82.98506927490234,\n",
       " 82.88079833984375,\n",
       " 82.78585052490234,\n",
       " 82.70560455322266,\n",
       " 82.6393051147461,\n",
       " 82.62971496582031,\n",
       " 82.6202392578125,\n",
       " 82.61087036132812,\n",
       " 82.6017074584961,\n",
       " 82.59292602539062,\n",
       " 82.58451843261719,\n",
       " 82.57634735107422,\n",
       " 82.56864166259766,\n",
       " 82.56175231933594,\n",
       " 82.55626678466797,\n",
       " 82.55294799804688,\n",
       " 82.55265808105469,\n",
       " 82.55814361572266,\n",
       " 82.65216064453125,\n",
       " 82.8220443725586,\n",
       " 83.15138244628906,\n",
       " 83.632568359375,\n",
       " 84.21849060058594,\n",
       " 84.92047882080078,\n",
       " 85.6975326538086,\n",
       " 86.49623107910156,\n",
       " 87.26040649414062,\n",
       " 87.96720123291016,\n",
       " 88.64666748046875,\n",
       " 89.31429290771484,\n",
       " 90.01148223876953,\n",
       " 90.83271789550781,\n",
       " 91.90042877197266,\n",
       " 93.3316650390625,\n",
       " 94.8963851928711,\n",
       " 96.54058837890625,\n",
       " 98.29235076904297,\n",
       " 100.22734832763672,\n",
       " 101.6956787109375,\n",
       " 103.13861083984375,\n",
       " 104.88832092285156,\n",
       " 106.73262023925781,\n",
       " 108.53324890136719,\n",
       " 109.9072036743164,\n",
       " 111.42298889160156,\n",
       " 113.58907318115234,\n",
       " 115.50450134277344,\n",
       " 117.1274185180664,\n",
       " 118.58692932128906,\n",
       " 119.97303009033203,\n",
       " 121.3211441040039,\n",
       " 122.62813568115234,\n",
       " 123.87114715576172,\n",
       " 125.04446411132812,\n",
       " 126.13540649414062,\n",
       " 126.9631576538086,\n",
       " 127.43634033203125,\n",
       " 127.64544677734375,\n",
       " 127.95195007324219,\n",
       " 128.2107391357422,\n",
       " 128.42352294921875,\n",
       " 128.60256958007812,\n",
       " 128.7528076171875,\n",
       " 128.87789916992188,\n",
       " 128.983642578125,\n",
       " 129.07278442382812,\n",
       " 129.1480255126953,\n",
       " 129.21127319335938,\n",
       " 129.26385498046875,\n",
       " 129.30653381347656,\n",
       " 129.33755493164062,\n",
       " 129.35031127929688,\n",
       " 129.345703125,\n",
       " 129.3216094970703,\n",
       " 129.27810668945312,\n",
       " 129.20376586914062,\n",
       " 129.10350036621094,\n",
       " 128.98388671875,\n",
       " 128.8489227294922,\n",
       " 128.70167541503906,\n",
       " 128.54420471191406,\n",
       " 128.37762451171875,\n",
       " 128.20242309570312,\n",
       " 128.04730224609375,\n",
       " 127.8830795288086,\n",
       " 127.71063232421875,\n",
       " 127.55194091796875,\n",
       " 127.44589233398438,\n",
       " 127.37188720703125,\n",
       " 127.31507110595703,\n",
       " 127.26607513427734,\n",
       " 127.22111511230469,\n",
       " 127.18133544921875,\n",
       " 127.1442642211914,\n",
       " 127.1082763671875,\n",
       " 127.07201385498047,\n",
       " 127.03451538085938,\n",
       " 127.0110092163086,\n",
       " 126.95121765136719,\n",
       " 126.85517120361328,\n",
       " 126.71723175048828,\n",
       " 126.53417205810547,\n",
       " 126.32460021972656,\n",
       " 126.11495208740234,\n",
       " 125.9026870727539,\n",
       " 125.68133544921875,\n",
       " 125.44824981689453,\n",
       " 125.20159149169922,\n",
       " 124.94268035888672,\n",
       " 124.66826629638672,\n",
       " 124.63529205322266,\n",
       " 124.59634399414062,\n",
       " 124.54989624023438,\n",
       " 124.49986267089844,\n",
       " 124.4485855102539,\n",
       " 124.39552307128906,\n",
       " 124.33943939208984,\n",
       " 124.27714538574219,\n",
       " 124.20404052734375,\n",
       " 124.10383605957031,\n",
       " 123.93952941894531,\n",
       " 123.61283874511719,\n",
       " 122.76478576660156,\n",
       " 123.1148910522461,\n",
       " 123.36602020263672,\n",
       " 123.54864501953125,\n",
       " 123.68391418457031,\n",
       " 123.78587341308594,\n",
       " 123.86491394042969,\n",
       " 123.928466796875,\n",
       " 123.98085021972656,\n",
       " 124.02445983886719,\n",
       " 124.06148529052734,\n",
       " 124.09334564208984,\n",
       " 124.12110137939453,\n",
       " 124.14558410644531]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9900012524613868"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(Y.tolist(), array.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
