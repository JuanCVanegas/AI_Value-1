{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Interpolation/InterpolatedDenMonth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATES</th>\n",
       "      <th>D REVENUE</th>\n",
       "      <th>U CR</th>\n",
       "      <th>D OE</th>\n",
       "      <th>D NOI</th>\n",
       "      <th>U CAPEX</th>\n",
       "      <th>U CWK</th>\n",
       "      <th>D FCF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>1884.372544</td>\n",
       "      <td>976.202014</td>\n",
       "      <td>475.249997</td>\n",
       "      <td>757.519678</td>\n",
       "      <td>207.477947</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>856.600959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>1884.566826</td>\n",
       "      <td>983.762225</td>\n",
       "      <td>485.004015</td>\n",
       "      <td>734.017979</td>\n",
       "      <td>207.303532</td>\n",
       "      <td>3638.472896</td>\n",
       "      <td>810.859727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-28</td>\n",
       "      <td>1884.761107</td>\n",
       "      <td>991.322435</td>\n",
       "      <td>494.758033</td>\n",
       "      <td>710.516281</td>\n",
       "      <td>207.129117</td>\n",
       "      <td>3676.945791</td>\n",
       "      <td>765.118495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>1884.955389</td>\n",
       "      <td>998.882646</td>\n",
       "      <td>504.512051</td>\n",
       "      <td>687.014582</td>\n",
       "      <td>206.954702</td>\n",
       "      <td>3715.418687</td>\n",
       "      <td>719.377263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>1880.767673</td>\n",
       "      <td>1006.377690</td>\n",
       "      <td>481.542613</td>\n",
       "      <td>511.922217</td>\n",
       "      <td>207.283705</td>\n",
       "      <td>3792.839197</td>\n",
       "      <td>732.414605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>1785.193900</td>\n",
       "      <td>972.274049</td>\n",
       "      <td>461.469501</td>\n",
       "      <td>414.377788</td>\n",
       "      <td>98.125058</td>\n",
       "      <td>2795.231076</td>\n",
       "      <td>733.164793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2018-09-30</td>\n",
       "      <td>1730.706270</td>\n",
       "      <td>953.165883</td>\n",
       "      <td>488.056175</td>\n",
       "      <td>424.307526</td>\n",
       "      <td>95.323030</td>\n",
       "      <td>2858.452805</td>\n",
       "      <td>729.764211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2018-10-31</td>\n",
       "      <td>1667.921494</td>\n",
       "      <td>856.900384</td>\n",
       "      <td>471.261535</td>\n",
       "      <td>434.874583</td>\n",
       "      <td>92.144220</td>\n",
       "      <td>2849.606546</td>\n",
       "      <td>737.713784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>1605.136718</td>\n",
       "      <td>760.634885</td>\n",
       "      <td>454.466895</td>\n",
       "      <td>445.441639</td>\n",
       "      <td>88.965411</td>\n",
       "      <td>2840.760287</td>\n",
       "      <td>745.663358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>1542.351942</td>\n",
       "      <td>664.369385</td>\n",
       "      <td>437.672255</td>\n",
       "      <td>456.008696</td>\n",
       "      <td>85.786601</td>\n",
       "      <td>2831.914028</td>\n",
       "      <td>753.612931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATES    D REVENUE         U CR        D OE       D NOI     U CAPEX  \\\n",
       "0    2009-12-31  1884.372544   976.202014  475.249997  757.519678  207.477947   \n",
       "1    2010-01-31  1884.566826   983.762225  485.004015  734.017979  207.303532   \n",
       "2    2010-02-28  1884.761107   991.322435  494.758033  710.516281  207.129117   \n",
       "3    2010-03-31  1884.955389   998.882646  504.512051  687.014582  206.954702   \n",
       "4    2010-04-30  1880.767673  1006.377690  481.542613  511.922217  207.283705   \n",
       "..          ...          ...          ...         ...         ...         ...   \n",
       "104  2018-08-31  1785.193900   972.274049  461.469501  414.377788   98.125058   \n",
       "105  2018-09-30  1730.706270   953.165883  488.056175  424.307526   95.323030   \n",
       "106  2018-10-31  1667.921494   856.900384  471.261535  434.874583   92.144220   \n",
       "107  2018-11-30  1605.136718   760.634885  454.466895  445.441639   88.965411   \n",
       "108  2018-12-31  1542.351942   664.369385  437.672255  456.008696   85.786601   \n",
       "\n",
       "           U CWK       D FCF  \n",
       "0    3600.000000  856.600959  \n",
       "1    3638.472896  810.859727  \n",
       "2    3676.945791  765.118495  \n",
       "3    3715.418687  719.377263  \n",
       "4    3792.839197  732.414605  \n",
       "..           ...         ...  \n",
       "104  2795.231076  733.164793  \n",
       "105  2858.452805  729.764211  \n",
       "106  2849.606546  737.713784  \n",
       "107  2840.760287  745.663358  \n",
       "108  2831.914028  753.612931  \n",
       "\n",
       "[109 rows x 8 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "721.8102386623852"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"D FCF\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2009-12-31', 1884.372544, 976.2020142, 475.24999739999987,\n",
       "        757.519678, 207.4779469, 3600.0, 856.6009594000002],\n",
       "       ['2010-01-31', 1884.5668256666668, 983.7622247333335, 485.0040154,\n",
       "        734.0179793333333, 207.30353190000002, 3638.472895666667,\n",
       "        810.8597272333334],\n",
       "       ['2010-02-28', 1884.761107333333, 991.3224352666666,\n",
       "        494.75803339999993, 710.5162806666667, 207.12911689999999,\n",
       "        3676.945791333333, 765.1184950666667],\n",
       "       ['2010-03-31', 1884.955389, 998.8826458, 504.5120514, 687.014582,\n",
       "        206.9547019, 3715.418687, 719.3772629],\n",
       "       ['2010-04-30', 1880.767673333333, 1006.3776901999997,\n",
       "        481.5426128333333, 511.92221730000006, 207.28370463333331,\n",
       "        3792.8391966666654, 732.4146046],\n",
       "       ['2010-05-31', 1876.5799576666668, 1013.8727346000001,\n",
       "        458.5731742666666, 336.8298526000001, 207.61270736666665,\n",
       "        3870.2597063333333, 745.4519462999999],\n",
       "       ['2010-06-30', 1872.392242, 1021.367779, 435.6037357, 161.7374879,\n",
       "        207.9417101, 3947.680216, 758.489288],\n",
       "       ['2010-07-31', 1853.240114, 1015.1698886666666, 421.8261523,\n",
       "        187.6358415, 207.7144804333333, 3965.748594666666,\n",
       "        756.6899263333332],\n",
       "       ['2010-08-31', 1834.087986, 1008.9719983333333, 408.0485689,\n",
       "        213.5341951, 207.48725076666665, 3983.816973333333,\n",
       "        754.8905646666667],\n",
       "       ['2010-09-30', 1814.935858, 1002.774108, 394.2709855, 239.4325487,\n",
       "        207.2600211, 4001.885352, 753.0912030000002],\n",
       "       ['2010-10-31', 1851.320774, 1008.5464486666666, 411.1460836666666,\n",
       "        246.73378476666667, 212.21753106666665, 4093.646761333333,\n",
       "        715.3372166666667],\n",
       "       ['2010-11-30', 1887.70569, 1014.3187893333335, 428.0211818333333,\n",
       "        254.03502083333333, 217.1750410333333, 4185.408170666667,\n",
       "        677.5832303333334],\n",
       "       ['2010-12-31', 1924.090606, 1020.09113, 444.89628, 261.3362569,\n",
       "        222.132551, 4277.16958, 639.829244],\n",
       "       ['2011-01-31', 1840.631611, 1004.3123142000001, 439.1857453333333,\n",
       "        253.3520595, 221.3439679, 4255.687593333333, 625.4113584666667],\n",
       "       ['2011-02-28', 1757.172616, 988.5334983999999, 433.47521066666667,\n",
       "        245.36786209999997, 220.5553848, 4234.205606666666,\n",
       "        610.9934729333334],\n",
       "       ['2011-03-31', 1673.713621, 972.7546826, 427.764676, 237.3836647,\n",
       "        219.7668017, 4212.723620000002, 596.5755874],\n",
       "       ['2011-04-30', 1697.5040236666666, 943.8024453, 430.2420961,\n",
       "        237.04147333333333, 223.6841742333333, 4253.569522333334,\n",
       "        596.6860897999999],\n",
       "       ['2011-05-31', 1721.2944263333334, 914.850208, 432.71951619999993,\n",
       "        236.69928196666663, 227.60154676666667, 4294.415424666667,\n",
       "        596.7965922000002],\n",
       "       ['2011-06-30', 1745.084829, 885.8979707000002, 435.1969363,\n",
       "        236.3570906, 231.5189193, 4335.261327, 596.9070946],\n",
       "       ['2011-07-31', 1775.998593, 875.2949231666668, 444.6121419,\n",
       "        236.2388491, 227.72962546666668, 4329.278552666667,\n",
       "        628.3878588333333],\n",
       "       ['2011-08-31', 1806.912357, 864.6918756333333, 454.02734749999996,\n",
       "        236.1206076, 223.94033163333333, 4323.295778333333,\n",
       "        659.8686230666667],\n",
       "       ['2011-09-30', 1837.826121, 854.0888281, 463.44255310000005,\n",
       "        236.0023661, 220.1510378, 4317.313004, 691.3493873],\n",
       "       ['2011-10-31', 1885.0705423333332, 857.2014145333335,\n",
       "        470.0062231666667, 244.5463731, 212.89141523333333,\n",
       "        4309.167693666666, 690.0065109333333],\n",
       "       ['2011-11-30', 1932.314963666667, 860.3140009666665,\n",
       "        476.56989323333335, 253.0903801, 205.63179266666666,\n",
       "        4301.022383333333, 688.6636345666667],\n",
       "       ['2011-12-31', 1979.559385, 863.4265874, 483.13356330000005,\n",
       "        261.6343871, 198.3721701, 4292.877073, 687.3207582],\n",
       "       ['2012-01-31', 1910.3834399999998, 858.4811889666668,\n",
       "        483.72593293333335, 263.6296255, 198.3738698333333, 4291.272806,\n",
       "        711.6253066666667],\n",
       "       ['2012-02-29', 1841.2074949999999, 853.5357905333334,\n",
       "        484.3183025666667, 265.6248639, 198.37556956666668,\n",
       "        4289.668538999998, 735.9298551333335],\n",
       "       ['2012-03-31', 1772.03155, 848.5903921, 484.9106722, 267.6201023,\n",
       "        198.3772693, 4288.064272, 760.2344036000002],\n",
       "       ['2012-04-30', 1805.3226533333332, 852.7747259666667,\n",
       "        500.10971653333337, 262.53434903333334, 203.80507153333332,\n",
       "        4248.180273333333, 760.4925157666668],\n",
       "       ['2012-05-31', 1838.6137566666666, 856.9590598333334,\n",
       "        515.3087608666667, 257.44859576666664, 209.23287376666664,\n",
       "        4208.296274666666, 760.7506279333335],\n",
       "       ['2012-06-30', 1871.90486, 861.1433937, 530.5078052, 252.3628425,\n",
       "        214.660676, 4168.412276, 761.0087401000002],\n",
       "       ['2012-07-31', 1870.0189613333332, 888.6962120999999,\n",
       "        512.9147551333333, 274.75087963333334, 210.84279596666664,\n",
       "        4100.139316, 761.8369197333334],\n",
       "       ['2012-08-31', 1868.1330626666668, 916.2490305,\n",
       "        495.32170506666665, 297.1389167666666, 207.02491593333332,\n",
       "        4031.8663560000005, 762.6650993666667],\n",
       "       ['2012-09-30', 1866.247164, 943.8018489, 477.728655, 319.5269539,\n",
       "        203.2070359, 3963.593396, 763.493279],\n",
       "       ['2012-10-31', 1872.4550559999998, 871.4747433666665,\n",
       "        485.99178150000006, 323.89898873333334, 198.78250549999998,\n",
       "        3581.357899333333, 776.451154],\n",
       "       ['2012-11-30', 1878.6629480000001, 799.1476378333333, 494.254908,\n",
       "        328.27102356666666, 194.3579751, 3199.1224026666664, 789.409029],\n",
       "       ['2012-12-31', 1884.87084, 726.8205323, 502.5180345, 332.6430584,\n",
       "        189.9334447, 2816.886906, 802.366904],\n",
       "       ['2013-01-31', 1896.30791, 753.0427803333333, 514.5447965666667,\n",
       "        333.5149285333333, 192.01279616666667, 2893.339288,\n",
       "        793.3964250333332],\n",
       "       ['2013-02-28', 1907.7449800000002, 779.2650283666666,\n",
       "        526.5715586333333, 334.38679866666666, 194.09214763333333,\n",
       "        2969.79167, 784.4259460666666],\n",
       "       ['2013-03-31', 1919.18205, 805.4872763999998, 538.5983207,\n",
       "        335.2586688, 196.1714991, 3046.244052, 775.4554671],\n",
       "       ['2013-04-30', 1867.7861953333331, 783.4079046999999,\n",
       "        530.8571651000001, 335.86746453333336, 195.6670658333333,\n",
       "        3048.921046333333, 766.0225778666667],\n",
       "       ['2013-05-31', 1816.3903406666666, 761.328533, 523.1160095,\n",
       "        336.47626026666666, 195.16263256666667, 3051.5980406666667,\n",
       "        756.5896886333333],\n",
       "       ['2013-06-30', 1764.994486, 739.2491613, 515.3748539, 337.085056,\n",
       "        194.6581993, 3054.275035, 747.1567994],\n",
       "       ['2013-07-31', 1768.6169343333331, 757.7170030999998, 520.4034373,\n",
       "        329.2451542333333, 198.2425908, 2952.306149666667, 757.3171348],\n",
       "       ['2013-08-31', 1772.2393826666666, 776.1848449, 525.4320207000002,\n",
       "        321.40525246666664, 201.8269823, 2850.337264333333,\n",
       "        767.4774702000001],\n",
       "       ['2013-09-30', 1775.861831, 794.6526867, 530.4606041000002,\n",
       "        313.5653506999999, 205.4113738, 2748.368379, 777.6378056],\n",
       "       ['2013-10-31', 1781.312525333333, 813.7964820333333,\n",
       "        531.6057520333334, 320.4643399333333, 203.1795522,\n",
       "        2446.6776800000002, 776.7867944],\n",
       "       ['2013-11-30', 1786.7632196666668, 832.9402773666667,\n",
       "        532.7508999666667, 327.36332916666663, 200.9477306, 2144.986981,\n",
       "        775.9357832000001],\n",
       "       ['2013-12-31', 1792.2139140000004, 852.0840727, 533.8960479,\n",
       "        334.2623184, 198.715909, 1843.296282, 775.0847719999998],\n",
       "       ['2014-01-31', 1772.1792736666669, 861.7296213999998, 528.3798523,\n",
       "        342.6429393, 191.0202412333333, 1839.5208699999998,\n",
       "        774.5279383333333],\n",
       "       ['2014-02-28', 1752.144633333333, 871.3751701, 522.8636567,\n",
       "        351.0235602, 183.32457346666664, 1835.7454579999999,\n",
       "        773.9711046666665],\n",
       "       ['2014-03-31', 1732.109993, 881.0207187999998, 517.3474611,\n",
       "        359.4041811, 175.6289057, 1831.970046, 773.414271],\n",
       "       ['2014-04-30', 1721.8949903333335, 890.6855609999999,\n",
       "        507.92859023333335, 349.91219946666666, 168.82089786666666,\n",
       "        1848.738663666667, 760.1008118333333],\n",
       "       ['2014-05-31', 1711.6799876666666, 900.3504032,\n",
       "        498.50971936666673, 340.4202178333333, 162.01289003333332,\n",
       "        1865.507281333333, 746.7873526666666],\n",
       "       ['2014-06-30', 1701.464985, 910.0152454, 489.09084850000005,\n",
       "        330.9282362, 155.2048822, 1882.275899, 733.4738934999998],\n",
       "       ['2014-07-31', 1728.4231946666666, 914.2662125, 481.6856930666667,\n",
       "        331.95640223333334, 150.8917052333333, 1896.6301780000001,\n",
       "        727.0572944999999],\n",
       "       ['2014-08-31', 1755.3814043333334, 918.5171796,\n",
       "        474.28053763333327, 332.98456826666666, 146.57852826666667,\n",
       "        1910.984457, 720.6406955],\n",
       "       ['2014-09-30', 1782.339614, 922.7681467, 466.8753822,\n",
       "        334.0127343000001, 142.2653513, 1925.338736, 714.2240965],\n",
       "       ['2014-10-31', 1725.137324333333, 965.4992654666668,\n",
       "        478.28002593333326, 415.6834258, 141.41725303333334,\n",
       "        1946.0452103333328, 728.1806636666665],\n",
       "       ['2014-11-30', 1667.935034666667, 1008.2303842333333,\n",
       "        489.68466966666665, 497.35411730000004, 140.56915476666666,\n",
       "        1966.751684666667, 742.1372308333333],\n",
       "       ['2014-12-31', 1610.732745, 1050.961503, 501.0893134, 579.0248088,\n",
       "        139.7210565, 1987.458159, 756.093798],\n",
       "       ['2015-01-31', 1746.422448666667, 1054.429111, 508.5803035333333,\n",
       "        579.2034107000001, 137.07026573333334, 2005.468421,\n",
       "        771.8714318333333],\n",
       "       ['2015-02-28', 1882.112152333333, 1057.8967189999998,\n",
       "        516.0712936666666, 579.3820125999998, 134.41947496666666,\n",
       "        2023.478683, 787.6490656666667],\n",
       "       ['2015-03-31', 2017.801856, 1061.364327, 523.5622838,\n",
       "        579.5606144999998, 131.7686842, 2041.488945, 803.4266995],\n",
       "       ['2015-04-30', 2107.344116, 1096.44801, 526.1169451000002,\n",
       "        577.4851386666667, 131.0318083, 2038.723757, 790.2704643666667],\n",
       "       ['2015-05-31', 2196.8863760000004, 1131.531693, 528.6716064,\n",
       "        575.4096628333333, 130.2949324, 2035.9585690000001,\n",
       "        777.1142292333334],\n",
       "       ['2015-06-30', 2286.428636, 1166.615376, 531.2262677, 573.334187,\n",
       "        129.5580565, 2033.193381, 763.9579941000002],\n",
       "       ['2015-07-31', 2528.4880129999997, 1194.063472, 562.655131,\n",
       "        551.8155191666667, 128.9129271, 2038.7990923333327, 725.2341621],\n",
       "       ['2015-08-31', 2770.5473899999997, 1221.511568, 594.0839943000002,\n",
       "        530.2968513333334, 128.2677977, 2044.4048036666666, 686.5103301],\n",
       "       ['2015-09-30', 3012.606767, 1248.959664, 625.5128576000002,\n",
       "        508.7781835, 127.6226683, 2050.010515, 647.7864981],\n",
       "       ['2015-10-31', 2903.7366663333332, 1269.6701176666666,\n",
       "        641.4096041, 508.9514627, 117.39104201, 2031.2492326666666,\n",
       "        646.7970369666667],\n",
       "       ['2015-11-30', 2794.8665656666667, 1290.3805713333334,\n",
       "        657.3063506000002, 509.1247419, 107.15941572, 2012.4879503333332,\n",
       "        645.8075758333333],\n",
       "       ['2015-12-31', 2685.996465, 1311.091025, 673.2030971, 509.2980211,\n",
       "        96.92778943, 1993.726668, 644.8181147000001],\n",
       "       ['2016-01-31', 2834.140780666666, 1366.4444733333332,\n",
       "        674.0792667333334, 500.8613563, 382.7185262866667, 2146.965891,\n",
       "        645.8685558666667],\n",
       "       ['2016-02-29', 2982.285096333333, 1421.7979216666665,\n",
       "        674.9554363666666, 492.4246915, 668.5092631433333, 2300.205114,\n",
       "        646.9189970333333],\n",
       "       ['2016-03-31', 3130.429412, 1477.1513699999996, 675.831606,\n",
       "        483.9880267, 954.3, 2453.444337, 647.9694382],\n",
       "       ['2016-04-30', 3060.8571920000004, 1508.7480799999996,\n",
       "        653.6836567666667, 473.8452801, 669.9162089666665,\n",
       "        2448.972803333333, 637.6159774666667],\n",
       "       ['2016-05-31', 2991.284972, 1540.34479, 631.5357075333333,\n",
       "        463.7025335, 385.5324179333333, 2444.5012696666668,\n",
       "        627.2625167333333],\n",
       "       ['2016-06-30', 2921.712752, 1571.9415, 609.3877583, 453.5597869,\n",
       "        101.1486269, 2440.029736, 616.909056],\n",
       "       ['2016-07-31', 2979.422658, 1553.679082333333, 612.0762081333334,\n",
       "        473.88566743333337, 103.19915363333334, 2475.9393219999997,\n",
       "        608.7162381333333],\n",
       "       ['2016-08-31', 3037.132564, 1535.416664666667, 614.7646579666666,\n",
       "        494.2115479666666, 105.24968036666668, 2511.848908,\n",
       "        600.5234202666667],\n",
       "       ['2016-09-30', 3094.84247, 1517.1542470000004, 617.4531078,\n",
       "        514.5374285, 107.3002071, 2547.758494, 592.3306024],\n",
       "       ['2016-10-31', 2941.914112333333, 1493.7506856666669,\n",
       "        601.3888980666667, 497.1393087333333, 106.27214706666666,\n",
       "        2492.278597666667, 605.3801967666667],\n",
       "       ['2016-11-30', 2788.9857546666667, 1470.347124333333,\n",
       "        585.3246883333334, 479.7411889666667, 105.24408703333332,\n",
       "        2436.798701333333, 618.4297911333333],\n",
       "       ['2016-12-31', 2636.057397, 1446.943563, 569.2604786, 462.3430692,\n",
       "        104.216027, 2381.318805, 631.4793855],\n",
       "       ['2017-01-31', 2629.386708333333, 1421.7832626666666,\n",
       "        553.3237412999999, 463.41115033333335, 105.35134376666666,\n",
       "        2394.287123333333, 669.1150419666667],\n",
       "       ['2017-02-28', 2622.7160196666664, 1396.6229623333334,\n",
       "        537.3870039999998, 464.47923146666665, 106.48666053333334,\n",
       "        2407.2554416666667, 706.7506984333335],\n",
       "       ['2017-03-31', 2616.045331, 1371.462662, 521.4502666999998,\n",
       "        465.5473126, 107.6219773, 2420.2237600000008, 744.3863549],\n",
       "       ['2017-04-30', 2582.999953333333, 1385.6997396666666,\n",
       "        514.2855105000001, 456.63566276666666, 110.51347520000002,\n",
       "        2409.258488666667, 756.4180495333335],\n",
       "       ['2017-05-31', 2549.9545756666666, 1399.9368173333332,\n",
       "        507.12075430000004, 447.72401293333337, 113.4049731,\n",
       "        2398.293217333333, 768.4497441666666],\n",
       "       ['2017-06-30', 2516.909198, 1414.173895, 499.9559981, 438.8123631,\n",
       "        116.296471, 2387.327946, 780.4814388],\n",
       "       ['2017-07-31', 2529.782464, 1411.1019353333334,\n",
       "        495.39090156666674, 419.9090564333334, 113.3286994,\n",
       "        2482.2845416666664, 773.9692328666665],\n",
       "       ['2017-08-31', 2542.65573, 1408.0299756666666, 490.8258050333334,\n",
       "        401.00574976666667, 110.3609278, 2577.241137333333,\n",
       "        767.4570269333334],\n",
       "       ['2017-09-30', 2555.528996, 1404.958016, 486.2607085, 382.1024431,\n",
       "        107.3931562, 2672.197733, 760.944821],\n",
       "       ['2017-10-31', 2493.5604476666667, 1340.4287853333333,\n",
       "        485.59986143333333, 386.4377233, 106.82599553333333,\n",
       "        2640.667416333333, 748.7807167999999],\n",
       "       ['2017-11-30', 2431.591899333333, 1275.8995546666667,\n",
       "        484.9390143666667, 390.7730035, 106.25883486666667,\n",
       "        2609.1370996666665, 736.6166125999998],\n",
       "       ['2017-12-31', 2369.623351, 1211.370324, 484.27816730000006,\n",
       "        395.1082837, 105.6916742, 2577.606783, 724.4525083999998],\n",
       "       ['2018-01-31', 2307.4944116666666, 1212.1657916666666,\n",
       "        479.0572197666667, 392.9066318, 102.59903074333334,\n",
       "        2577.6159756666666, 729.9813198666666],\n",
       "       ['2018-02-28', 2245.365472333333, 1212.9612593333334,\n",
       "        473.83627223333326, 390.7049799, 99.50638728666668,\n",
       "        2577.625168333333, 735.5101313333333],\n",
       "       ['2018-03-31', 2183.236533, 1213.756727, 468.6153247, 388.503328,\n",
       "        96.41374383, 2577.634361, 741.0389428],\n",
       "       ['2018-04-30', 2086.8807423333333, 1146.0012783333334,\n",
       "        448.50893473333326, 390.50832306666666, 98.85220068666668,\n",
       "        2608.0187796666664, 740.6812809333335],\n",
       "       ['2018-05-31', 1990.5249516666665, 1078.2458296666666,\n",
       "        428.40254476666667, 392.51331813333326, 101.29065754333334,\n",
       "        2638.403198333333, 740.3236190666668],\n",
       "       ['2018-06-30', 1894.169161, 1010.490381, 408.2961548, 394.5183132,\n",
       "        103.7291144, 2668.787617, 739.9659572],\n",
       "       ['2018-07-31', 1839.681530666667, 991.3822151, 434.8828281333333,\n",
       "        404.4480508333333, 100.92708618333334, 2732.0093463333333,\n",
       "        736.5653751333334],\n",
       "       ['2018-08-31', 1785.1939003333332, 972.2740492,\n",
       "        461.46950146666666, 414.37778846666674, 98.12505796666667,\n",
       "        2795.231075666666, 733.1647930666667],\n",
       "       ['2018-09-30', 1730.70627, 953.1658833, 488.0561748, 424.3075261,\n",
       "        95.32302975, 2858.452805, 729.764211],\n",
       "       ['2018-10-31', 1667.921494, 856.9003839999998, 471.2615347666666,\n",
       "        434.87458276666666, 92.14422016333332, 2849.606546,\n",
       "        737.7137843333335],\n",
       "       ['2018-11-30', 1605.136718, 760.6348846999998, 454.4668947333333,\n",
       "        445.44163943333336, 88.96541057666668, 2840.760287,\n",
       "        745.6633576666667],\n",
       "       ['2018-12-31', 1542.351942, 664.3693853999998, 437.67225470000005,\n",
       "        456.0086961, 85.78660099, 2831.914028, 753.612931]], dtype=object)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,1:7]\n",
    "Y = dataset[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21536771, 0.34358992, 0.28760773, 1.        , 0.14011453,\n",
       "        0.70628215],\n",
       "       [0.21549004, 0.35192007, 0.32225043, 0.9605532 , 0.13991371,\n",
       "        0.72165108],\n",
       "       [0.21561238, 0.36025022, 0.35689312, 0.92110641, 0.13971289,\n",
       "        0.73702   ],\n",
       "       [0.21573472, 0.36858036, 0.39153581, 0.88165961, 0.13951207,\n",
       "        0.75238893],\n",
       "       [0.21309775, 0.37683871, 0.30995679, 0.58777307, 0.13989088,\n",
       "        0.78331641],\n",
       "       [0.21046078, 0.38509706, 0.22837778, 0.29388654, 0.14026969,\n",
       "        0.8142439 ],\n",
       "       [0.2078238 , 0.3933554 , 0.14679876, 0.        , 0.1406485 ,\n",
       "        0.84517139],\n",
       "       [0.19576386, 0.38652631, 0.09786584, 0.0434695 , 0.14038687,\n",
       "        0.85238924],\n",
       "       [0.18370391, 0.37969722, 0.04893292, 0.086939  , 0.14012524,\n",
       "        0.85960709],\n",
       "       [0.17164397, 0.37286814, 0.        , 0.1304085 , 0.13986361,\n",
       "        0.86682494],\n",
       "       [0.19455526, 0.37922834, 0.05993416, 0.14266337, 0.14557165,\n",
       "        0.90348124],\n",
       "       [0.21746656, 0.38558854, 0.11986831, 0.15491825, 0.15127969,\n",
       "        0.94013755],\n",
       "       [0.24037786, 0.39194874, 0.17980247, 0.16717312, 0.15698773,\n",
       "        0.97679385],\n",
       "       [0.18782438, 0.37456299, 0.15952074, 0.15377192, 0.15607976,\n",
       "        0.96821236],\n",
       "       [0.1352709 , 0.35717725, 0.13923902, 0.14037072, 0.1551718 ,\n",
       "        0.95963086],\n",
       "       [0.08271742, 0.33979151, 0.1189573 , 0.12696952, 0.15426383,\n",
       "        0.95104936],\n",
       "       [0.09769806, 0.30789075, 0.12775618, 0.12639516, 0.15877426,\n",
       "        0.96736624],\n",
       "       [0.11267869, 0.27598999, 0.13655507, 0.1258208 , 0.1632847 ,\n",
       "        0.98368312],\n",
       "       [0.12765932, 0.24408924, 0.14535396, 0.12524645, 0.16779513,\n",
       "        1.        ],\n",
       "       [0.14712547, 0.23240637, 0.17879331, 0.12504798, 0.16343216,\n",
       "        0.99761004],\n",
       "       [0.16659163, 0.2207235 , 0.21223267, 0.12484952, 0.1590692 ,\n",
       "        0.99522007],\n",
       "       [0.18605779, 0.20904063, 0.24567202, 0.12465105, 0.15470623,\n",
       "        0.99283011],\n",
       "       [0.21580723, 0.2124702 , 0.26898377, 0.13899188, 0.14634756,\n",
       "        0.98957627],\n",
       "       [0.24555667, 0.21589978, 0.29229552, 0.1533327 , 0.13798888,\n",
       "        0.98632243],\n",
       "       [0.27530612, 0.21932935, 0.31560727, 0.16767352, 0.1296302 ,\n",
       "        0.98306859],\n",
       "       [0.23174656, 0.21388031, 0.31771115, 0.17102246, 0.12963216,\n",
       "        0.98242773],\n",
       "       [0.18818701, 0.20843127, 0.31981503, 0.1743714 , 0.12963412,\n",
       "        0.98178686],\n",
       "       [0.14462746, 0.20298222, 0.32191891, 0.17772034, 0.12963608,\n",
       "        0.981146  ],\n",
       "       [0.16559061, 0.20759269, 0.37590033, 0.16918408, 0.13588561,\n",
       "        0.96521338],\n",
       "       [0.18655375, 0.21220316, 0.42988176, 0.16064782, 0.14213514,\n",
       "        0.94928075],\n",
       "       [0.2075169 , 0.21681363, 0.48386319, 0.15211155, 0.14838467,\n",
       "        0.93334813],\n",
       "       [0.20632937, 0.24717245, 0.42137913, 0.18968911, 0.14398879,\n",
       "        0.90607485],\n",
       "       [0.20514183, 0.27753127, 0.35889507, 0.22726666, 0.13959291,\n",
       "        0.87880157],\n",
       "       [0.2039543 , 0.30789009, 0.29641102, 0.26484421, 0.13519703,\n",
       "        0.85152829],\n",
       "       [0.20786336, 0.22819714, 0.32575861, 0.27218252, 0.13010266,\n",
       "        0.69883512],\n",
       "       [0.21177242, 0.14850418, 0.3551062 , 0.27952084, 0.12500829,\n",
       "        0.54614194],\n",
       "       [0.21568148, 0.06881122, 0.38445379, 0.28685915, 0.11991392,\n",
       "        0.39344876],\n",
       "       [0.22288331, 0.09770397, 0.42716844, 0.28832255, 0.12230807,\n",
       "        0.42398951],\n",
       "       [0.23008515, 0.12659671, 0.46988309, 0.28978595, 0.12470222,\n",
       "        0.45453025],\n",
       "       [0.23728698, 0.15548945, 0.51259773, 0.29124936, 0.12709637,\n",
       "        0.485071  ],\n",
       "       [0.20492341, 0.1311615 , 0.48510399, 0.2922712 , 0.12651557,\n",
       "        0.48614039],\n",
       "       [0.17255984, 0.10683355, 0.45761024, 0.29329304, 0.12593477,\n",
       "        0.48720978],\n",
       "       [0.14019627, 0.08250559, 0.4301165 , 0.29431489, 0.12535397,\n",
       "        0.48827917],\n",
       "       [0.1424773 , 0.10285422, 0.44797618, 0.28115588, 0.12948101,\n",
       "        0.44754524],\n",
       "       [0.14475833, 0.12320284, 0.46583586, 0.26799687, 0.13360805,\n",
       "        0.40681132],\n",
       "       [0.14703936, 0.14355146, 0.48369555, 0.25483787, 0.13773509,\n",
       "        0.36607739],\n",
       "       [0.15047162, 0.16464487, 0.48776269, 0.26641758, 0.13516539,\n",
       "        0.24555977],\n",
       "       [0.15390388, 0.18573829, 0.49182984, 0.2779973 , 0.13259569,\n",
       "        0.12504215],\n",
       "       [0.15733614, 0.2068317 , 0.49589698, 0.28957702, 0.13002598,\n",
       "        0.00452454],\n",
       "       [0.14472048, 0.21745956, 0.47630548, 0.3036436 , 0.12116525,\n",
       "        0.00301636],\n",
       "       [0.13210482, 0.22808742, 0.45671398, 0.31771019, 0.11230451,\n",
       "        0.00150818],\n",
       "       [0.11948917, 0.23871528, 0.43712248, 0.33177677, 0.10344378,\n",
       "        0.        ],\n",
       "       [0.11305686, 0.2493644 , 0.4036701 , 0.31584481, 0.09560508,\n",
       "        0.00669863],\n",
       "       [0.10662455, 0.26001352, 0.37021773, 0.29991284, 0.08776639,\n",
       "        0.01339726],\n",
       "       [0.10019224, 0.27066264, 0.33676536, 0.28398088, 0.0799277 ,\n",
       "        0.02009588],\n",
       "       [0.11716762, 0.27534652, 0.31046496, 0.28570662, 0.07496154,\n",
       "        0.02583005],\n",
       "       [0.13414299, 0.28003041, 0.28416457, 0.28743236, 0.06999538,\n",
       "        0.03156421],\n",
       "       [0.15111837, 0.2847143 , 0.25786417, 0.2891581 , 0.06502922,\n",
       "        0.03729837],\n",
       "       [0.11509853, 0.33179719, 0.29836928, 0.42623956, 0.06405273,\n",
       "        0.04557007],\n",
       "       [0.07907869, 0.37888008, 0.33887439, 0.56332102, 0.06307623,\n",
       "        0.05384177],\n",
       "       [0.04305886, 0.42596297, 0.3793795 , 0.70040248, 0.06209974,\n",
       "        0.06211347],\n",
       "       [0.12850161, 0.42978373, 0.40598475, 0.70070225, 0.05904764,\n",
       "        0.06930811],\n",
       "       [0.21394436, 0.43360448, 0.43259   , 0.70100203, 0.05599554,\n",
       "        0.07650274],\n",
       "       [0.2993871 , 0.43742523, 0.45919525, 0.70130181, 0.05294344,\n",
       "        0.08369737],\n",
       "       [0.35577117, 0.47608186, 0.46826847, 0.69781819, 0.052095  ,\n",
       "        0.08259275],\n",
       "       [0.41215523, 0.5147385 , 0.47734168, 0.69433458, 0.05124657,\n",
       "        0.08148813],\n",
       "       [0.46853929, 0.55339513, 0.4864149 , 0.69085096, 0.05039813,\n",
       "        0.08038351],\n",
       "       [0.62096219, 0.58363857, 0.59803869, 0.65473261, 0.04965534,\n",
       "        0.08262284],\n",
       "       [0.7733851 , 0.613882  , 0.70966248, 0.61861427, 0.04891254,\n",
       "        0.08486218],\n",
       "       [0.925808  , 0.64412543, 0.82128627, 0.58249592, 0.04816974,\n",
       "        0.08710152],\n",
       "       [0.85725335, 0.66694505, 0.87774568, 0.58278676, 0.03638912,\n",
       "        0.07960687],\n",
       "       [0.78869869, 0.68976468, 0.93420509, 0.58307761, 0.0246085 ,\n",
       "        0.07211223],\n",
       "       [0.72014404, 0.7125843 , 0.9906645 , 0.58336845, 0.01282788,\n",
       "        0.06461758],\n",
       "       [0.81342936, 0.77357499, 0.99377633, 0.5692078 , 0.34188526,\n",
       "        0.12583268],\n",
       "       [0.90671468, 0.83456568, 0.99688817, 0.55504714, 0.67094263,\n",
       "        0.18704778],\n",
       "       [1.        , 0.89555637, 1.        , 0.54088649, 1.        ,\n",
       "        0.24826288],\n",
       "       [0.95619092, 0.93037091, 0.92133861, 0.52386224, 0.67256257,\n",
       "        0.24647661],\n",
       "       [0.91238183, 0.96518546, 0.84267722, 0.50683799, 0.34512515,\n",
       "        0.24469035],\n",
       "       [0.86857275, 1.        , 0.76401584, 0.48981373, 0.01768772,\n",
       "        0.24290409],\n",
       "       [0.90491222, 0.97987772, 0.77356422, 0.52393003, 0.02004869,\n",
       "        0.25724904],\n",
       "       [0.9412517 , 0.95975545, 0.78311261, 0.55804632, 0.02240965,\n",
       "        0.27159399],\n",
       "       [0.97759118, 0.93963317, 0.792661  , 0.59216262, 0.02477061,\n",
       "        0.28593894],\n",
       "       [0.88129339, 0.91384617, 0.73560682, 0.56296047, 0.02358691,\n",
       "        0.26377616],\n",
       "       [0.78499559, 0.88805917, 0.67855264, 0.53375832, 0.02240321,\n",
       "        0.24161338],\n",
       "       [0.6886978 , 0.86227217, 0.62149846, 0.50455617, 0.02121951,\n",
       "        0.21945059],\n",
       "       [0.68449732, 0.83454953, 0.56489702, 0.50634891, 0.0225267 ,\n",
       "        0.2246311 ],\n",
       "       [0.68029684, 0.80682688, 0.50829558, 0.50814165, 0.0238339 ,\n",
       "        0.22981161],\n",
       "       [0.67609636, 0.77910423, 0.45169414, 0.50993438, 0.02514109,\n",
       "        0.23499212],\n",
       "       [0.65528794, 0.79479123, 0.42624755, 0.49497649, 0.02847034,\n",
       "        0.23061177],\n",
       "       [0.63447952, 0.81047822, 0.40080097, 0.48001859, 0.03179959,\n",
       "        0.22623143],\n",
       "       [0.61367111, 0.82616521, 0.37535438, 0.46506069, 0.03512884,\n",
       "        0.22185109],\n",
       "       [0.6217773 , 0.8227804 , 0.35914083, 0.43333214, 0.03171177,\n",
       "        0.25978379],\n",
       "       [0.6298835 , 0.81939559, 0.34292729, 0.40160358, 0.0282947 ,\n",
       "        0.29771649],\n",
       "       [0.63798969, 0.81601078, 0.32671374, 0.36987503, 0.02487763,\n",
       "        0.33564919],\n",
       "       [0.59896858, 0.74490984, 0.32436665, 0.37715165, 0.02422461,\n",
       "        0.32305364],\n",
       "       [0.55994747, 0.6738089 , 0.32201957, 0.38442827, 0.02357158,\n",
       "        0.3104581 ],\n",
       "       [0.52092636, 0.60270796, 0.31967248, 0.39170489, 0.02291856,\n",
       "        0.29786256],\n",
       "       [0.48180425, 0.60358444, 0.30112959, 0.38800949, 0.01935771,\n",
       "        0.29786623],\n",
       "       [0.44268214, 0.60446092, 0.2825867 , 0.38431409, 0.01579686,\n",
       "        0.2978699 ],\n",
       "       [0.40356003, 0.6053374 , 0.26404381, 0.3806187 , 0.01223601,\n",
       "        0.29787357],\n",
       "       [0.34288554, 0.53068168, 0.19263329, 0.38398401, 0.01504364,\n",
       "        0.31001136],\n",
       "       [0.28221105, 0.45602596, 0.12122277, 0.38734933, 0.01785126,\n",
       "        0.32214915],\n",
       "       [0.22153656, 0.38137024, 0.04981225, 0.39071464, 0.02065888,\n",
       "        0.33428694],\n",
       "       [0.18722612, 0.36031608, 0.14423836, 0.40738137, 0.01743264,\n",
       "        0.35954238],\n",
       "       [0.15291569, 0.33926193, 0.23866447, 0.42404809, 0.01420641,\n",
       "        0.38479782],\n",
       "       [0.11860525, 0.31820777, 0.33309058, 0.44071482, 0.01098017,\n",
       "        0.41005326],\n",
       "       [0.07907017, 0.21213851, 0.27344218, 0.45845126, 0.00732012,\n",
       "        0.40651941],\n",
       "       [0.03953508, 0.10606926, 0.21379378, 0.4761877 , 0.00366006,\n",
       "        0.40298556],\n",
       "       [0.        , 0.        , 0.15414538, 0.49392414, 0.        ,\n",
       "        0.39945171]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87, 6) (11, 6) (11, 6) (87,) (11,) (11,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.2)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(6, activation='elu', input_shape=(6,)),\n",
    "    Dense(64, activation='elu'),\n",
    "    Dense(64, activation='elu'),\n",
    "    Dense(64, activation='elu'),\n",
    "    Dense(64, activation='elu'),\n",
    "    Dense(64, activation='elu'),\n",
    "    Dense(64, activation='elu'),\n",
    "    Dense(1, activation='elu'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87 samples, validate on 11 samples\n",
      "Epoch 1/1500\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 438.8143 - val_loss: 152.5198\n",
      "Epoch 2/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 101.0138 - val_loss: 150.4374\n",
      "Epoch 3/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 98.8184 - val_loss: 127.7902\n",
      "Epoch 4/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 86.6569 - val_loss: 114.6184\n",
      "Epoch 5/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 84.5963 - val_loss: 106.5863\n",
      "Epoch 6/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 78.1904 - val_loss: 101.3380\n",
      "Epoch 7/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 71.4647 - val_loss: 83.0783\n",
      "Epoch 8/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 67.7851 - val_loss: 84.7293\n",
      "Epoch 9/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 63.8796 - val_loss: 73.2591\n",
      "Epoch 10/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 65.6452 - val_loss: 75.5046\n",
      "Epoch 11/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 63.9924 - val_loss: 64.0235\n",
      "Epoch 12/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 62.4091 - val_loss: 63.6372\n",
      "Epoch 13/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 58.5612 - val_loss: 72.9266\n",
      "Epoch 14/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 57.9283 - val_loss: 59.8615\n",
      "Epoch 15/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 52.7317 - val_loss: 49.0780\n",
      "Epoch 16/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 55.5057 - val_loss: 49.4779\n",
      "Epoch 17/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 53.9943 - val_loss: 47.8603\n",
      "Epoch 18/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 53.0197 - val_loss: 44.0511\n",
      "Epoch 19/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 52.8225 - val_loss: 42.4707\n",
      "Epoch 20/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 52.7896 - val_loss: 36.9971\n",
      "Epoch 21/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 55.6248 - val_loss: 40.2145\n",
      "Epoch 22/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 49.0564 - val_loss: 52.8129\n",
      "Epoch 23/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 55.1168 - val_loss: 41.5213\n",
      "Epoch 24/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 51.9192 - val_loss: 40.1959\n",
      "Epoch 25/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 51.1086 - val_loss: 53.6586\n",
      "Epoch 26/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 47.5678 - val_loss: 94.5414\n",
      "Epoch 27/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 53.0259 - val_loss: 43.8945\n",
      "Epoch 28/1500\n",
      "87/87 [==============================] - 0s 989us/step - loss: 49.3928 - val_loss: 43.1736\n",
      "Epoch 29/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 49.0836 - val_loss: 33.7772\n",
      "Epoch 30/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 48.8083 - val_loss: 78.1443\n",
      "Epoch 31/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 50.4494 - val_loss: 45.2774\n",
      "Epoch 32/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 51.1306 - val_loss: 31.6325\n",
      "Epoch 33/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 48.6568 - val_loss: 92.8501\n",
      "Epoch 34/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 52.0011 - val_loss: 32.7690\n",
      "Epoch 35/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 48.3080 - val_loss: 54.0186\n",
      "Epoch 36/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 50.2737 - val_loss: 45.8006\n",
      "Epoch 37/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 47.7501 - val_loss: 34.6337\n",
      "Epoch 38/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 47.7307 - val_loss: 42.9244\n",
      "Epoch 39/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 50.5864 - val_loss: 35.5307\n",
      "Epoch 40/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 48.6210 - val_loss: 37.7311\n",
      "Epoch 41/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 46.6116 - val_loss: 90.8889\n",
      "Epoch 42/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 45.6598 - val_loss: 35.7993\n",
      "Epoch 43/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 47.1737 - val_loss: 70.2993\n",
      "Epoch 44/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 46.4888 - val_loss: 49.6788\n",
      "Epoch 45/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 47.1664 - val_loss: 54.7771\n",
      "Epoch 46/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 49.8913 - val_loss: 37.3267\n",
      "Epoch 47/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 47.4743 - val_loss: 34.2631\n",
      "Epoch 48/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 51.2198 - val_loss: 35.0215\n",
      "Epoch 49/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 49.7715 - val_loss: 33.8352\n",
      "Epoch 50/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 44.7328 - val_loss: 27.9615\n",
      "Epoch 51/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 47.1184 - val_loss: 34.6926\n",
      "Epoch 52/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 45.4152 - val_loss: 41.7680\n",
      "Epoch 53/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 46.7281 - val_loss: 32.6211\n",
      "Epoch 54/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 44.2007 - val_loss: 68.7891\n",
      "Epoch 55/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 44.1360 - val_loss: 60.5047\n",
      "Epoch 56/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 42.3229 - val_loss: 41.5047\n",
      "Epoch 57/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 42.8987 - val_loss: 49.3282\n",
      "Epoch 58/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 41.2620 - val_loss: 87.4123\n",
      "Epoch 59/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 43.1100 - val_loss: 36.0447\n",
      "Epoch 60/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 41.2523 - val_loss: 37.3336\n",
      "Epoch 61/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 38.9496 - val_loss: 34.8730\n",
      "Epoch 62/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 39.4241 - val_loss: 34.5584\n",
      "Epoch 63/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 40.3781 - val_loss: 31.2427\n",
      "Epoch 64/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 42.8127 - val_loss: 39.9718\n",
      "Epoch 65/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 37.4466 - val_loss: 38.5801\n",
      "Epoch 66/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 40.9197 - val_loss: 30.2790\n",
      "Epoch 67/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 38.4119 - val_loss: 64.5788\n",
      "Epoch 68/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 40.0262 - val_loss: 58.3737\n",
      "Epoch 69/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 40.8575 - val_loss: 65.6437\n",
      "Epoch 70/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 36.8810 - val_loss: 40.9813\n",
      "Epoch 71/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 38.6140 - val_loss: 28.9139\n",
      "Epoch 72/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 37.2661 - val_loss: 33.3089\n",
      "Epoch 73/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 37.0233 - val_loss: 50.9581\n",
      "Epoch 74/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 35.4204 - val_loss: 50.0659\n",
      "Epoch 75/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 40.3879 - val_loss: 39.5343\n",
      "Epoch 76/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 37.3554 - val_loss: 27.0274\n",
      "Epoch 77/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 33.7212 - val_loss: 97.8388\n",
      "Epoch 78/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 36.6022 - val_loss: 38.4852\n",
      "Epoch 79/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 36.7651 - val_loss: 31.1490\n",
      "Epoch 80/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 34.9401 - val_loss: 37.6853\n",
      "Epoch 81/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 36.3083 - val_loss: 41.9930\n",
      "Epoch 82/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.7057 - val_loss: 55.5232\n",
      "Epoch 83/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 38.0848 - val_loss: 61.2371\n",
      "Epoch 84/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 37.3506 - val_loss: 71.5020\n",
      "Epoch 85/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 34.2325 - val_loss: 36.8859\n",
      "Epoch 86/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 37.0285 - val_loss: 45.5795\n",
      "Epoch 87/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 35.4418 - val_loss: 24.9747\n",
      "Epoch 88/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 34.3577 - val_loss: 27.2371\n",
      "Epoch 89/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 36.0584 - val_loss: 33.3564\n",
      "Epoch 90/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 33.3997 - val_loss: 35.1715\n",
      "Epoch 91/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 35.9173 - val_loss: 54.9412\n",
      "Epoch 92/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.7930 - val_loss: 57.0362\n",
      "Epoch 93/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.4736 - val_loss: 42.5235\n",
      "Epoch 94/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 33.1239 - val_loss: 35.8933\n",
      "Epoch 95/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 36.0707 - val_loss: 35.5913\n",
      "Epoch 96/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 32.3942 - val_loss: 48.6672\n",
      "Epoch 97/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 37.2683 - val_loss: 37.7799\n",
      "Epoch 98/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 36.8795 - val_loss: 59.3555\n",
      "Epoch 99/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 35.8027 - val_loss: 57.0824\n",
      "Epoch 100/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 34.0623 - val_loss: 43.7019\n",
      "Epoch 101/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 36.2347 - val_loss: 61.4894\n",
      "Epoch 102/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 36.9749 - val_loss: 45.4678\n",
      "Epoch 103/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 36.1240 - val_loss: 41.6200\n",
      "Epoch 104/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 35.6997 - val_loss: 31.0114\n",
      "Epoch 105/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.9313 - val_loss: 71.7745\n",
      "Epoch 106/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 36.1272 - val_loss: 50.3270\n",
      "Epoch 107/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 34.1901 - val_loss: 48.2190\n",
      "Epoch 108/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 34.1852 - val_loss: 30.4290\n",
      "Epoch 109/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 34.4699 - val_loss: 29.5553\n",
      "Epoch 110/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 35.4206 - val_loss: 52.4940\n",
      "Epoch 111/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 37.3467 - val_loss: 44.8078\n",
      "Epoch 112/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 36.8856 - val_loss: 39.6623\n",
      "Epoch 113/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.4298 - val_loss: 37.7041\n",
      "Epoch 114/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 33.6457 - val_loss: 23.0469\n",
      "Epoch 115/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.4482 - val_loss: 34.8393\n",
      "Epoch 116/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.5269 - val_loss: 57.3669\n",
      "Epoch 117/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 35.6092 - val_loss: 24.8577\n",
      "Epoch 118/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 34.5455 - val_loss: 50.2060\n",
      "Epoch 119/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 33.4011 - val_loss: 29.7779\n",
      "Epoch 120/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 35.6197 - val_loss: 26.8343\n",
      "Epoch 121/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 34.5048 - val_loss: 41.3077\n",
      "Epoch 122/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 35.6471 - val_loss: 32.9488\n",
      "Epoch 123/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 34.7655 - val_loss: 28.5519\n",
      "Epoch 124/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.3804 - val_loss: 24.7411\n",
      "Epoch 125/1500\n",
      "87/87 [==============================] - 0s 989us/step - loss: 35.2262 - val_loss: 40.1220\n",
      "Epoch 126/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.0329 - val_loss: 52.3364\n",
      "Epoch 127/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 34.4922 - val_loss: 22.4225\n",
      "Epoch 128/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.3426 - val_loss: 36.9299\n",
      "Epoch 129/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 35.1782 - val_loss: 23.3702\n",
      "Epoch 130/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.6863 - val_loss: 30.5331\n",
      "Epoch 131/1500\n",
      "87/87 [==============================] - 0s 989us/step - loss: 32.7294 - val_loss: 30.8834\n",
      "Epoch 132/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.7471 - val_loss: 49.5263\n",
      "Epoch 133/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.3094 - val_loss: 38.7062\n",
      "Epoch 134/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.5101 - val_loss: 27.1543\n",
      "Epoch 135/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 33.0363 - val_loss: 48.7352\n",
      "Epoch 136/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.2333 - val_loss: 32.8272\n",
      "Epoch 137/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 30.6020 - val_loss: 48.1821\n",
      "Epoch 138/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 34.5442 - val_loss: 28.9122\n",
      "Epoch 139/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.6479 - val_loss: 25.4032\n",
      "Epoch 140/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 34.0152 - val_loss: 29.6126\n",
      "Epoch 141/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.6703 - val_loss: 23.7628\n",
      "Epoch 142/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.5915 - val_loss: 31.7598\n",
      "Epoch 143/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.9620 - val_loss: 27.5425\n",
      "Epoch 144/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.1183 - val_loss: 25.2811\n",
      "Epoch 145/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.7098 - val_loss: 34.3473\n",
      "Epoch 146/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.4479 - val_loss: 26.5953\n",
      "Epoch 147/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.2129 - val_loss: 41.5204\n",
      "Epoch 148/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 33.8032 - val_loss: 44.0737\n",
      "Epoch 149/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.5432 - val_loss: 53.4670\n",
      "Epoch 150/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 33.4174 - val_loss: 45.3030\n",
      "Epoch 151/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 33.2962 - val_loss: 49.6504\n",
      "Epoch 152/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.0288 - val_loss: 39.4643\n",
      "Epoch 153/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 33.3227 - val_loss: 36.5760\n",
      "Epoch 154/1500\n",
      "87/87 [==============================] - 0s 989us/step - loss: 32.3908 - val_loss: 20.2527\n",
      "Epoch 155/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.7637 - val_loss: 23.0410\n",
      "Epoch 156/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.1880 - val_loss: 65.3752\n",
      "Epoch 157/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.6334 - val_loss: 37.7204\n",
      "Epoch 158/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 32.3384 - val_loss: 32.5441\n",
      "Epoch 159/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 33.2654 - val_loss: 31.6608\n",
      "Epoch 160/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.2459 - val_loss: 22.6727\n",
      "Epoch 161/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 33.5846 - val_loss: 29.0701\n",
      "Epoch 162/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.8922 - val_loss: 44.5369\n",
      "Epoch 163/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 32.8753 - val_loss: 30.7917\n",
      "Epoch 164/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.3144 - val_loss: 33.1994\n",
      "Epoch 165/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.3808 - val_loss: 26.3529\n",
      "Epoch 166/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.6956 - val_loss: 33.6596\n",
      "Epoch 167/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.7814 - val_loss: 42.3243\n",
      "Epoch 168/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.7714 - val_loss: 53.2768\n",
      "Epoch 169/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.8674 - val_loss: 21.6448\n",
      "Epoch 170/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 33.1816 - val_loss: 22.0619\n",
      "Epoch 171/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.7639 - val_loss: 32.9555\n",
      "Epoch 172/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.7777 - val_loss: 32.1474\n",
      "Epoch 173/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 34.4091 - val_loss: 26.4289\n",
      "Epoch 174/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.2795 - val_loss: 27.0408\n",
      "Epoch 175/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.7974 - val_loss: 44.4656\n",
      "Epoch 176/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 33.3780 - val_loss: 42.1260\n",
      "Epoch 177/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.3095 - val_loss: 36.0343\n",
      "Epoch 178/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.1398 - val_loss: 53.9594\n",
      "Epoch 179/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 33.1431 - val_loss: 22.9314\n",
      "Epoch 180/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.9329 - val_loss: 24.8072\n",
      "Epoch 181/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.9398 - val_loss: 53.4981\n",
      "Epoch 182/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.6303 - val_loss: 22.7040\n",
      "Epoch 183/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.6878 - val_loss: 41.2149\n",
      "Epoch 184/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.9966 - val_loss: 28.4959\n",
      "Epoch 185/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.6782 - val_loss: 37.4604\n",
      "Epoch 186/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 29.7404 - val_loss: 42.0015\n",
      "Epoch 187/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 34.0507 - val_loss: 27.3541\n",
      "Epoch 188/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 30.1700 - val_loss: 30.0288\n",
      "Epoch 189/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.6016 - val_loss: 39.1938\n",
      "Epoch 190/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.3728 - val_loss: 36.8415\n",
      "Epoch 191/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.7684 - val_loss: 59.1007\n",
      "Epoch 192/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.3589 - val_loss: 53.8041\n",
      "Epoch 193/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 34.4021 - val_loss: 26.2378\n",
      "Epoch 194/1500\n",
      "87/87 [==============================] - ETA: 0s - loss: 32.33 - 0s 1ms/step - loss: 32.0093 - val_loss: 29.5930\n",
      "Epoch 195/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.9580 - val_loss: 32.4197\n",
      "Epoch 196/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 31.0804 - val_loss: 30.6850\n",
      "Epoch 197/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.0929 - val_loss: 56.9052\n",
      "Epoch 198/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.0984 - val_loss: 24.4117\n",
      "Epoch 199/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.9789 - val_loss: 38.5218\n",
      "Epoch 200/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 31.1360 - val_loss: 43.5722\n",
      "Epoch 201/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 33.4476 - val_loss: 30.9495\n",
      "Epoch 202/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 32.9356 - val_loss: 21.5501\n",
      "Epoch 203/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.1809 - val_loss: 25.9876\n",
      "Epoch 204/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 33.5211 - val_loss: 37.5087\n",
      "Epoch 205/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.7880 - val_loss: 27.9005\n",
      "Epoch 206/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.7247 - val_loss: 31.6716\n",
      "Epoch 207/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.0023 - val_loss: 22.7745\n",
      "Epoch 208/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 32.5178 - val_loss: 23.6265\n",
      "Epoch 209/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.2744 - val_loss: 33.4473\n",
      "Epoch 210/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 29.3550 - val_loss: 24.4126\n",
      "Epoch 211/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.0340 - val_loss: 54.8049\n",
      "Epoch 212/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.8521 - val_loss: 23.5113\n",
      "Epoch 213/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.3952 - val_loss: 23.3233\n",
      "Epoch 214/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.9092 - val_loss: 29.3184\n",
      "Epoch 215/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.2547 - val_loss: 35.7428\n",
      "Epoch 216/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.1106 - val_loss: 42.6254\n",
      "Epoch 217/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.4012 - val_loss: 34.2417\n",
      "Epoch 218/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.9874 - val_loss: 54.8177\n",
      "Epoch 219/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.8696 - val_loss: 22.2166\n",
      "Epoch 220/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.1485 - val_loss: 23.1328\n",
      "Epoch 221/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.7825 - val_loss: 47.8395\n",
      "Epoch 222/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.1787 - val_loss: 33.9498\n",
      "Epoch 223/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.1123 - val_loss: 33.2773\n",
      "Epoch 224/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.7357 - val_loss: 42.4989\n",
      "Epoch 225/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.6712 - val_loss: 27.8657\n",
      "Epoch 226/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 27.8124 - val_loss: 35.0854\n",
      "Epoch 227/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.1021 - val_loss: 25.5156\n",
      "Epoch 228/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.6219 - val_loss: 26.9460\n",
      "Epoch 229/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.0323 - val_loss: 40.4582\n",
      "Epoch 230/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.4277 - val_loss: 31.2401\n",
      "Epoch 231/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.1372 - val_loss: 21.4428\n",
      "Epoch 232/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.3108 - val_loss: 22.4706\n",
      "Epoch 233/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.2668 - val_loss: 42.4178\n",
      "Epoch 234/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.7633 - val_loss: 44.7238\n",
      "Epoch 235/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.6688 - val_loss: 33.5586\n",
      "Epoch 236/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 32.5188 - val_loss: 38.0566\n",
      "Epoch 237/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.7044 - val_loss: 36.1884\n",
      "Epoch 238/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.3321 - val_loss: 19.6533\n",
      "Epoch 239/1500\n",
      "87/87 [==============================] - 0s 965us/step - loss: 29.4382 - val_loss: 25.2752\n",
      "Epoch 240/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.6961 - val_loss: 25.9178\n",
      "Epoch 241/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 28.1185 - val_loss: 34.4719\n",
      "Epoch 242/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 29.0609 - val_loss: 25.4846\n",
      "Epoch 243/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 30.1680 - val_loss: 27.5000\n",
      "Epoch 244/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.9397 - val_loss: 31.6818\n",
      "Epoch 245/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 28.5256 - val_loss: 27.2894\n",
      "Epoch 246/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.3062 - val_loss: 21.8911\n",
      "Epoch 247/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 27.9825 - val_loss: 23.4888\n",
      "Epoch 248/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.2480 - val_loss: 45.8436\n",
      "Epoch 249/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.1826 - val_loss: 41.4329\n",
      "Epoch 250/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.8385 - val_loss: 32.5735\n",
      "Epoch 251/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.7737 - val_loss: 43.4757\n",
      "Epoch 252/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.3298 - val_loss: 31.6268\n",
      "Epoch 253/1500\n",
      "87/87 [==============================] - 0s 965us/step - loss: 29.7883 - val_loss: 35.3437\n",
      "Epoch 254/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.2311 - val_loss: 30.5567\n",
      "Epoch 255/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.1375 - val_loss: 22.2071\n",
      "Epoch 256/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 28.3687 - val_loss: 23.2175\n",
      "Epoch 257/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.1846 - val_loss: 47.7254\n",
      "Epoch 258/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.5374 - val_loss: 48.2681\n",
      "Epoch 259/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 29.1271 - val_loss: 22.3601\n",
      "Epoch 260/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 28.9491 - val_loss: 28.1599\n",
      "Epoch 261/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.3621 - val_loss: 37.0360\n",
      "Epoch 262/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 27.3939 - val_loss: 48.0903\n",
      "Epoch 263/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 30.8458 - val_loss: 29.5337\n",
      "Epoch 264/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 29.7124 - val_loss: 54.1280\n",
      "Epoch 265/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.1487 - val_loss: 28.0219\n",
      "Epoch 266/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 28.2533 - val_loss: 33.2918\n",
      "Epoch 267/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.1301 - val_loss: 28.7874\n",
      "Epoch 268/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.5802 - val_loss: 21.6422\n",
      "Epoch 269/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.8981 - val_loss: 30.6542\n",
      "Epoch 270/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.2450 - val_loss: 25.3923\n",
      "Epoch 271/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.7760 - val_loss: 87.7820\n",
      "Epoch 272/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 31.9319 - val_loss: 18.0497\n",
      "Epoch 273/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.7584 - val_loss: 19.0030\n",
      "Epoch 274/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.3315 - val_loss: 24.4900\n",
      "Epoch 275/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.8479 - val_loss: 38.7504\n",
      "Epoch 276/1500\n",
      "87/87 [==============================] - 0s 986us/step - loss: 28.3821 - val_loss: 32.8095\n",
      "Epoch 277/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.8453 - val_loss: 25.2078\n",
      "Epoch 278/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.0034 - val_loss: 43.8199\n",
      "Epoch 279/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.9680 - val_loss: 39.5838\n",
      "Epoch 280/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.8139 - val_loss: 30.5536\n",
      "Epoch 281/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.6227 - val_loss: 27.1466\n",
      "Epoch 282/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.3865 - val_loss: 39.2871\n",
      "Epoch 283/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.6445 - val_loss: 37.5863\n",
      "Epoch 284/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.7240 - val_loss: 32.5704\n",
      "Epoch 285/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 28.9170 - val_loss: 39.1317\n",
      "Epoch 286/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.6979 - val_loss: 48.3097\n",
      "Epoch 287/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.6273 - val_loss: 30.7975\n",
      "Epoch 288/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.0765 - val_loss: 30.7437\n",
      "Epoch 289/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.0044 - val_loss: 23.8130\n",
      "Epoch 290/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.2340 - val_loss: 20.2550\n",
      "Epoch 291/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.3315 - val_loss: 24.5677\n",
      "Epoch 292/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.8550 - val_loss: 31.5139\n",
      "Epoch 293/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.2846 - val_loss: 36.6758\n",
      "Epoch 294/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.0176 - val_loss: 45.7939\n",
      "Epoch 295/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.2954 - val_loss: 33.9836\n",
      "Epoch 296/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.3647 - val_loss: 46.2188\n",
      "Epoch 297/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 30.0073 - val_loss: 39.3738\n",
      "Epoch 298/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.5134 - val_loss: 19.6152\n",
      "Epoch 299/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.3739 - val_loss: 26.4229\n",
      "Epoch 300/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.9149 - val_loss: 25.5444\n",
      "Epoch 301/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.0047 - val_loss: 44.7530\n",
      "Epoch 302/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.9336 - val_loss: 25.1445\n",
      "Epoch 303/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 27.2220 - val_loss: 36.8239\n",
      "Epoch 304/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.7337 - val_loss: 28.3412\n",
      "Epoch 305/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.6869 - val_loss: 21.1406\n",
      "Epoch 306/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.6703 - val_loss: 36.1686\n",
      "Epoch 307/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.9210 - val_loss: 64.7254\n",
      "Epoch 308/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.0079 - val_loss: 39.8795\n",
      "Epoch 309/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 27.0220 - val_loss: 54.5729\n",
      "Epoch 310/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.7137 - val_loss: 25.5967\n",
      "Epoch 311/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.0401 - val_loss: 29.6396\n",
      "Epoch 312/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.9999 - val_loss: 21.4693\n",
      "Epoch 313/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.6425 - val_loss: 28.6642\n",
      "Epoch 314/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 28.2976 - val_loss: 29.8579\n",
      "Epoch 315/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.0011 - val_loss: 27.4767\n",
      "Epoch 316/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.7230 - val_loss: 31.0718\n",
      "Epoch 317/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.3470 - val_loss: 40.5466\n",
      "Epoch 318/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.3813 - val_loss: 42.2218\n",
      "Epoch 319/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.8283 - val_loss: 22.1535\n",
      "Epoch 320/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.7832 - val_loss: 27.4760\n",
      "Epoch 321/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.3611 - val_loss: 41.4511\n",
      "Epoch 322/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.5135 - val_loss: 21.0505\n",
      "Epoch 323/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.5228 - val_loss: 36.4502\n",
      "Epoch 324/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.4842 - val_loss: 52.1605\n",
      "Epoch 325/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 27.2086 - val_loss: 28.8577\n",
      "Epoch 326/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.5583 - val_loss: 21.7213\n",
      "Epoch 327/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.8794 - val_loss: 31.6993\n",
      "Epoch 328/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.8745 - val_loss: 30.9518\n",
      "Epoch 329/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.9509 - val_loss: 25.4702\n",
      "Epoch 330/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.3188 - val_loss: 28.5397\n",
      "Epoch 331/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 26.0764 - val_loss: 23.7834\n",
      "Epoch 332/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.7525 - val_loss: 33.0542\n",
      "Epoch 333/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.6349 - val_loss: 33.9098\n",
      "Epoch 334/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.3548 - val_loss: 22.2177\n",
      "Epoch 335/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.2897 - val_loss: 20.6064\n",
      "Epoch 336/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.2212 - val_loss: 26.2339\n",
      "Epoch 337/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 29.2151 - val_loss: 25.5138\n",
      "Epoch 338/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.9118 - val_loss: 23.8508\n",
      "Epoch 339/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 28.7574 - val_loss: 23.8830\n",
      "Epoch 340/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.6613 - val_loss: 30.4317\n",
      "Epoch 341/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.7091 - val_loss: 34.9850\n",
      "Epoch 342/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 25.9594 - val_loss: 37.9411\n",
      "Epoch 343/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.1395 - val_loss: 20.6109\n",
      "Epoch 344/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.6626 - val_loss: 34.5798\n",
      "Epoch 345/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 26.0160 - val_loss: 34.8757\n",
      "Epoch 346/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.9790 - val_loss: 25.8970\n",
      "Epoch 347/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.9273 - val_loss: 54.9782\n",
      "Epoch 348/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.8638 - val_loss: 22.6149\n",
      "Epoch 349/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.5097 - val_loss: 19.6946\n",
      "Epoch 350/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.0616 - val_loss: 22.5645\n",
      "Epoch 351/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 23.4694 - val_loss: 30.8814\n",
      "Epoch 352/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.7872 - val_loss: 18.3281\n",
      "Epoch 353/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 24.3772 - val_loss: 46.0640\n",
      "Epoch 354/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.5227 - val_loss: 22.2408\n",
      "Epoch 355/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.8601 - val_loss: 56.9905\n",
      "Epoch 356/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.4236 - val_loss: 33.0390\n",
      "Epoch 357/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 28.6267 - val_loss: 23.5850\n",
      "Epoch 358/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.1254 - val_loss: 29.3803\n",
      "Epoch 359/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.3287 - val_loss: 19.1330\n",
      "Epoch 360/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.5310 - val_loss: 28.9104\n",
      "Epoch 361/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.0776 - val_loss: 18.1715\n",
      "Epoch 362/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.2644 - val_loss: 20.8109\n",
      "Epoch 363/1500\n",
      "87/87 [==============================] - 0s 965us/step - loss: 24.5758 - val_loss: 46.7947\n",
      "Epoch 364/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.9237 - val_loss: 30.7982\n",
      "Epoch 365/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.1255 - val_loss: 22.6097\n",
      "Epoch 366/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.5859 - val_loss: 27.4406\n",
      "Epoch 367/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.5308 - val_loss: 34.2333\n",
      "Epoch 368/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.8186 - val_loss: 27.2307\n",
      "Epoch 369/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.2069 - val_loss: 20.1396\n",
      "Epoch 370/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.9741 - val_loss: 21.8788\n",
      "Epoch 371/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 24.5449 - val_loss: 17.3706\n",
      "Epoch 372/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.4584 - val_loss: 26.3278\n",
      "Epoch 373/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 26.3780 - val_loss: 21.2458\n",
      "Epoch 374/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 25.9064 - val_loss: 23.4999\n",
      "Epoch 375/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.3063 - val_loss: 21.3671\n",
      "Epoch 376/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.2447 - val_loss: 20.8589\n",
      "Epoch 377/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.9822 - val_loss: 32.1110\n",
      "Epoch 378/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.5024 - val_loss: 26.9869\n",
      "Epoch 379/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.0098 - val_loss: 28.2776\n",
      "Epoch 380/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.0549 - val_loss: 17.4828\n",
      "Epoch 381/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.3428 - val_loss: 20.0496\n",
      "Epoch 382/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 25.8263 - val_loss: 18.3224\n",
      "Epoch 383/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.2938 - val_loss: 26.8806\n",
      "Epoch 384/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.9278 - val_loss: 32.5520\n",
      "Epoch 385/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.0948 - val_loss: 30.1803\n",
      "Epoch 386/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.5401 - val_loss: 26.1356\n",
      "Epoch 387/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.0965 - val_loss: 36.3733\n",
      "Epoch 388/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.0709 - val_loss: 21.4136\n",
      "Epoch 389/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.3858 - val_loss: 29.7037\n",
      "Epoch 390/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.9370 - val_loss: 25.2688\n",
      "Epoch 391/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 25.9813 - val_loss: 22.3377\n",
      "Epoch 392/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 25.4398 - val_loss: 16.9864\n",
      "Epoch 393/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.5923 - val_loss: 27.5864\n",
      "Epoch 394/1500\n",
      "87/87 [==============================] - 0s 989us/step - loss: 24.9175 - val_loss: 34.7122\n",
      "Epoch 395/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 25.3611 - val_loss: 22.0093\n",
      "Epoch 396/1500\n",
      "87/87 [==============================] - ETA: 0s - loss: 25.09 - 0s 1ms/step - loss: 23.7665 - val_loss: 29.9248\n",
      "Epoch 397/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 27.3015 - val_loss: 28.8628\n",
      "Epoch 398/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.7166 - val_loss: 13.4956\n",
      "Epoch 399/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.6255 - val_loss: 25.8087\n",
      "Epoch 400/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 24.1310 - val_loss: 20.6102\n",
      "Epoch 401/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.1116 - val_loss: 34.1576\n",
      "Epoch 402/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.3961 - val_loss: 37.8016\n",
      "Epoch 403/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 27.0892 - val_loss: 27.4091\n",
      "Epoch 404/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.4140 - val_loss: 33.3266\n",
      "Epoch 405/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.7377 - val_loss: 24.9001\n",
      "Epoch 406/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.3835 - val_loss: 27.5834\n",
      "Epoch 407/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.8388 - val_loss: 21.8308\n",
      "Epoch 408/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.5013 - val_loss: 24.0543\n",
      "Epoch 409/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.6374 - val_loss: 20.2469\n",
      "Epoch 410/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.0289 - val_loss: 29.2709\n",
      "Epoch 411/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.9618 - val_loss: 16.9764\n",
      "Epoch 412/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.8961 - val_loss: 47.1443\n",
      "Epoch 413/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.5087 - val_loss: 35.6146\n",
      "Epoch 414/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.5592 - val_loss: 36.1678\n",
      "Epoch 415/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.3935 - val_loss: 21.4442\n",
      "Epoch 416/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 22.9283 - val_loss: 19.0445\n",
      "Epoch 417/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.2872 - val_loss: 26.3287\n",
      "Epoch 418/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 22.5712 - val_loss: 31.2468\n",
      "Epoch 419/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.0595 - val_loss: 17.7428\n",
      "Epoch 420/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.5772 - val_loss: 16.9894\n",
      "Epoch 421/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.8761 - val_loss: 20.8503\n",
      "Epoch 422/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.6687 - val_loss: 23.0886\n",
      "Epoch 423/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 23.0985 - val_loss: 35.5949\n",
      "Epoch 424/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 26.0303 - val_loss: 24.9385\n",
      "Epoch 425/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.3286 - val_loss: 21.0233\n",
      "Epoch 426/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 21.2584 - val_loss: 18.8224\n",
      "Epoch 427/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.9959 - val_loss: 31.7671\n",
      "Epoch 428/1500\n",
      "87/87 [==============================] - ETA: 0s - loss: 27.48 - 0s 1ms/step - loss: 26.0540 - val_loss: 22.4386\n",
      "Epoch 429/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.9569 - val_loss: 41.8641\n",
      "Epoch 430/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.2189 - val_loss: 25.5046\n",
      "Epoch 431/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.6518 - val_loss: 33.6191\n",
      "Epoch 432/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.2748 - val_loss: 18.7353\n",
      "Epoch 433/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.6389 - val_loss: 23.7649\n",
      "Epoch 434/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.4249 - val_loss: 18.3780\n",
      "Epoch 435/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.5430 - val_loss: 35.5026\n",
      "Epoch 436/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.5133 - val_loss: 16.7047\n",
      "Epoch 437/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.9531 - val_loss: 19.9005\n",
      "Epoch 438/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 22.7991 - val_loss: 21.2038\n",
      "Epoch 439/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 21.4409 - val_loss: 27.8317\n",
      "Epoch 440/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 25.3208 - val_loss: 38.9708\n",
      "Epoch 441/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 24.7571 - val_loss: 27.6530\n",
      "Epoch 442/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.3804 - val_loss: 30.2705\n",
      "Epoch 443/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.7742 - val_loss: 21.2956\n",
      "Epoch 444/1500\n",
      "87/87 [==============================] - 0s 942us/step - loss: 23.7249 - val_loss: 25.1920\n",
      "Epoch 445/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.6540 - val_loss: 34.2128\n",
      "Epoch 446/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.7016 - val_loss: 25.5425\n",
      "Epoch 447/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 21.5889 - val_loss: 40.5916\n",
      "Epoch 448/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 22.2038 - val_loss: 23.9889\n",
      "Epoch 449/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 21.5685 - val_loss: 16.7690\n",
      "Epoch 450/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 21.8173 - val_loss: 33.2671\n",
      "Epoch 451/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.0947 - val_loss: 39.6005\n",
      "Epoch 452/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.0587 - val_loss: 27.0465\n",
      "Epoch 453/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.6319 - val_loss: 20.8213\n",
      "Epoch 454/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.9747 - val_loss: 21.2564\n",
      "Epoch 455/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.9947 - val_loss: 30.0137\n",
      "Epoch 456/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 22.6150 - val_loss: 21.2875\n",
      "Epoch 457/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.4785 - val_loss: 22.9553\n",
      "Epoch 458/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 20.4724 - val_loss: 19.8106\n",
      "Epoch 459/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 22.3659 - val_loss: 27.6497\n",
      "Epoch 460/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 21.9146 - val_loss: 18.9159\n",
      "Epoch 461/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 22.2678 - val_loss: 23.2389\n",
      "Epoch 462/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.5233 - val_loss: 30.3415\n",
      "Epoch 463/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 19.9884 - val_loss: 43.6735\n",
      "Epoch 464/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.4254 - val_loss: 13.7825\n",
      "Epoch 465/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.8851 - val_loss: 26.3269\n",
      "Epoch 466/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 21.2717 - val_loss: 38.8733\n",
      "Epoch 467/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 22.5676 - val_loss: 46.2870\n",
      "Epoch 468/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 24.4656 - val_loss: 24.0244\n",
      "Epoch 469/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 22.9977 - val_loss: 57.6701\n",
      "Epoch 470/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 23.9195 - val_loss: 22.3304\n",
      "Epoch 471/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 22.5311 - val_loss: 15.8339\n",
      "Epoch 472/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 20.3789 - val_loss: 16.0042\n",
      "Epoch 473/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 21.9696 - val_loss: 26.1621\n",
      "Epoch 474/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 22.4270 - val_loss: 19.4265\n",
      "Epoch 475/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 21.0771 - val_loss: 19.4763\n",
      "Epoch 476/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 20.8193 - val_loss: 23.7767\n",
      "Epoch 477/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 21.6728 - val_loss: 34.8029\n",
      "Epoch 478/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 22.3676 - val_loss: 24.4849\n",
      "Epoch 479/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 20.9704 - val_loss: 25.6187\n",
      "Epoch 480/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.6459 - val_loss: 21.4231\n",
      "Epoch 481/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 21.5629 - val_loss: 19.7245\n",
      "Epoch 482/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 21.1843 - val_loss: 19.7556\n",
      "Epoch 483/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 22.4935 - val_loss: 21.5357\n",
      "Epoch 484/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 20.9218 - val_loss: 24.5556\n",
      "Epoch 485/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 20.0926 - val_loss: 39.5432\n",
      "Epoch 486/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 21.3005 - val_loss: 29.5992\n",
      "Epoch 487/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 21.4838 - val_loss: 50.9828\n",
      "Epoch 488/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 22.4965 - val_loss: 20.9836\n",
      "Epoch 489/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 21.5147 - val_loss: 17.0207\n",
      "Epoch 490/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 19.5112 - val_loss: 32.7367\n",
      "Epoch 491/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 19.5471 - val_loss: 28.0843\n",
      "Epoch 492/1500\n",
      "87/87 [==============================] - 0s 989us/step - loss: 22.0137 - val_loss: 23.6199\n",
      "Epoch 493/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.7425 - val_loss: 20.2276\n",
      "Epoch 494/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 19.0373 - val_loss: 20.4160\n",
      "Epoch 495/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 23.1267 - val_loss: 21.8101\n",
      "Epoch 496/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.8426 - val_loss: 29.2074\n",
      "Epoch 497/1500\n",
      "87/87 [==============================] - ETA: 0s - loss: 23.04 - 0s 988us/step - loss: 20.7664 - val_loss: 16.2735\n",
      "Epoch 498/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.9265 - val_loss: 16.4252\n",
      "Epoch 499/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 21.0931 - val_loss: 24.0042\n",
      "Epoch 500/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 20.9582 - val_loss: 40.2064\n",
      "Epoch 501/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.7946 - val_loss: 22.6697\n",
      "Epoch 502/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.6964 - val_loss: 21.0973\n",
      "Epoch 503/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 19.7892 - val_loss: 29.4953\n",
      "Epoch 504/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 19.8968 - val_loss: 19.5958\n",
      "Epoch 505/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.9977 - val_loss: 17.2262\n",
      "Epoch 506/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 20.3919 - val_loss: 22.6202\n",
      "Epoch 507/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 19.7095 - val_loss: 27.8286\n",
      "Epoch 508/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.8780 - val_loss: 33.5372\n",
      "Epoch 509/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 21.3131 - val_loss: 29.3643\n",
      "Epoch 510/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 20.2959 - val_loss: 29.2934\n",
      "Epoch 511/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.6289 - val_loss: 22.4882\n",
      "Epoch 512/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 17.2608 - val_loss: 20.8810\n",
      "Epoch 513/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.8577 - val_loss: 22.3743\n",
      "Epoch 514/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 19.5897 - val_loss: 17.0153\n",
      "Epoch 515/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.2940 - val_loss: 35.9189\n",
      "Epoch 516/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 20.0684 - val_loss: 22.9060\n",
      "Epoch 517/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 19.1418 - val_loss: 28.8083\n",
      "Epoch 518/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 19.3129 - val_loss: 20.5493\n",
      "Epoch 519/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 19.7740 - val_loss: 17.4009\n",
      "Epoch 520/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.5865 - val_loss: 15.2690\n",
      "Epoch 521/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 19.6392 - val_loss: 15.6738\n",
      "Epoch 522/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 19.7219 - val_loss: 20.6469\n",
      "Epoch 523/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.0798 - val_loss: 35.5511\n",
      "Epoch 524/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.2503 - val_loss: 25.1808\n",
      "Epoch 525/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.0370 - val_loss: 17.1517\n",
      "Epoch 526/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.1366 - val_loss: 20.0855\n",
      "Epoch 527/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.5729 - val_loss: 26.4471\n",
      "Epoch 528/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.6073 - val_loss: 17.1692\n",
      "Epoch 529/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.4890 - val_loss: 15.1181\n",
      "Epoch 530/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.1329 - val_loss: 23.6730\n",
      "Epoch 531/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.4788 - val_loss: 32.1772\n",
      "Epoch 532/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 18.5618 - val_loss: 22.2627\n",
      "Epoch 533/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.6384 - val_loss: 15.5844\n",
      "Epoch 534/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.9742 - val_loss: 22.4248\n",
      "Epoch 535/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 19.2803 - val_loss: 27.3634\n",
      "Epoch 536/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.4451 - val_loss: 25.2020\n",
      "Epoch 537/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.1044 - val_loss: 19.5220\n",
      "Epoch 538/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.2926 - val_loss: 14.1128\n",
      "Epoch 539/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.6509 - val_loss: 14.9280\n",
      "Epoch 540/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.2987 - val_loss: 22.4032\n",
      "Epoch 541/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.5051 - val_loss: 17.6001\n",
      "Epoch 542/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 16.8198 - val_loss: 18.8841\n",
      "Epoch 543/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.5397 - val_loss: 32.1259\n",
      "Epoch 544/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.8530 - val_loss: 25.3781\n",
      "Epoch 545/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.2970 - val_loss: 27.6509\n",
      "Epoch 546/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.8645 - val_loss: 20.1706\n",
      "Epoch 547/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.7561 - val_loss: 25.5563\n",
      "Epoch 548/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 19.3958 - val_loss: 20.0590\n",
      "Epoch 549/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.7396 - val_loss: 16.8724\n",
      "Epoch 550/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 17.2942 - val_loss: 19.3288\n",
      "Epoch 551/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.3484 - val_loss: 19.4965\n",
      "Epoch 552/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.2944 - val_loss: 15.9653\n",
      "Epoch 553/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.9834 - val_loss: 15.4580\n",
      "Epoch 554/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.7896 - val_loss: 18.8315\n",
      "Epoch 555/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.3283 - val_loss: 30.5337\n",
      "Epoch 556/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.4743 - val_loss: 23.9386\n",
      "Epoch 557/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.7325 - val_loss: 23.8550\n",
      "Epoch 558/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.2911 - val_loss: 31.4139\n",
      "Epoch 559/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.1054 - val_loss: 38.6334\n",
      "Epoch 560/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 18.6371 - val_loss: 21.9387\n",
      "Epoch 561/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.1350 - val_loss: 41.3702\n",
      "Epoch 562/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.4872 - val_loss: 18.3727\n",
      "Epoch 563/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 17.0699 - val_loss: 21.6977\n",
      "Epoch 564/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.6605 - val_loss: 13.8211\n",
      "Epoch 565/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.8399 - val_loss: 28.5786\n",
      "Epoch 566/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.3994 - val_loss: 26.0092\n",
      "Epoch 567/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.0425 - val_loss: 21.7790\n",
      "Epoch 568/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.6088 - val_loss: 22.0486\n",
      "Epoch 569/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.0083 - val_loss: 28.4306\n",
      "Epoch 570/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.2620 - val_loss: 14.4757\n",
      "Epoch 571/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.2609 - val_loss: 17.6537\n",
      "Epoch 572/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.4994 - val_loss: 34.9738\n",
      "Epoch 573/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.3566 - val_loss: 16.4306\n",
      "Epoch 574/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.3005 - val_loss: 15.8388\n",
      "Epoch 575/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.7150 - val_loss: 24.8321\n",
      "Epoch 576/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.7800 - val_loss: 18.5786\n",
      "Epoch 577/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.2854 - val_loss: 23.7808\n",
      "Epoch 578/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.0622 - val_loss: 33.7341\n",
      "Epoch 579/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.2190 - val_loss: 24.2915\n",
      "Epoch 580/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.4324 - val_loss: 34.4064\n",
      "Epoch 581/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 17.5231 - val_loss: 27.4074\n",
      "Epoch 582/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.3401 - val_loss: 19.4563\n",
      "Epoch 583/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.8566 - val_loss: 24.7521\n",
      "Epoch 584/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.6211 - val_loss: 38.8338\n",
      "Epoch 585/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.2483 - val_loss: 16.7262\n",
      "Epoch 586/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.3106 - val_loss: 26.7818\n",
      "Epoch 587/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.7699 - val_loss: 22.7957\n",
      "Epoch 588/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.5151 - val_loss: 21.4265\n",
      "Epoch 589/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.7450 - val_loss: 31.3518\n",
      "Epoch 590/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.0015 - val_loss: 21.4112\n",
      "Epoch 591/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 16.0966 - val_loss: 18.3046\n",
      "Epoch 592/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.9874 - val_loss: 20.8591\n",
      "Epoch 593/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.2373 - val_loss: 19.4202\n",
      "Epoch 594/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 16.1696 - val_loss: 20.8201\n",
      "Epoch 595/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.3722 - val_loss: 24.4142\n",
      "Epoch 596/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.0088 - val_loss: 28.3835\n",
      "Epoch 597/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.8593 - val_loss: 22.6631\n",
      "Epoch 598/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.4719 - val_loss: 20.6916\n",
      "Epoch 599/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.5697 - val_loss: 19.8130\n",
      "Epoch 600/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.8941 - val_loss: 22.0117\n",
      "Epoch 601/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.9797 - val_loss: 19.6133\n",
      "Epoch 602/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.1362 - val_loss: 21.0200\n",
      "Epoch 603/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.1552 - val_loss: 25.1423\n",
      "Epoch 604/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 15.8015 - val_loss: 29.4543\n",
      "Epoch 605/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.9937 - val_loss: 24.7144\n",
      "Epoch 606/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.4232 - val_loss: 23.5003\n",
      "Epoch 607/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.3188 - val_loss: 17.3875\n",
      "Epoch 608/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.5859 - val_loss: 19.6180\n",
      "Epoch 609/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 18.0760 - val_loss: 23.9255\n",
      "Epoch 610/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.5883 - val_loss: 21.8441\n",
      "Epoch 611/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.4550 - val_loss: 32.9809\n",
      "Epoch 612/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.3373 - val_loss: 13.7631\n",
      "Epoch 613/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.2565 - val_loss: 34.9664\n",
      "Epoch 614/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.3323 - val_loss: 24.6284\n",
      "Epoch 615/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 17.8640 - val_loss: 15.8586\n",
      "Epoch 616/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.1795 - val_loss: 18.9733\n",
      "Epoch 617/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.8874 - val_loss: 15.9379\n",
      "Epoch 618/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.8474 - val_loss: 19.4371\n",
      "Epoch 619/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.0040 - val_loss: 38.3197\n",
      "Epoch 620/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.1356 - val_loss: 25.3209\n",
      "Epoch 621/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.8654 - val_loss: 14.4286\n",
      "Epoch 622/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.1251 - val_loss: 25.0452\n",
      "Epoch 623/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.3217 - val_loss: 27.8815\n",
      "Epoch 624/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.7917 - val_loss: 16.9164\n",
      "Epoch 625/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.9941 - val_loss: 18.2340\n",
      "Epoch 626/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 16.4668 - val_loss: 33.0723\n",
      "Epoch 627/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.4045 - val_loss: 15.4372\n",
      "Epoch 628/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.6774 - val_loss: 31.1314\n",
      "Epoch 629/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.8105 - val_loss: 17.9733\n",
      "Epoch 630/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.8659 - val_loss: 14.8996\n",
      "Epoch 631/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.2924 - val_loss: 13.6544\n",
      "Epoch 632/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 16.0012 - val_loss: 16.9915\n",
      "Epoch 633/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.4097 - val_loss: 15.6238\n",
      "Epoch 634/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.2170 - val_loss: 22.2047\n",
      "Epoch 635/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.6238 - val_loss: 15.4564\n",
      "Epoch 636/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.7036 - val_loss: 13.5674\n",
      "Epoch 637/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.2527 - val_loss: 21.3368\n",
      "Epoch 638/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.5032 - val_loss: 32.6215\n",
      "Epoch 639/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.9431 - val_loss: 16.8138\n",
      "Epoch 640/1500\n",
      "87/87 [==============================] - 0s 989us/step - loss: 15.4919 - val_loss: 16.9512\n",
      "Epoch 641/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.4019 - val_loss: 20.6974\n",
      "Epoch 642/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.4447 - val_loss: 15.1956\n",
      "Epoch 643/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.1205 - val_loss: 30.9551\n",
      "Epoch 644/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.7413 - val_loss: 18.3812\n",
      "Epoch 645/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.0060 - val_loss: 23.2998\n",
      "Epoch 646/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.9578 - val_loss: 21.7411\n",
      "Epoch 647/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.4351 - val_loss: 22.3310\n",
      "Epoch 648/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.6198 - val_loss: 21.1486\n",
      "Epoch 649/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.3640 - val_loss: 24.1237\n",
      "Epoch 650/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.1293 - val_loss: 16.9000\n",
      "Epoch 651/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 15.5535 - val_loss: 20.1007\n",
      "Epoch 652/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.1964 - val_loss: 33.6374\n",
      "Epoch 653/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.1857 - val_loss: 26.6972\n",
      "Epoch 654/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.2710 - val_loss: 28.0083\n",
      "Epoch 655/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.9657 - val_loss: 18.7818\n",
      "Epoch 656/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.4890 - val_loss: 18.6724\n",
      "Epoch 657/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.6382 - val_loss: 15.1991\n",
      "Epoch 658/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.7947 - val_loss: 18.2105\n",
      "Epoch 659/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.6266 - val_loss: 22.1541\n",
      "Epoch 660/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.8877 - val_loss: 17.2433\n",
      "Epoch 661/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.1661 - val_loss: 19.3348\n",
      "Epoch 662/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.0385 - val_loss: 18.2297\n",
      "Epoch 663/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.7940 - val_loss: 28.3652\n",
      "Epoch 664/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 13.9855 - val_loss: 12.1029\n",
      "Epoch 665/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.3389 - val_loss: 23.1424\n",
      "Epoch 666/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.3013 - val_loss: 20.2514\n",
      "Epoch 667/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.8605 - val_loss: 17.9265\n",
      "Epoch 668/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.5844 - val_loss: 12.5473\n",
      "Epoch 669/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 15.3252 - val_loss: 18.6357\n",
      "Epoch 670/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.5013 - val_loss: 15.5128\n",
      "Epoch 671/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.2024 - val_loss: 23.0809\n",
      "Epoch 672/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.1944 - val_loss: 18.1113\n",
      "Epoch 673/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.2553 - val_loss: 29.0581\n",
      "Epoch 674/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.9731 - val_loss: 27.6343\n",
      "Epoch 675/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.3982 - val_loss: 18.2699\n",
      "Epoch 676/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 16.1656 - val_loss: 21.9175\n",
      "Epoch 677/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.3984 - val_loss: 24.7795\n",
      "Epoch 678/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.7098 - val_loss: 33.3929\n",
      "Epoch 679/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.1089 - val_loss: 20.0954\n",
      "Epoch 680/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.2383 - val_loss: 23.0032\n",
      "Epoch 681/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.9238 - val_loss: 17.5568\n",
      "Epoch 682/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.6186 - val_loss: 15.2925\n",
      "Epoch 683/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.8993 - val_loss: 18.3074\n",
      "Epoch 684/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 15.2410 - val_loss: 15.2893\n",
      "Epoch 685/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.2332 - val_loss: 13.9506\n",
      "Epoch 686/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.2569 - val_loss: 29.5465\n",
      "Epoch 687/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.4948 - val_loss: 18.8184\n",
      "Epoch 688/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.2530 - val_loss: 16.4901\n",
      "Epoch 689/1500\n",
      "87/87 [==============================] - ETA: 0s - loss: 13.00 - 0s 1ms/step - loss: 13.9826 - val_loss: 18.7470\n",
      "Epoch 690/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.7716 - val_loss: 20.8888\n",
      "Epoch 691/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 14.5975 - val_loss: 17.1601\n",
      "Epoch 692/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.8504 - val_loss: 20.3927\n",
      "Epoch 693/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.8734 - val_loss: 17.0074\n",
      "Epoch 694/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.7704 - val_loss: 15.1036\n",
      "Epoch 695/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.7706 - val_loss: 14.6026\n",
      "Epoch 696/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.5003 - val_loss: 20.4512\n",
      "Epoch 697/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.9738 - val_loss: 23.4221\n",
      "Epoch 698/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.8155 - val_loss: 17.0998\n",
      "Epoch 699/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.6038 - val_loss: 15.2006\n",
      "Epoch 700/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.4271 - val_loss: 13.6592\n",
      "Epoch 701/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.3120 - val_loss: 22.2611\n",
      "Epoch 702/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.2516 - val_loss: 18.3571\n",
      "Epoch 703/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.9677 - val_loss: 25.3325\n",
      "Epoch 704/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 15.1841 - val_loss: 16.1337\n",
      "Epoch 705/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.6047 - val_loss: 24.2869\n",
      "Epoch 706/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 13.2179 - val_loss: 14.9026\n",
      "Epoch 707/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.0374 - val_loss: 20.5185\n",
      "Epoch 708/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.6738 - val_loss: 28.7923\n",
      "Epoch 709/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.9447 - val_loss: 22.4185\n",
      "Epoch 710/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.3164 - val_loss: 20.7438\n",
      "Epoch 711/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 14.1710 - val_loss: 16.9221\n",
      "Epoch 712/1500\n",
      "87/87 [==============================] - 0s 989us/step - loss: 13.3124 - val_loss: 24.0562\n",
      "Epoch 713/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.9077 - val_loss: 18.5407\n",
      "Epoch 714/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.3549 - val_loss: 22.1384\n",
      "Epoch 715/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.9241 - val_loss: 14.7842\n",
      "Epoch 716/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.1530 - val_loss: 27.8072\n",
      "Epoch 717/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.2586 - val_loss: 25.2083\n",
      "Epoch 718/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.3549 - val_loss: 28.3451\n",
      "Epoch 719/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.3409 - val_loss: 18.7365\n",
      "Epoch 720/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.8780 - val_loss: 13.4296\n",
      "Epoch 721/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.6963 - val_loss: 19.7982\n",
      "Epoch 722/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.8781 - val_loss: 31.5973\n",
      "Epoch 723/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 15.2710 - val_loss: 18.4368\n",
      "Epoch 724/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.6058 - val_loss: 15.1473\n",
      "Epoch 725/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.1404 - val_loss: 19.5573\n",
      "Epoch 726/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.6634 - val_loss: 16.3616\n",
      "Epoch 727/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.0318 - val_loss: 17.7038\n",
      "Epoch 728/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.3952 - val_loss: 21.2656\n",
      "Epoch 729/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.3043 - val_loss: 14.0766\n",
      "Epoch 730/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.5690 - val_loss: 27.1256\n",
      "Epoch 731/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.2984 - val_loss: 11.8929\n",
      "Epoch 732/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.1195 - val_loss: 15.3659\n",
      "Epoch 733/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.2764 - val_loss: 17.5168\n",
      "Epoch 734/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.1315 - val_loss: 22.2623\n",
      "Epoch 735/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.6997 - val_loss: 24.3583\n",
      "Epoch 736/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.1967 - val_loss: 16.3125\n",
      "Epoch 737/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.9882 - val_loss: 21.0253\n",
      "Epoch 738/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.6558 - val_loss: 22.1820\n",
      "Epoch 739/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.4264 - val_loss: 25.5346\n",
      "Epoch 740/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.7288 - val_loss: 17.0508\n",
      "Epoch 741/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.9195 - val_loss: 30.8333\n",
      "Epoch 742/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.2987 - val_loss: 18.7110\n",
      "Epoch 743/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.2626 - val_loss: 21.6724\n",
      "Epoch 744/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.0243 - val_loss: 33.2190\n",
      "Epoch 745/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.8420 - val_loss: 19.1523\n",
      "Epoch 746/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.5345 - val_loss: 25.3663\n",
      "Epoch 747/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.6244 - val_loss: 19.9311\n",
      "Epoch 748/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.3052 - val_loss: 12.7158\n",
      "Epoch 749/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.1282 - val_loss: 29.9713\n",
      "Epoch 750/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.0891 - val_loss: 23.0944\n",
      "Epoch 751/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.0777 - val_loss: 12.1475\n",
      "Epoch 752/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.4458 - val_loss: 17.1081\n",
      "Epoch 753/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 14.4252 - val_loss: 22.8258\n",
      "Epoch 754/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.9976 - val_loss: 14.2928\n",
      "Epoch 755/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.0704 - val_loss: 13.6608\n",
      "Epoch 756/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 14.8292 - val_loss: 16.6810\n",
      "Epoch 757/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.6707 - val_loss: 22.0276\n",
      "Epoch 758/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.9774 - val_loss: 26.6700\n",
      "Epoch 759/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 13.4962 - val_loss: 21.1595\n",
      "Epoch 760/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.1741 - val_loss: 23.1528\n",
      "Epoch 761/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.9266 - val_loss: 19.0311\n",
      "Epoch 762/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.5413 - val_loss: 16.7597\n",
      "Epoch 763/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.1513 - val_loss: 17.8711\n",
      "Epoch 764/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.5927 - val_loss: 17.5934\n",
      "Epoch 765/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.6985 - val_loss: 20.6389\n",
      "Epoch 766/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.0454 - val_loss: 15.3045\n",
      "Epoch 767/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.8117 - val_loss: 29.5686\n",
      "Epoch 768/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.9976 - val_loss: 14.9439\n",
      "Epoch 769/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.6846 - val_loss: 20.2352\n",
      "Epoch 770/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.9543 - val_loss: 18.3379\n",
      "Epoch 771/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.5038 - val_loss: 16.3437\n",
      "Epoch 772/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.5247 - val_loss: 20.7203\n",
      "Epoch 773/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.7879 - val_loss: 21.2135\n",
      "Epoch 774/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.1974 - val_loss: 12.8856\n",
      "Epoch 775/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.1492 - val_loss: 16.7543\n",
      "Epoch 776/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.0899 - val_loss: 16.5410\n",
      "Epoch 777/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.5086 - val_loss: 21.5903\n",
      "Epoch 778/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.6579 - val_loss: 17.8429\n",
      "Epoch 779/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.1181 - val_loss: 20.6500\n",
      "Epoch 780/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.4055 - val_loss: 19.2167\n",
      "Epoch 781/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.1210 - val_loss: 15.6132\n",
      "Epoch 782/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 14.5377 - val_loss: 20.4421\n",
      "Epoch 783/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.6280 - val_loss: 14.0653\n",
      "Epoch 784/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 14.1802 - val_loss: 16.9685\n",
      "Epoch 785/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.1933 - val_loss: 18.9457\n",
      "Epoch 786/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.7880 - val_loss: 14.8039\n",
      "Epoch 787/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 14.1710 - val_loss: 24.0768\n",
      "Epoch 788/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.2067 - val_loss: 19.2065\n",
      "Epoch 789/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.9647 - val_loss: 14.8160\n",
      "Epoch 790/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.3434 - val_loss: 11.4256\n",
      "Epoch 791/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.2891 - val_loss: 24.2490\n",
      "Epoch 792/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.4415 - val_loss: 10.6746\n",
      "Epoch 793/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.3449 - val_loss: 20.1780\n",
      "Epoch 794/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.8944 - val_loss: 14.6952\n",
      "Epoch 795/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.2837 - val_loss: 16.4059\n",
      "Epoch 796/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.0088 - val_loss: 28.7322\n",
      "Epoch 797/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.0249 - val_loss: 19.9845\n",
      "Epoch 798/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.9165 - val_loss: 20.1919\n",
      "Epoch 799/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.4651 - val_loss: 19.1307\n",
      "Epoch 800/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.0621 - val_loss: 18.7097\n",
      "Epoch 801/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.3227 - val_loss: 15.1390\n",
      "Epoch 802/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.6927 - val_loss: 17.2491\n",
      "Epoch 803/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.9090 - val_loss: 15.4359\n",
      "Epoch 804/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.5342 - val_loss: 17.4813\n",
      "Epoch 805/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.6477 - val_loss: 17.9299\n",
      "Epoch 806/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.6231 - val_loss: 18.1607\n",
      "Epoch 807/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.0910 - val_loss: 24.8407\n",
      "Epoch 808/1500\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 14.9958 - val_loss: 23.5717\n",
      "Epoch 809/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.2621 - val_loss: 26.9056\n",
      "Epoch 810/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.0715 - val_loss: 13.7549\n",
      "Epoch 811/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.5457 - val_loss: 15.3904\n",
      "Epoch 812/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 13.0193 - val_loss: 13.1230\n",
      "Epoch 813/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.3438 - val_loss: 23.5403\n",
      "Epoch 814/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.6411 - val_loss: 22.5526\n",
      "Epoch 815/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.4948 - val_loss: 15.7461\n",
      "Epoch 816/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.7513 - val_loss: 23.5457\n",
      "Epoch 817/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.3851 - val_loss: 17.6965\n",
      "Epoch 818/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 14.0500 - val_loss: 15.1277\n",
      "Epoch 819/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.1149 - val_loss: 19.2428\n",
      "Epoch 820/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.2744 - val_loss: 16.8148\n",
      "Epoch 821/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.3099 - val_loss: 26.6327\n",
      "Epoch 822/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.7423 - val_loss: 20.8801\n",
      "Epoch 823/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.5562 - val_loss: 15.3397\n",
      "Epoch 824/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.6289 - val_loss: 14.2084\n",
      "Epoch 825/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.0894 - val_loss: 25.6483\n",
      "Epoch 826/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 12.8907 - val_loss: 22.6629\n",
      "Epoch 827/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.5320 - val_loss: 17.0625\n",
      "Epoch 828/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.6265 - val_loss: 14.8858\n",
      "Epoch 829/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.3804 - val_loss: 19.6294\n",
      "Epoch 830/1500\n",
      "87/87 [==============================] - ETA: 0s - loss: 14.29 - 0s 1ms/step - loss: 13.4421 - val_loss: 18.4043\n",
      "Epoch 831/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.3950 - val_loss: 23.5770\n",
      "Epoch 832/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.5436 - val_loss: 16.3033\n",
      "Epoch 833/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.0829 - val_loss: 22.2952\n",
      "Epoch 834/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.3401 - val_loss: 28.7785\n",
      "Epoch 835/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.6983 - val_loss: 20.0275\n",
      "Epoch 836/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.6501 - val_loss: 16.4294\n",
      "Epoch 837/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 12.7173 - val_loss: 18.0742\n",
      "Epoch 838/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 13.0189 - val_loss: 18.9511\n",
      "Epoch 839/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.0892 - val_loss: 14.8009\n",
      "Epoch 840/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.2451 - val_loss: 20.8715\n",
      "Epoch 841/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.7420 - val_loss: 12.0243\n",
      "Epoch 842/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.2678 - val_loss: 13.5520\n",
      "Epoch 843/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 13.3099 - val_loss: 21.6428\n",
      "Epoch 844/1500\n",
      "87/87 [==============================] - 0s 989us/step - loss: 12.6336 - val_loss: 15.8900\n",
      "Epoch 845/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.5631 - val_loss: 14.2411\n",
      "Epoch 846/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.4420 - val_loss: 21.6770\n",
      "Epoch 847/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.5803 - val_loss: 14.1788\n",
      "Epoch 848/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.4286 - val_loss: 15.2114\n",
      "Epoch 849/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.8417 - val_loss: 22.3492\n",
      "Epoch 850/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.6707 - val_loss: 17.4291\n",
      "Epoch 851/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 11.7705 - val_loss: 22.2806\n",
      "Epoch 852/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 13.0782 - val_loss: 16.8751\n",
      "Epoch 853/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.9248 - val_loss: 20.9263\n",
      "Epoch 854/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.8779 - val_loss: 18.7155\n",
      "Epoch 855/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.6672 - val_loss: 16.8577\n",
      "Epoch 856/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.9673 - val_loss: 13.6776\n",
      "Epoch 857/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.9012 - val_loss: 12.7624\n",
      "Epoch 858/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.2532 - val_loss: 13.1491\n",
      "Epoch 859/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.3398 - val_loss: 13.7737\n",
      "Epoch 860/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 12.1039 - val_loss: 18.1357\n",
      "Epoch 861/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 13.4408 - val_loss: 19.8856\n",
      "Epoch 862/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.8773 - val_loss: 15.5804\n",
      "Epoch 863/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.8996 - val_loss: 25.7536\n",
      "Epoch 864/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 14.3928 - val_loss: 13.0095\n",
      "Epoch 865/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 12.2295 - val_loss: 18.3187\n",
      "Epoch 866/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.2453 - val_loss: 17.8368\n",
      "Epoch 867/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 13.5276 - val_loss: 12.8649\n",
      "Epoch 868/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 11.7911 - val_loss: 23.0621\n",
      "Epoch 869/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.6013 - val_loss: 18.0857\n",
      "Epoch 870/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.5222 - val_loss: 15.8524\n",
      "Epoch 871/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.2387 - val_loss: 15.0343\n",
      "Epoch 872/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.6474 - val_loss: 14.4691\n",
      "Epoch 873/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.0725 - val_loss: 13.8640\n",
      "Epoch 874/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.5676 - val_loss: 31.8030\n",
      "Epoch 875/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.5414 - val_loss: 30.2905\n",
      "Epoch 876/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.3167 - val_loss: 15.8644\n",
      "Epoch 877/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.7486 - val_loss: 14.7139\n",
      "Epoch 878/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.8828 - val_loss: 16.6526\n",
      "Epoch 879/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.2449 - val_loss: 22.9115\n",
      "Epoch 880/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.9967 - val_loss: 14.1865\n",
      "Epoch 881/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.5578 - val_loss: 14.3912\n",
      "Epoch 882/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.5229 - val_loss: 24.9068\n",
      "Epoch 883/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.5963 - val_loss: 21.9688\n",
      "Epoch 884/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.3696 - val_loss: 14.9491\n",
      "Epoch 885/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.0984 - val_loss: 23.4723\n",
      "Epoch 886/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.7521 - val_loss: 17.1058\n",
      "Epoch 887/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 14.0502 - val_loss: 22.6851\n",
      "Epoch 888/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.9801 - val_loss: 20.4704\n",
      "Epoch 889/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.7622 - val_loss: 17.5744\n",
      "Epoch 890/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.2124 - val_loss: 32.6693\n",
      "Epoch 891/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.3821 - val_loss: 17.4240\n",
      "Epoch 892/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.0028 - val_loss: 20.6314\n",
      "Epoch 893/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.7252 - val_loss: 14.0536\n",
      "Epoch 894/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.6003 - val_loss: 16.7908\n",
      "Epoch 895/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.3950 - val_loss: 18.9480\n",
      "Epoch 896/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.6489 - val_loss: 18.2066\n",
      "Epoch 897/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.3663 - val_loss: 14.8363\n",
      "Epoch 898/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.5876 - val_loss: 24.7235\n",
      "Epoch 899/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.8838 - val_loss: 21.9789\n",
      "Epoch 900/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.4625 - val_loss: 17.7618\n",
      "Epoch 901/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.0148 - val_loss: 26.0528\n",
      "Epoch 902/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.6264 - val_loss: 21.1162\n",
      "Epoch 903/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.7868 - val_loss: 13.0196\n",
      "Epoch 904/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.4551 - val_loss: 18.2165\n",
      "Epoch 905/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.3834 - val_loss: 20.9403\n",
      "Epoch 906/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.2345 - val_loss: 15.3250\n",
      "Epoch 907/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.0462 - val_loss: 17.9270\n",
      "Epoch 908/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.9228 - val_loss: 13.7388\n",
      "Epoch 909/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.5541 - val_loss: 26.5463\n",
      "Epoch 910/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.9900 - val_loss: 18.1139\n",
      "Epoch 911/1500\n",
      "87/87 [==============================] - 0s 989us/step - loss: 12.2581 - val_loss: 24.1271\n",
      "Epoch 912/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.9325 - val_loss: 14.4885\n",
      "Epoch 913/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.7252 - val_loss: 19.8562\n",
      "Epoch 914/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 12.7124 - val_loss: 16.4548\n",
      "Epoch 915/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 12.2388 - val_loss: 15.2107\n",
      "Epoch 916/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.3813 - val_loss: 15.0103\n",
      "Epoch 917/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.1698 - val_loss: 18.5183\n",
      "Epoch 918/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.9585 - val_loss: 19.0098\n",
      "Epoch 919/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.9305 - val_loss: 11.3696\n",
      "Epoch 920/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.1053 - val_loss: 10.6949\n",
      "Epoch 921/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.2537 - val_loss: 23.5445\n",
      "Epoch 922/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.3906 - val_loss: 10.6491\n",
      "Epoch 923/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.9154 - val_loss: 14.0377\n",
      "Epoch 924/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.3998 - val_loss: 17.8422\n",
      "Epoch 925/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.3928 - val_loss: 10.2738\n",
      "Epoch 926/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.4317 - val_loss: 15.7788\n",
      "Epoch 927/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 11.9628 - val_loss: 13.3542\n",
      "Epoch 928/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.7135 - val_loss: 19.9664\n",
      "Epoch 929/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.6417 - val_loss: 15.1037\n",
      "Epoch 930/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.8256 - val_loss: 14.7294\n",
      "Epoch 931/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.7020 - val_loss: 13.8356\n",
      "Epoch 932/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.4759 - val_loss: 37.7549\n",
      "Epoch 933/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.0677 - val_loss: 13.1049\n",
      "Epoch 934/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.3675 - val_loss: 12.9873\n",
      "Epoch 935/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.1023 - val_loss: 19.8413\n",
      "Epoch 936/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.2326 - val_loss: 14.6913\n",
      "Epoch 937/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.8005 - val_loss: 12.5768\n",
      "Epoch 938/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 12.3377 - val_loss: 25.7963\n",
      "Epoch 939/1500\n",
      "87/87 [==============================] - 0s 989us/step - loss: 11.7233 - val_loss: 19.6986\n",
      "Epoch 940/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.4336 - val_loss: 11.3068\n",
      "Epoch 941/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.3701 - val_loss: 17.2027\n",
      "Epoch 942/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.3007 - val_loss: 18.7330\n",
      "Epoch 943/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 12.2328 - val_loss: 10.7544\n",
      "Epoch 944/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.5143 - val_loss: 12.6509\n",
      "Epoch 945/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.2136 - val_loss: 18.5257\n",
      "Epoch 946/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.9230 - val_loss: 12.5675\n",
      "Epoch 947/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 10.8178 - val_loss: 10.9114\n",
      "Epoch 948/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.0201 - val_loss: 13.8065\n",
      "Epoch 949/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 11.9470 - val_loss: 21.8415\n",
      "Epoch 950/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.4054 - val_loss: 21.4853\n",
      "Epoch 951/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.5116 - val_loss: 10.3546\n",
      "Epoch 952/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.7977 - val_loss: 20.3952\n",
      "Epoch 953/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.2145 - val_loss: 21.1510\n",
      "Epoch 954/1500\n",
      "87/87 [==============================] - 0s 966us/step - loss: 12.1580 - val_loss: 21.1671\n",
      "Epoch 955/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.6443 - val_loss: 10.4449\n",
      "Epoch 956/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.3058 - val_loss: 13.9830\n",
      "Epoch 957/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.8122 - val_loss: 11.4617\n",
      "Epoch 958/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.6416 - val_loss: 13.2250\n",
      "Epoch 959/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.7456 - val_loss: 12.5438\n",
      "Epoch 960/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 12.3434 - val_loss: 13.1154\n",
      "Epoch 961/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.3552 - val_loss: 12.8870\n",
      "Epoch 962/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 12.1064 - val_loss: 14.0896\n",
      "Epoch 963/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.2600 - val_loss: 15.1408\n",
      "Epoch 964/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.7206 - val_loss: 13.4342\n",
      "Epoch 965/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.5615 - val_loss: 14.0961\n",
      "Epoch 966/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.6735 - val_loss: 35.1768\n",
      "Epoch 967/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.8228 - val_loss: 41.6012\n",
      "Epoch 968/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.1880 - val_loss: 16.1669\n",
      "Epoch 969/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.1748 - val_loss: 10.3700\n",
      "Epoch 970/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.0033 - val_loss: 19.6577\n",
      "Epoch 971/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.9886 - val_loss: 10.1259\n",
      "Epoch 972/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.9292 - val_loss: 17.2415\n",
      "Epoch 973/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1141 - val_loss: 22.0331\n",
      "Epoch 974/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.1782 - val_loss: 32.1434\n",
      "Epoch 975/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.8121 - val_loss: 11.8784\n",
      "Epoch 976/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.3542 - val_loss: 9.6097\n",
      "Epoch 977/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.5497 - val_loss: 15.1502\n",
      "Epoch 978/1500\n",
      "87/87 [==============================] - 0s 965us/step - loss: 11.5943 - val_loss: 14.8501\n",
      "Epoch 979/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.1989 - val_loss: 15.4259\n",
      "Epoch 980/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.9640 - val_loss: 13.1838\n",
      "Epoch 981/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 12.3178 - val_loss: 13.6459\n",
      "Epoch 982/1500\n",
      "87/87 [==============================] - 0s 999us/step - loss: 10.7278 - val_loss: 23.8351\n",
      "Epoch 983/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 13.0938 - val_loss: 11.9133\n",
      "Epoch 984/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.2237 - val_loss: 11.0947\n",
      "Epoch 985/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.9672 - val_loss: 23.5383\n",
      "Epoch 986/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.7904 - val_loss: 13.7170\n",
      "Epoch 987/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.5755 - val_loss: 17.4080\n",
      "Epoch 988/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.1342 - val_loss: 11.1246\n",
      "Epoch 989/1500\n",
      "87/87 [==============================] - 0s 989us/step - loss: 11.4784 - val_loss: 11.7883\n",
      "Epoch 990/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.1783 - val_loss: 11.6802\n",
      "Epoch 991/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.4675 - val_loss: 11.0360\n",
      "Epoch 992/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.5627 - val_loss: 22.1028\n",
      "Epoch 993/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.3351 - val_loss: 8.5613\n",
      "Epoch 994/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.3815 - val_loss: 13.6161\n",
      "Epoch 995/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.4246 - val_loss: 12.6097\n",
      "Epoch 996/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.8540 - val_loss: 12.7328\n",
      "Epoch 997/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.8711 - val_loss: 11.0897\n",
      "Epoch 998/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.3836 - val_loss: 33.5904\n",
      "Epoch 999/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.8822 - val_loss: 14.9302\n",
      "Epoch 1000/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.6384 - val_loss: 10.2832\n",
      "Epoch 1001/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.1928 - val_loss: 9.7263\n",
      "Epoch 1002/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 11.2195 - val_loss: 8.7129\n",
      "Epoch 1003/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.5066 - val_loss: 14.8666\n",
      "Epoch 1004/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.9071 - val_loss: 12.9565\n",
      "Epoch 1005/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 9.8120 - val_loss: 14.9050\n",
      "Epoch 1006/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.0239 - val_loss: 26.7045\n",
      "Epoch 1007/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.8377 - val_loss: 11.6826\n",
      "Epoch 1008/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.1301 - val_loss: 11.7496\n",
      "Epoch 1009/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.9462 - val_loss: 18.2490\n",
      "Epoch 1010/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.0142 - val_loss: 18.7510\n",
      "Epoch 1011/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.7915 - val_loss: 16.5977\n",
      "Epoch 1012/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.1753 - val_loss: 19.0165\n",
      "Epoch 1013/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.8038 - val_loss: 14.4038\n",
      "Epoch 1014/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.3059 - val_loss: 12.7559\n",
      "Epoch 1015/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.7806 - val_loss: 29.0644\n",
      "Epoch 1016/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 10.8076 - val_loss: 16.2482\n",
      "Epoch 1017/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.9700 - val_loss: 15.2812\n",
      "Epoch 1018/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.3511 - val_loss: 18.3440\n",
      "Epoch 1019/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.8693 - val_loss: 23.6562\n",
      "Epoch 1020/1500\n",
      "87/87 [==============================] - 0s 989us/step - loss: 10.5270 - val_loss: 16.3734\n",
      "Epoch 1021/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 12.3430 - val_loss: 12.2849\n",
      "Epoch 1022/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.7300 - val_loss: 14.9537\n",
      "Epoch 1023/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.5479 - val_loss: 7.7907\n",
      "Epoch 1024/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.7427 - val_loss: 13.0013\n",
      "Epoch 1025/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.0670 - val_loss: 11.0416\n",
      "Epoch 1026/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.6045 - val_loss: 16.5539\n",
      "Epoch 1027/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.4807 - val_loss: 15.1733\n",
      "Epoch 1028/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.1638 - val_loss: 15.3900\n",
      "Epoch 1029/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.6182 - val_loss: 11.6185\n",
      "Epoch 1030/1500\n",
      "87/87 [==============================] - 0s 965us/step - loss: 10.6534 - val_loss: 24.2228\n",
      "Epoch 1031/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.2528 - val_loss: 9.9394\n",
      "Epoch 1032/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.2273 - val_loss: 24.4274\n",
      "Epoch 1033/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.0304 - val_loss: 18.0289\n",
      "Epoch 1034/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 11.2899 - val_loss: 24.8140\n",
      "Epoch 1035/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 10.4494 - val_loss: 16.3693\n",
      "Epoch 1036/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 10.5932 - val_loss: 10.7793\n",
      "Epoch 1037/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.1537 - val_loss: 18.3333\n",
      "Epoch 1038/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9635 - val_loss: 25.8520\n",
      "Epoch 1039/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5689 - val_loss: 10.2379\n",
      "Epoch 1040/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9806 - val_loss: 12.2341\n",
      "Epoch 1041/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.0675 - val_loss: 14.9942\n",
      "Epoch 1042/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.8222 - val_loss: 10.3896\n",
      "Epoch 1043/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.2978 - val_loss: 14.8703\n",
      "Epoch 1044/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.0789 - val_loss: 10.2359\n",
      "Epoch 1045/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.3672 - val_loss: 12.7985\n",
      "Epoch 1046/1500\n",
      "87/87 [==============================] - 0s 989us/step - loss: 12.0483 - val_loss: 10.5185\n",
      "Epoch 1047/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.1810 - val_loss: 11.8319\n",
      "Epoch 1048/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 9.6920 - val_loss: 10.2109\n",
      "Epoch 1049/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.8562 - val_loss: 19.3922\n",
      "Epoch 1050/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.4003 - val_loss: 12.7456\n",
      "Epoch 1051/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.9235 - val_loss: 10.4341\n",
      "Epoch 1052/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.0900 - val_loss: 20.0922\n",
      "Epoch 1053/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.5701 - val_loss: 10.0948\n",
      "Epoch 1054/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.0512 - val_loss: 15.2780\n",
      "Epoch 1055/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.2375 - val_loss: 11.6321\n",
      "Epoch 1056/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 10.5794 - val_loss: 23.2800\n",
      "Epoch 1057/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 10.2786 - val_loss: 20.3861\n",
      "Epoch 1058/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.0171 - val_loss: 10.2858\n",
      "Epoch 1059/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.4871 - val_loss: 13.0705\n",
      "Epoch 1060/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.2836 - val_loss: 18.6298\n",
      "Epoch 1061/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.3631 - val_loss: 14.7001\n",
      "Epoch 1062/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.2423 - val_loss: 14.5420\n",
      "Epoch 1063/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 10.6542 - val_loss: 16.4474\n",
      "Epoch 1064/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.4117 - val_loss: 13.0680\n",
      "Epoch 1065/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.3232 - val_loss: 11.9546\n",
      "Epoch 1066/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.2560 - val_loss: 11.5162\n",
      "Epoch 1067/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.4141 - val_loss: 12.9642\n",
      "Epoch 1068/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.3375 - val_loss: 11.5306\n",
      "Epoch 1069/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.2486 - val_loss: 9.0432\n",
      "Epoch 1070/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.7569 - val_loss: 15.0382\n",
      "Epoch 1071/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9868 - val_loss: 24.3746\n",
      "Epoch 1072/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.2347 - val_loss: 19.3014\n",
      "Epoch 1073/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 12.8101 - val_loss: 10.7830\n",
      "Epoch 1074/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8626 - val_loss: 10.7297\n",
      "Epoch 1075/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.4194 - val_loss: 8.9887\n",
      "Epoch 1076/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8414 - val_loss: 13.7429\n",
      "Epoch 1077/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7892 - val_loss: 9.2069\n",
      "Epoch 1078/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.6995 - val_loss: 16.0253\n",
      "Epoch 1079/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8872 - val_loss: 14.6389\n",
      "Epoch 1080/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1236 - val_loss: 15.1425\n",
      "Epoch 1081/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.2091 - val_loss: 14.8795\n",
      "Epoch 1082/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.2350 - val_loss: 19.1782\n",
      "Epoch 1083/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.0975 - val_loss: 15.2001\n",
      "Epoch 1084/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.8135 - val_loss: 9.0584\n",
      "Epoch 1085/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.0754 - val_loss: 19.2013\n",
      "Epoch 1086/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 10.4746 - val_loss: 19.3602\n",
      "Epoch 1087/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.2391 - val_loss: 18.6943\n",
      "Epoch 1088/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.0448 - val_loss: 13.7416\n",
      "Epoch 1089/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 11.1502 - val_loss: 11.7537\n",
      "Epoch 1090/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.8401 - val_loss: 28.7364\n",
      "Epoch 1091/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.7871 - val_loss: 11.4209\n",
      "Epoch 1092/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3836 - val_loss: 12.6690\n",
      "Epoch 1093/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.3603 - val_loss: 17.6195\n",
      "Epoch 1094/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 10.9009 - val_loss: 8.4108\n",
      "Epoch 1095/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 10.1645 - val_loss: 12.3342\n",
      "Epoch 1096/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9418 - val_loss: 15.7947\n",
      "Epoch 1097/1500\n",
      "87/87 [==============================] - 0s 966us/step - loss: 10.2141 - val_loss: 24.3359\n",
      "Epoch 1098/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 10.5015 - val_loss: 14.8130\n",
      "Epoch 1099/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.9901 - val_loss: 17.5101\n",
      "Epoch 1100/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 10.0115 - val_loss: 22.1283\n",
      "Epoch 1101/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 10.2036 - val_loss: 16.9304\n",
      "Epoch 1102/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.2176 - val_loss: 8.5229\n",
      "Epoch 1103/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 11.2117 - val_loss: 12.9593\n",
      "Epoch 1104/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1636 - val_loss: 14.8451\n",
      "Epoch 1105/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8457 - val_loss: 7.9514\n",
      "Epoch 1106/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 10.4997 - val_loss: 17.7933\n",
      "Epoch 1107/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1529 - val_loss: 11.8165\n",
      "Epoch 1108/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8817 - val_loss: 21.2414\n",
      "Epoch 1109/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1021 - val_loss: 18.5647\n",
      "Epoch 1110/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1029 - val_loss: 13.2003\n",
      "Epoch 1111/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 9.8665 - val_loss: 23.1257\n",
      "Epoch 1112/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.6366 - val_loss: 17.0757\n",
      "Epoch 1113/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7753 - val_loss: 9.8190\n",
      "Epoch 1114/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.2925 - val_loss: 18.0806\n",
      "Epoch 1115/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7422 - val_loss: 16.0487\n",
      "Epoch 1116/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.7368 - val_loss: 11.6676\n",
      "Epoch 1117/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9284 - val_loss: 19.8443\n",
      "Epoch 1118/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 10.8456 - val_loss: 21.1351\n",
      "Epoch 1119/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.0140 - val_loss: 28.0569\n",
      "Epoch 1120/1500\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 10.6178 - val_loss: 14.5713\n",
      "Epoch 1121/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1571 - val_loss: 16.8873\n",
      "Epoch 1122/1500\n",
      "87/87 [==============================] - 0s 954us/step - loss: 10.5038 - val_loss: 22.0083\n",
      "Epoch 1123/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.2838 - val_loss: 19.5246\n",
      "Epoch 1124/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1890 - val_loss: 19.9355\n",
      "Epoch 1125/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 10.5523 - val_loss: 33.7948\n",
      "Epoch 1126/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.0469 - val_loss: 14.9250\n",
      "Epoch 1127/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.3859 - val_loss: 19.2162\n",
      "Epoch 1128/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1419 - val_loss: 10.4712\n",
      "Epoch 1129/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9256 - val_loss: 15.1902\n",
      "Epoch 1130/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.6841 - val_loss: 18.3529\n",
      "Epoch 1131/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.8901 - val_loss: 11.0425\n",
      "Epoch 1132/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8725 - val_loss: 13.0406\n",
      "Epoch 1133/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5674 - val_loss: 20.2746\n",
      "Epoch 1134/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9537 - val_loss: 14.8463\n",
      "Epoch 1135/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7886 - val_loss: 14.0706\n",
      "Epoch 1136/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.9378 - val_loss: 20.4784\n",
      "Epoch 1137/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.0947 - val_loss: 11.2474\n",
      "Epoch 1138/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9024 - val_loss: 22.7419\n",
      "Epoch 1139/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.3517 - val_loss: 10.7015\n",
      "Epoch 1140/1500\n",
      "87/87 [==============================] - 0s 965us/step - loss: 9.6922 - val_loss: 12.9504\n",
      "Epoch 1141/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.6875 - val_loss: 18.1750\n",
      "Epoch 1142/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.3653 - val_loss: 20.0390\n",
      "Epoch 1143/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.6625 - val_loss: 10.4888\n",
      "Epoch 1144/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9519 - val_loss: 14.1014\n",
      "Epoch 1145/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9051 - val_loss: 17.3410\n",
      "Epoch 1146/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.5737 - val_loss: 17.4862\n",
      "Epoch 1147/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8497 - val_loss: 9.2863\n",
      "Epoch 1148/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.8090 - val_loss: 13.8110\n",
      "Epoch 1149/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1101 - val_loss: 13.4400\n",
      "Epoch 1150/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2636 - val_loss: 13.4981\n",
      "Epoch 1151/1500\n",
      "87/87 [==============================] - ETA: 0s - loss: 11.70 - 0s 1ms/step - loss: 10.2480 - val_loss: 13.1607\n",
      "Epoch 1152/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.9987 - val_loss: 11.0836\n",
      "Epoch 1153/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7281 - val_loss: 20.3140\n",
      "Epoch 1154/1500\n",
      "87/87 [==============================] - 0s 954us/step - loss: 10.0748 - val_loss: 17.3842\n",
      "Epoch 1155/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.4387 - val_loss: 22.9533\n",
      "Epoch 1156/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9267 - val_loss: 19.1030\n",
      "Epoch 1157/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.2780 - val_loss: 13.9711\n",
      "Epoch 1158/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 10.7235 - val_loss: 14.0159\n",
      "Epoch 1159/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.0031 - val_loss: 20.5309\n",
      "Epoch 1160/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8280 - val_loss: 19.1273\n",
      "Epoch 1161/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 10.8282 - val_loss: 12.0779\n",
      "Epoch 1162/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7502 - val_loss: 16.8837\n",
      "Epoch 1163/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.8249 - val_loss: 18.7675\n",
      "Epoch 1164/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.4747 - val_loss: 17.3748\n",
      "Epoch 1165/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.8869 - val_loss: 11.5525\n",
      "Epoch 1166/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1408 - val_loss: 26.9582\n",
      "Epoch 1167/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7015 - val_loss: 12.8149\n",
      "Epoch 1168/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.4927 - val_loss: 17.5361\n",
      "Epoch 1169/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1768 - val_loss: 12.4137\n",
      "Epoch 1170/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.4497 - val_loss: 11.8211\n",
      "Epoch 1171/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 10.3097 - val_loss: 13.4157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1172/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9272 - val_loss: 13.8019\n",
      "Epoch 1173/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.6765 - val_loss: 14.3396\n",
      "Epoch 1174/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.0707 - val_loss: 13.9661\n",
      "Epoch 1175/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.4115 - val_loss: 11.6941\n",
      "Epoch 1176/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2659 - val_loss: 21.0368\n",
      "Epoch 1177/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5152 - val_loss: 21.5045\n",
      "Epoch 1178/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.2393 - val_loss: 14.2482\n",
      "Epoch 1179/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.2869 - val_loss: 18.4201\n",
      "Epoch 1180/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.0606 - val_loss: 24.3850\n",
      "Epoch 1181/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5655 - val_loss: 17.4939\n",
      "Epoch 1182/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1860 - val_loss: 14.5160\n",
      "Epoch 1183/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1516 - val_loss: 12.5984\n",
      "Epoch 1184/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.2861 - val_loss: 22.1062\n",
      "Epoch 1185/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7288 - val_loss: 18.3562\n",
      "Epoch 1186/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.8079 - val_loss: 10.0516\n",
      "Epoch 1187/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1616 - val_loss: 12.5567\n",
      "Epoch 1188/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.6795 - val_loss: 10.3395\n",
      "Epoch 1189/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.6306 - val_loss: 6.0276\n",
      "Epoch 1190/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9114 - val_loss: 9.5769\n",
      "Epoch 1191/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.6341 - val_loss: 10.4023\n",
      "Epoch 1192/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3627 - val_loss: 22.8192\n",
      "Epoch 1193/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.6301 - val_loss: 17.3720\n",
      "Epoch 1194/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.2810 - val_loss: 10.7740\n",
      "Epoch 1195/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.4086 - val_loss: 25.9142\n",
      "Epoch 1196/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1501 - val_loss: 13.3817\n",
      "Epoch 1197/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.6571 - val_loss: 20.8151\n",
      "Epoch 1198/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.8009 - val_loss: 13.3874\n",
      "Epoch 1199/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5153 - val_loss: 12.4739\n",
      "Epoch 1200/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7820 - val_loss: 9.5957\n",
      "Epoch 1201/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7199 - val_loss: 14.4206\n",
      "Epoch 1202/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 9.3139 - val_loss: 11.1914\n",
      "Epoch 1203/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1520 - val_loss: 19.2774\n",
      "Epoch 1204/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5381 - val_loss: 16.5919\n",
      "Epoch 1205/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8159 - val_loss: 18.4066\n",
      "Epoch 1206/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7653 - val_loss: 14.2484\n",
      "Epoch 1207/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3775 - val_loss: 21.3042\n",
      "Epoch 1208/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.9851 - val_loss: 11.5189\n",
      "Epoch 1209/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 9.1364 - val_loss: 13.9470\n",
      "Epoch 1210/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5472 - val_loss: 10.6712\n",
      "Epoch 1211/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1128 - val_loss: 20.4497\n",
      "Epoch 1212/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2479 - val_loss: 27.9174\n",
      "Epoch 1213/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5265 - val_loss: 21.7194\n",
      "Epoch 1214/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1606 - val_loss: 10.3400\n",
      "Epoch 1215/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.8895 - val_loss: 13.5500\n",
      "Epoch 1216/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8401 - val_loss: 19.3264\n",
      "Epoch 1217/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8862 - val_loss: 12.2823\n",
      "Epoch 1218/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7659 - val_loss: 22.2429\n",
      "Epoch 1219/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.4712 - val_loss: 15.1056\n",
      "Epoch 1220/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7055 - val_loss: 26.5066\n",
      "Epoch 1221/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2413 - val_loss: 15.2453\n",
      "Epoch 1222/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 11.0122 - val_loss: 12.4447\n",
      "Epoch 1223/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.0203 - val_loss: 8.4421\n",
      "Epoch 1224/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.7090 - val_loss: 16.4061\n",
      "Epoch 1225/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8948 - val_loss: 16.4700\n",
      "Epoch 1226/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.2544 - val_loss: 8.8938\n",
      "Epoch 1227/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.9562 - val_loss: 15.7544\n",
      "Epoch 1228/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7397 - val_loss: 14.5318\n",
      "Epoch 1229/1500\n",
      "87/87 [==============================] - ETA: 0s - loss: 10.17 - 0s 1ms/step - loss: 10.0293 - val_loss: 9.7611\n",
      "Epoch 1230/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8632 - val_loss: 13.8809\n",
      "Epoch 1231/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7392 - val_loss: 24.2864\n",
      "Epoch 1232/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1488 - val_loss: 11.7383\n",
      "Epoch 1233/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8721 - val_loss: 17.8380\n",
      "Epoch 1234/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1101 - val_loss: 11.5748\n",
      "Epoch 1235/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5471 - val_loss: 10.7173\n",
      "Epoch 1236/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.0167 - val_loss: 23.8262\n",
      "Epoch 1237/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9478 - val_loss: 9.4086\n",
      "Epoch 1238/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1023 - val_loss: 9.6289\n",
      "Epoch 1239/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9375 - val_loss: 19.9128\n",
      "Epoch 1240/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5483 - val_loss: 15.8546\n",
      "Epoch 1241/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9451 - val_loss: 10.3584\n",
      "Epoch 1242/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.5306 - val_loss: 14.0842\n",
      "Epoch 1243/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1650 - val_loss: 18.3186\n",
      "Epoch 1244/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3733 - val_loss: 12.9044\n",
      "Epoch 1245/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8226 - val_loss: 23.4482\n",
      "Epoch 1246/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.8131 - val_loss: 14.5608\n",
      "Epoch 1247/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.2294 - val_loss: 20.4605\n",
      "Epoch 1248/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7875 - val_loss: 11.8246\n",
      "Epoch 1249/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3356 - val_loss: 6.5412\n",
      "Epoch 1250/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5025 - val_loss: 15.7854\n",
      "Epoch 1251/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.0259 - val_loss: 19.4624\n",
      "Epoch 1252/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 9.8557 - val_loss: 10.5304\n",
      "Epoch 1253/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7063 - val_loss: 21.2774\n",
      "Epoch 1254/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.0622 - val_loss: 14.0326\n",
      "Epoch 1255/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3011 - val_loss: 9.9568\n",
      "Epoch 1256/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1450 - val_loss: 10.9822\n",
      "Epoch 1257/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5270 - val_loss: 10.7068\n",
      "Epoch 1258/1500\n",
      "87/87 [==============================] - 0s 989us/step - loss: 9.8694 - val_loss: 10.2048\n",
      "Epoch 1259/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.0421 - val_loss: 14.2231\n",
      "Epoch 1260/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.9736 - val_loss: 12.8629\n",
      "Epoch 1261/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1391 - val_loss: 14.8219\n",
      "Epoch 1262/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.4610 - val_loss: 13.4282\n",
      "Epoch 1263/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2050 - val_loss: 9.8286\n",
      "Epoch 1264/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.0714 - val_loss: 12.6652\n",
      "Epoch 1265/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.4786 - val_loss: 8.6308\n",
      "Epoch 1266/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9522 - val_loss: 14.4918\n",
      "Epoch 1267/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8218 - val_loss: 7.2872\n",
      "Epoch 1268/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2816 - val_loss: 9.3715\n",
      "Epoch 1269/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 8.9512 - val_loss: 25.7501\n",
      "Epoch 1270/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1765 - val_loss: 17.3451\n",
      "Epoch 1271/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2601 - val_loss: 15.9059\n",
      "Epoch 1272/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1519 - val_loss: 13.5021\n",
      "Epoch 1273/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3182 - val_loss: 12.9750\n",
      "Epoch 1274/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5623 - val_loss: 11.7775\n",
      "Epoch 1275/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.3044 - val_loss: 10.9641\n",
      "Epoch 1276/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2218 - val_loss: 13.5251\n",
      "Epoch 1277/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.4070 - val_loss: 9.9936\n",
      "Epoch 1278/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3018 - val_loss: 9.9770\n",
      "Epoch 1279/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.6191 - val_loss: 16.1326\n",
      "Epoch 1280/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 9.1781 - val_loss: 10.7331\n",
      "Epoch 1281/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1876 - val_loss: 14.2298\n",
      "Epoch 1282/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 9.2694 - val_loss: 14.5587\n",
      "Epoch 1283/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3439 - val_loss: 23.3425\n",
      "Epoch 1284/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7376 - val_loss: 10.4893\n",
      "Epoch 1285/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.7816 - val_loss: 13.4638\n",
      "Epoch 1286/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1632 - val_loss: 14.4867\n",
      "Epoch 1287/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.5153 - val_loss: 14.6163\n",
      "Epoch 1288/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.4708 - val_loss: 17.6869\n",
      "Epoch 1289/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8939 - val_loss: 18.2558\n",
      "Epoch 1290/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.4400 - val_loss: 11.7815\n",
      "Epoch 1291/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.5416 - val_loss: 12.4645\n",
      "Epoch 1292/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.6645 - val_loss: 20.9491\n",
      "Epoch 1293/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1532 - val_loss: 11.2243\n",
      "Epoch 1294/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8868 - val_loss: 18.0153\n",
      "Epoch 1295/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1381 - val_loss: 13.9750\n",
      "Epoch 1296/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5539 - val_loss: 21.0201\n",
      "Epoch 1297/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2059 - val_loss: 17.8212\n",
      "Epoch 1298/1500\n",
      "87/87 [==============================] - 0s 989us/step - loss: 8.8565 - val_loss: 15.2575\n",
      "Epoch 1299/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3418 - val_loss: 16.6434\n",
      "Epoch 1300/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 9.1135 - val_loss: 14.2247\n",
      "Epoch 1301/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2114 - val_loss: 22.9596\n",
      "Epoch 1302/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2967 - val_loss: 7.0139\n",
      "Epoch 1303/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.6152 - val_loss: 36.9364\n",
      "Epoch 1304/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9711 - val_loss: 9.1273\n",
      "Epoch 1305/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7150 - val_loss: 12.6366\n",
      "Epoch 1306/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1960 - val_loss: 14.7654\n",
      "Epoch 1307/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.7182 - val_loss: 10.4465\n",
      "Epoch 1308/1500\n",
      "87/87 [==============================] - ETA: 0s - loss: 8.4552 - 0s 1ms/step - loss: 9.0727 - val_loss: 14.9277\n",
      "Epoch 1309/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2631 - val_loss: 16.1124\n",
      "Epoch 1310/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 7.6369 - val_loss: 21.8480\n",
      "Epoch 1311/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.6875 - val_loss: 13.3223\n",
      "Epoch 1312/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2302 - val_loss: 12.4817\n",
      "Epoch 1313/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.6055 - val_loss: 13.5776\n",
      "Epoch 1314/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.0633 - val_loss: 10.3183\n",
      "Epoch 1315/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.9318 - val_loss: 8.2357\n",
      "Epoch 1316/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3667 - val_loss: 20.2587\n",
      "Epoch 1317/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5808 - val_loss: 17.0477\n",
      "Epoch 1318/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.6219 - val_loss: 12.7264\n",
      "Epoch 1319/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.1862 - val_loss: 20.0441\n",
      "Epoch 1320/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.4249 - val_loss: 9.9698\n",
      "Epoch 1321/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.4623 - val_loss: 19.9423\n",
      "Epoch 1322/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.2919 - val_loss: 16.4679\n",
      "Epoch 1323/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.6218 - val_loss: 25.4233\n",
      "Epoch 1324/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.9360 - val_loss: 11.0843\n",
      "Epoch 1325/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.6971 - val_loss: 10.7318\n",
      "Epoch 1326/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.7055 - val_loss: 11.5198\n",
      "Epoch 1327/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2785 - val_loss: 8.8317\n",
      "Epoch 1328/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2418 - val_loss: 14.4213\n",
      "Epoch 1329/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1625 - val_loss: 10.1879\n",
      "Epoch 1330/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.7101 - val_loss: 8.4224\n",
      "Epoch 1331/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.6268 - val_loss: 12.6371\n",
      "Epoch 1332/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.4272 - val_loss: 22.3458\n",
      "Epoch 1333/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3767 - val_loss: 12.7197\n",
      "Epoch 1334/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1660 - val_loss: 7.3529\n",
      "Epoch 1335/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.0790 - val_loss: 15.5981\n",
      "Epoch 1336/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2485 - val_loss: 13.0247\n",
      "Epoch 1337/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1863 - val_loss: 19.2027\n",
      "Epoch 1338/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.0438 - val_loss: 25.0812\n",
      "Epoch 1339/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1940 - val_loss: 11.2151\n",
      "Epoch 1340/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1598 - val_loss: 7.6444\n",
      "Epoch 1341/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.6747 - val_loss: 21.5619\n",
      "Epoch 1342/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.8263 - val_loss: 7.9998\n",
      "Epoch 1343/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.6119 - val_loss: 7.9758\n",
      "Epoch 1344/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.0924 - val_loss: 8.5507\n",
      "Epoch 1345/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.3244 - val_loss: 11.8218\n",
      "Epoch 1346/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3630 - val_loss: 11.5252\n",
      "Epoch 1347/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 7.5942 - val_loss: 15.5431\n",
      "Epoch 1348/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.0795 - val_loss: 17.6475\n",
      "Epoch 1349/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.6919 - val_loss: 15.9587\n",
      "Epoch 1350/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.6233 - val_loss: 19.6374\n",
      "Epoch 1351/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.8549 - val_loss: 27.8050\n",
      "Epoch 1352/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2872 - val_loss: 19.5244\n",
      "Epoch 1353/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2996 - val_loss: 16.0028\n",
      "Epoch 1354/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3523 - val_loss: 11.4709\n",
      "Epoch 1355/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5543 - val_loss: 13.2988\n",
      "Epoch 1356/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.0847 - val_loss: 14.3046\n",
      "Epoch 1357/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.9007 - val_loss: 15.1579\n",
      "Epoch 1358/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.1107 - val_loss: 15.0802\n",
      "Epoch 1359/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.2656 - val_loss: 12.7029\n",
      "Epoch 1360/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.7225 - val_loss: 18.6692\n",
      "Epoch 1361/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.7428 - val_loss: 10.3718\n",
      "Epoch 1362/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.4365 - val_loss: 9.2600\n",
      "Epoch 1363/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.6023 - val_loss: 11.9548\n",
      "Epoch 1364/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.9722 - val_loss: 9.2825\n",
      "Epoch 1365/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1658 - val_loss: 14.2425\n",
      "Epoch 1366/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5778 - val_loss: 14.4286\n",
      "Epoch 1367/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.6919 - val_loss: 13.6256\n",
      "Epoch 1368/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.8428 - val_loss: 14.8941\n",
      "Epoch 1369/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.6162 - val_loss: 14.0420\n",
      "Epoch 1370/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.5760 - val_loss: 16.5386\n",
      "Epoch 1371/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.8319 - val_loss: 11.8942\n",
      "Epoch 1372/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.4286 - val_loss: 13.0719\n",
      "Epoch 1373/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.6828 - val_loss: 11.3376\n",
      "Epoch 1374/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5729 - val_loss: 11.6540\n",
      "Epoch 1375/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.9868 - val_loss: 20.5186\n",
      "Epoch 1376/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.7167 - val_loss: 16.8828\n",
      "Epoch 1377/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.7701 - val_loss: 12.8931\n",
      "Epoch 1378/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1381 - val_loss: 12.9802\n",
      "Epoch 1379/1500\n",
      "87/87 [==============================] - ETA: 0s - loss: 8.5662 - 0s 1ms/step - loss: 8.5834 - val_loss: 20.8053\n",
      "Epoch 1380/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3604 - val_loss: 22.0786\n",
      "Epoch 1381/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.7561 - val_loss: 10.0037\n",
      "Epoch 1382/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.3192 - val_loss: 9.2747\n",
      "Epoch 1383/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 8.8700 - val_loss: 17.0624\n",
      "Epoch 1384/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.0049 - val_loss: 13.2459\n",
      "Epoch 1385/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3072 - val_loss: 15.7458\n",
      "Epoch 1386/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2316 - val_loss: 10.0121\n",
      "Epoch 1387/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.0515 - val_loss: 15.8678\n",
      "Epoch 1388/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3985 - val_loss: 7.3690\n",
      "Epoch 1389/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.5671 - val_loss: 24.9407\n",
      "Epoch 1390/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3027 - val_loss: 9.7313\n",
      "Epoch 1391/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 7.9006 - val_loss: 26.6786\n",
      "Epoch 1392/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.1101 - val_loss: 12.8209\n",
      "Epoch 1393/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 7.9451 - val_loss: 12.8465\n",
      "Epoch 1394/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 10.8942 - val_loss: 19.5484\n",
      "Epoch 1395/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.3803 - val_loss: 11.5744\n",
      "Epoch 1396/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.6129 - val_loss: 9.7312\n",
      "Epoch 1397/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.3845 - val_loss: 14.7450\n",
      "Epoch 1398/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.7614 - val_loss: 8.7356\n",
      "Epoch 1399/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.1718 - val_loss: 11.4076\n",
      "Epoch 1400/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2262 - val_loss: 19.0599\n",
      "Epoch 1401/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.7464 - val_loss: 10.7218\n",
      "Epoch 1402/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.0677 - val_loss: 11.3369\n",
      "Epoch 1403/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 7.8307 - val_loss: 14.6521\n",
      "Epoch 1404/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.8137 - val_loss: 15.5109\n",
      "Epoch 1405/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.5266 - val_loss: 16.0783\n",
      "Epoch 1406/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 1ms/step - loss: 8.9219 - val_loss: 19.0499\n",
      "Epoch 1407/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.4257 - val_loss: 14.4159\n",
      "Epoch 1408/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.6513 - val_loss: 11.5762\n",
      "Epoch 1409/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.2817 - val_loss: 13.8373\n",
      "Epoch 1410/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.8249 - val_loss: 10.3057\n",
      "Epoch 1411/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.2457 - val_loss: 12.9646\n",
      "Epoch 1412/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.4317 - val_loss: 12.3821\n",
      "Epoch 1413/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.9389 - val_loss: 15.5802\n",
      "Epoch 1414/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5532 - val_loss: 11.3063\n",
      "Epoch 1415/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.4044 - val_loss: 20.1137\n",
      "Epoch 1416/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.5850 - val_loss: 7.4169\n",
      "Epoch 1417/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.5723 - val_loss: 14.1884\n",
      "Epoch 1418/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.7083 - val_loss: 9.0631\n",
      "Epoch 1419/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.5043 - val_loss: 13.7690\n",
      "Epoch 1420/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5143 - val_loss: 18.7139\n",
      "Epoch 1421/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 7.3609 - val_loss: 11.2791\n",
      "Epoch 1422/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1801 - val_loss: 6.8038\n",
      "Epoch 1423/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2402 - val_loss: 11.4906\n",
      "Epoch 1424/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 7.7542 - val_loss: 13.5864\n",
      "Epoch 1425/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 8.5376 - val_loss: 14.0802\n",
      "Epoch 1426/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.1371 - val_loss: 12.7282\n",
      "Epoch 1427/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.3953 - val_loss: 18.5079\n",
      "Epoch 1428/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.8582 - val_loss: 12.2033\n",
      "Epoch 1429/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.6757 - val_loss: 17.9818\n",
      "Epoch 1430/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.1080 - val_loss: 14.1858\n",
      "Epoch 1431/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2159 - val_loss: 14.6462\n",
      "Epoch 1432/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 8.4986 - val_loss: 14.8410\n",
      "Epoch 1433/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.4264 - val_loss: 9.8380\n",
      "Epoch 1434/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.8435 - val_loss: 18.7177\n",
      "Epoch 1435/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.8639 - val_loss: 10.2258\n",
      "Epoch 1436/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.7549 - val_loss: 10.6967\n",
      "Epoch 1437/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.1286 - val_loss: 29.1662\n",
      "Epoch 1438/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.2236 - val_loss: 27.3009\n",
      "Epoch 1439/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.4125 - val_loss: 10.1655\n",
      "Epoch 1440/1500\n",
      "87/87 [==============================] - 0s 977us/step - loss: 8.7635 - val_loss: 9.5158\n",
      "Epoch 1441/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.6289 - val_loss: 18.8421\n",
      "Epoch 1442/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.3040 - val_loss: 25.9860\n",
      "Epoch 1443/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.1803 - val_loss: 20.4218\n",
      "Epoch 1444/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1671 - val_loss: 19.8150\n",
      "Epoch 1445/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.6841 - val_loss: 8.4261\n",
      "Epoch 1446/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.0843 - val_loss: 14.3064\n",
      "Epoch 1447/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.5811 - val_loss: 16.6406\n",
      "Epoch 1448/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.2298 - val_loss: 8.0059\n",
      "Epoch 1449/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.5286 - val_loss: 13.9522\n",
      "Epoch 1450/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3689 - val_loss: 15.9752\n",
      "Epoch 1451/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 7.1600 - val_loss: 14.5565\n",
      "Epoch 1452/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2943 - val_loss: 13.2440\n",
      "Epoch 1453/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.6507 - val_loss: 11.5090\n",
      "Epoch 1454/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 7.9442 - val_loss: 14.4012\n",
      "Epoch 1455/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.9281 - val_loss: 10.0031\n",
      "Epoch 1456/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.3988 - val_loss: 12.4142\n",
      "Epoch 1457/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.2931 - val_loss: 11.0206\n",
      "Epoch 1458/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.5703 - val_loss: 16.6909\n",
      "Epoch 1459/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.9469 - val_loss: 14.8901\n",
      "Epoch 1460/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.8652 - val_loss: 15.7841\n",
      "Epoch 1461/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.0263 - val_loss: 14.3906\n",
      "Epoch 1462/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.1301 - val_loss: 20.1608\n",
      "Epoch 1463/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.5976 - val_loss: 15.2772\n",
      "Epoch 1464/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.8860 - val_loss: 14.2146\n",
      "Epoch 1465/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.7866 - val_loss: 13.8741\n",
      "Epoch 1466/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.3087 - val_loss: 19.6489\n",
      "Epoch 1467/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 15.1880 - val_loss: 12.0652\n",
      "Epoch 1468/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.2293 - val_loss: 12.9362\n",
      "Epoch 1469/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.0085 - val_loss: 10.0733\n",
      "Epoch 1470/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.4084 - val_loss: 16.8816\n",
      "Epoch 1471/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.3708 - val_loss: 10.1329\n",
      "Epoch 1472/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.7928 - val_loss: 18.5315\n",
      "Epoch 1473/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2355 - val_loss: 19.6042\n",
      "Epoch 1474/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 7.9685 - val_loss: 14.1558\n",
      "Epoch 1475/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.6000 - val_loss: 8.6300\n",
      "Epoch 1476/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.4785 - val_loss: 12.0147\n",
      "Epoch 1477/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 7.5253 - val_loss: 13.1509\n",
      "Epoch 1478/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.9916 - val_loss: 13.7591\n",
      "Epoch 1479/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.3953 - val_loss: 12.0043\n",
      "Epoch 1480/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.3335 - val_loss: 10.6094\n",
      "Epoch 1481/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.7279 - val_loss: 14.9361\n",
      "Epoch 1482/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.2512 - val_loss: 13.0498\n",
      "Epoch 1483/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 7.7211 - val_loss: 14.2090\n",
      "Epoch 1484/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.2462 - val_loss: 16.9130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1485/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.6500 - val_loss: 9.7366\n",
      "Epoch 1486/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.2638 - val_loss: 9.6539\n",
      "Epoch 1487/1500\n",
      "87/87 [==============================] - 0s 1000us/step - loss: 7.4797 - val_loss: 20.4515\n",
      "Epoch 1488/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.0083 - val_loss: 23.5118\n",
      "Epoch 1489/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.7650 - val_loss: 11.0666\n",
      "Epoch 1490/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.3244 - val_loss: 15.5655\n",
      "Epoch 1491/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.4516 - val_loss: 8.0124\n",
      "Epoch 1492/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.3678 - val_loss: 11.0296\n",
      "Epoch 1493/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.0761 - val_loss: 14.7269\n",
      "Epoch 1494/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 7.8235 - val_loss: 10.7371\n",
      "Epoch 1495/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 7.9018 - val_loss: 9.4792\n",
      "Epoch 1496/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 9.1972 - val_loss: 12.5238\n",
      "Epoch 1497/1500\n",
      "87/87 [==============================] - 0s 988us/step - loss: 9.1542 - val_loss: 11.2712\n",
      "Epoch 1498/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.6742 - val_loss: 8.6695\n",
      "Epoch 1499/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.0415 - val_loss: 26.4871\n",
      "Epoch 1500/1500\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 8.3114 - val_loss: 9.2161\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train,\n",
    "          batch_size=2, epochs=1500,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd5xU1f3/8ddnCyy9IwooqFiwwYoGawgaY0ksP4lKLNhjSTQxRtHk6xf9aoK9JPZuLNgVewWNDQUVVJAiUpa61KVtnfP749zZmdm9W9nZHbzv5+Mxj7n33DtzP3N3Zz73nHvuueacQ0REBCCrpQMQEZHMoaQgIiKVlBRERKSSkoKIiFRSUhARkUpKCiIiUklJQaSBzKyfmTkzy6nHuqeb2Ueb+z4izUVJQX7SzGyemZWaWfcq5V8HP8j9WiYykcykpCBR8CMwMj5jZnsAbVouHJHMpaQgUfAf4LSk+VHAY8krmFknM3vMzArNbL6Z/d3MsoJl2WZ2k5mtMLO5wFEhr33QzJaY2SIzu9bMshsapJltY2bjzWyVmc0xs3OSlu1rZpPNrMjMlpnZLUF5npk9bmYrzWyNmX1hZls1dNsicUoKEgWfAR3NbNfgx/pE4PEq6/wL6ARsD/wcn0TOCJadA/waGAwMAUZUee2jQDmwY7DOYcDZjYjzKaAA2CbYxj/M7JBg2e3A7c65jsAOwDNB+agg7r5AN+A8YFMjti0CKClIdMRrC78EvgcWxRckJYornHPrnHPzgJuBU4NVTgBuc84tdM6tAv6Z9NqtgCOAPznnNjjnlgO3Aic1JDgz6wscCFzunCt2zn0NPJAUQxmwo5l1d86td859llTeDdjROVfhnJvinCtqyLZFkikpSFT8B/gdcDpVmo6A7kArYH5S2XygdzC9DbCwyrK47YBcYEnQfLMGuBfo2cD4tgFWOefW1RDDWcBOwPdBE9Gvkz7XW8A4M1tsZjeYWW4Dty1SSUlBIsE5Nx9/wvlI4IUqi1fgj7i3SyrblkRtYgm+eSZ5WdxCoATo7pzrHDw6Oud2a2CIi4GuZtYhLAbn3Gzn3Eh8srkeeM7M2jnnypxzVzvnBgL745u5TkOkkZQUJErOAoY75zYkFzrnKvBt9NeZWQcz2w64hMR5h2eAi8ysj5l1AUYnvXYJ8DZws5l1NLMsM9vBzH7ekMCccwuBT4B/BieP9wzifQLAzE4xsx7OuRiwJnhZhZn9wsz2CJrAivDJraIh2xZJpqQgkeGc+8E5N7mGxX8ENgBzgY+AJ4GHgmX345topgJfUr2mcRq++Wk6sBp4Dti6ESGOBPrhaw0vAv/rnHsnWHY48J2ZrcefdD7JOVcM9Aq2VwTMAD6g+kl0kXoz3WRHRETiVFMQEZFKSgoiIlJJSUFERCopKYiISKUtesje7t27u379+rV0GCIiW5QpU6ascM71CFu2RSeFfv36MXlyTT0MRUQkjJnNr2mZmo9ERKSSkoKIiFRSUhARkUpb9DkFEZH6Kisro6CggOLi4pYOpdnk5eXRp08fcnPrP3CukoKIREJBQQEdOnSgX79+mFlLh5N2zjlWrlxJQUEB/fv3r/fr1HwkIpFQXFxMt27dIpEQAMyMbt26NbhmpKQgIpERlYQQ15jPG8mk8MW8Vdzy9kxKy2MtHYqISEaJZFL4cv5q7nh/DuUxJQURaR4rV65k0KBBDBo0iF69etG7d+/K+dLS0nq9xxlnnMHMmTPTGqdONIuININu3brx9ddfAzBmzBjat2/PpZdemrKOcw7nHFlZ4cfrDz/8cNrjjGRNIU73FxKRljZnzhx23313zjvvPPLz81myZAnnnnsuQ4YMYbfdduOaa66pXPfAAw/k66+/pry8nM6dOzN69Gj22msv9ttvP5YvX94k8USyphCxc00iUsXVr3zH9MVFTfqeA7fpyP/+ZrdGvXb69Ok8/PDD3HPPPQCMHTuWrl27Ul5ezi9+8QtGjBjBwIEDU16zdu1afv7znzN27FguueQSHnroIUaPHh329g0S6ZqCiEgm2GGHHdhnn30q55966iny8/PJz89nxowZTJ8+vdpr2rRpwxFHHAHA3nvvzbx585oklkjWFOLUeiQSTY09ok+Xdu3aVU7Pnj2b22+/nc8//5zOnTtzyimnhF5r0KpVq8rp7OxsysvLmySWSNYUDLUfiUhmKioqokOHDnTs2JElS5bw1ltvNev2I11TEBHJNPn5+QwcOJDdd9+d7bffngMOOKBZt29uC+6CM2TIENeYm+zc/+Fcrnt9Bt+MOYwOefUfKEpEtlwzZsxg1113bekwml3Y5zazKc65IWHrR7P5SK1HIiKhIpkUREQkXKSTwpbbcCYikh6RTgoiIpJKSUFERCpFOilswR2vRETSIu1JwcyyzewrM3s1mO9vZpPMbLaZPW1mrYLy1sH8nGB5vzTGlK63FhEJNWzYsGoXot12221ccMEFNb6mffv26Q6rmuaoKVwMzEiavx641Tk3AFgNnBWUnwWsds7tCNwarCci8pMwcuRIxo0bl1I2btw4Ro4c2UIRhUtrUjCzPsBRwAPBvAHDgeeCVR4Fjg2mjwnmCZYfYuk+pFfzkYg0kxEjRvDqq69SUlICwLx581i8eDGDBg3ikEMOIT8/nz322IOXX365ReNM9zAXtwGXAR2C+W7AGudcfOSmAqB3MN0bWAjgnCs3s7XB+iuS39DMzgXOBdh2220bFZQaj0Qi7o3RsPSbpn3PXnvAEWNrXNytWzf23Xdf3nzzTY455hjGjRvHiSeeSJs2bXjxxRfp2LEjK1asYOjQoRx99NEt1sydtpqCmf0aWO6cm5JcHLKqq8eyRIFz9znnhjjnhvTo0aMJIhURaR7JTUjxpiPnHFdeeSV77rknhx56KIsWLWLZsmUtFmM6awoHAEeb2ZFAHtARX3PobGY5QW2hD7A4WL8A6AsUmFkO0AlYlcb4cGo/EommWo7o0+nYY4/lkksu4csvv2TTpk3k5+fzyCOPUFhYyJQpU8jNzaVfv36hQ2U3l7TVFJxzVzjn+jjn+gEnAe87504GJgAjgtVGAfEGtPHBPMHy912aRutT5yMRaQnt27dn2LBhnHnmmZUnmNeuXUvPnj3Jzc1lwoQJzJ8/v0VjbInrFC4HLjGzOfhzBg8G5Q8C3YLyS4DNv6+ciEiGGTlyJFOnTuWkk04C4OSTT2by5MkMGTKEJ554gl122aVF42uW+yk45yYCE4PpucC+IesUA79tjngS22zOrYmIwHHHHUdyI0j37t359NNPQ9ddv359c4VVKZJXNKv1SEQkXCSTgoiIhIt0UlDrkUi0bMl3mmyMxnzeSCYFjX0kEj15eXmsXLkyMonBOcfKlSvJy8tr0Oua5USziEhL69OnDwUFBRQWFrZ0KM0mLy+PPn36NOg1kU4KUTliEBHIzc2lf//+LR1Gxoto81FLRyAikpkimRRERCRcpJOCGo9ERFJFMimo9UhEJFwkk4KIiISLdFJQ5yMRkVTRTArqfiQiEiqaSUFEREJFOinozmsiIqkimRTUeCQiEi6SSUFERMJFOymo9UhEJEUkk4I6H4mIhItkUhARkXCRTgpqPRIRSRXJpGDqfyQiEiqSSUFERMJFOilo7CMRkVSRTArqfSQiEi6SSUFERMJFOilo7CMRkVSRTApqPRIRCRfJpCAiIuEinRTU+0hEJFUkk4J6H4mIhItkUhARkXCRTgpqPRIRSRXJpKCxj0REwkUyKYiISLhIJwWn7kciIinSlhTMLM/MPjezqWb2nZldHZT3N7NJZjbbzJ42s1ZBeetgfk6wvF+6YlPrkYhIuHTWFEqA4c65vYBBwOFmNhS4HrjVOTcAWA2cFax/FrDaObcjcGuwnoiINKO0JQXnrQ9mc4OHA4YDzwXljwLHBtPHBPMEyw8xS+8VBWo9EhFJldZzCmaWbWZfA8uBd4AfgDXOufJglQKgdzDdG1gIECxfC3RLS1zpeFMRkZ+AtCYF51yFc24Q0AfYF9g1bLXgOey3utqxvJmda2aTzWxyYWFh0wUrIiLN0/vIObcGmAgMBTqbWU6wqA+wOJguAPoCBMs7AatC3us+59wQ59yQHj16pDt0EZFISWfvox5m1jmYbgMcCswAJgAjgtVGAS8H0+ODeYLl77s09RlN86kKEZEtVk7dqzTa1sCjZpaNTz7POOdeNbPpwDgzuxb4CngwWP9B4D9mNgdfQzgpjbGJiEiItCUF59w0YHBI+Vz8+YWq5cXAb9MVTxj1PhIRSRXJK5rVeCQiEi6SSUFERMJFOik4DZ4tIpIikklBnY9ERMJFMinE6USziEiqSCcFERFJFcmkoOYjEZFwkUwKcWo9EhFJFemkICIiqSKZFEyXr4mIhIpkUojTPZpFRFJFMinoRLOISLhIJgUREQkX6aSgxiMRkVSRTgoiIpJKSUFERCpFOimo85GISKpIJgXdo1lEJFwkk4KIiISLeFJQ+5GISLJIJgU1HomIhItkUhARkXD1SgpmtoOZtQ6mh5nZRWbWOb2hpZ96H4mIpKpvTeF5oMLMdgQeBPoDT6YtqjRT5yMRkXD1TQox51w5cBxwm3Puz8DW6QtLRERaQn2TQpmZjQRGAa8GZbnpCan5qPVIRCRVfZPCGcB+wHXOuR/NrD/wePrCSi/dZEdEJFxOfVZyzk0HLgIwsy5AB+fc2HQGJiIiza++vY8mmllHM+sKTAUeNrNb0hta+qn3kYhIqvo2H3VyzhUB/w942Dm3N3Bo+sJKL/U+EhEJV9+kkGNmWwMnkDjRLCIiPzH1TQrXAG8BPzjnvjCz7YHZ6QureTj1PxIRSVHfE83PAs8mzc8Fjk9XUOmm1iMRkXD1PdHcx8xeNLPlZrbMzJ43sz7pDk5ERJpXfZuPHgbGA9sAvYFXgrItmnofiYikqm9S6OGce9g5Vx48HgF6pDGutFLvIxGRcPVNCivM7BQzyw4epwAr0xmYiIg0v/omhTPx3VGXAkuAEfihL2pkZn3NbIKZzTCz78zs4qC8q5m9Y2azg+cuQbmZ2R1mNsfMpplZfuM/Vv2o+UhEJFW9koJzboFz7mjnXA/nXE/n3LH4C9lqUw78xTm3KzAUuNDMBgKjgfeccwOA94J5gCOAAcHjXODuhn+c+lL7kYhImM2589oltS10zi1xzn0ZTK8DZuBPUh8DPBqs9ihwbDB9DPCY8z4DOgcXzImISDPZnKRQ78NtM+sHDAYmAVs555aATxxAz2C13sDCpJcVBGVV3+tcM5tsZpMLCwsbF3lAF6+JiKTanKRQr19UM2uPv3Pbn4Lxk2pctT7bcM7d55wb4pwb0qNH4zpAqfeRiEi4Wq9oNrN1hP/4G9Cmrjc3s1x8QnjCOfdCULzMzLZ2zi0JmoeWB+UFQN+kl/cBFte1DRERaTq11hSccx2ccx1DHh2cc3UlFMPfz3mGcy55mO3x+Du4ETy/nFR+WtALaSiwNt7MlC7qfSQikqpeYx810gHAqcA3ZvZ1UHYlMBZ4xszOAhYAvw2WvQ4cCcwBNlJHl9fNodYjEZFwaUsKzrmPqPn395CQ9R1wYbriERGRum3OiWYREfmJiWRSMHU/EhEJFcmkICIi4SKdFNT7SEQkVSSTghqPRETCRTIpiIhIuEgnBY19JCKSKpJJQZ2PRETCRTIpiIhIuEgnBfU+EhFJFcmkoOYjEZFwkUwKIiISLtJJQa1HIiKpIpkUTJeviYiEimRSEBGRcJFMCj3nv8KzrcbgKspbOhQRkYwSyaSQFStjn6xZ5K2d29KhiIhklEgmhU3t+wCQs6mwhSMREckskUwKLqsVAFZR0sKRiIhklogmhVwALFbWwpGIiGSWSCaFWHZQU1BSEBFJEcmkUFlTqCht4UhERDJLNJNCdmsArEI1BRGRZJFMCrHKcwqqKYiIJItkUog3H2Wp+UhEJEU0k0LliWYlBRGRZNFMCjrRLCISKppJwXIAdUkVEakqkknBsowSl6veRyIiVUQyKQCUkkOWzimIiKSIbFIoIxuUFEREUkQyKRhGKblkqflIRCRFJJMCQJnLUZdUEZEqIpsUimlFVvmmlg5DRCSjRDIpmEERbckuXdfSoYiIZJRIJgWAta4dOSVrWzoMEZGMEt2kQDuyS5UURESSpS0pmNlDZrbczL5NKutqZu+Y2ezguUtQbmZ2h5nNMbNpZpafrrgAjKCmoKQgIpIinTWFR4DDq5SNBt5zzg0A3gvmAY4ABgSPc4G70xgXEK8prINYLN2bEhHZYqQtKTjnPgRWVSk+Bng0mH4UODap/DHnfQZ0NrOt0xVbdpZR5NpiOCgpStdmRES2OM19TmEr59wSgOC5Z1DeG1iYtF5BUFaNmZ1rZpPNbHJhYWGjgtihZ3tK8SOl0tAL2JyD1y6FRV82atsiIpksU040W0iZC1vROXefc26Ic25Ijx49GrWxTm1yKcOPlEp8+OxYBaz6se4XlxTBF/fDY8c0atsiIpmsuZPCsnizUPC8PCgvAPomrdcHWJyuIHKzsyi3eE0hSAoTx8Idg+CLB2DtonRtWkQkozV3UhgPjAqmRwEvJ5WfFvRCGgqsjTczpYsFd1+rbD768UP//Npf4I7B8PHttZ+EdqEVGRGRLVo6u6Q+BXwK7GxmBWZ2FjAW+KWZzQZ+GcwDvA7MBeYA9wMXpCuuStnxmkJJUJD0I19RAu9cBXPeCXlhWEtXBikvhdKNLR2FiGyhctL1xs65kTUsOiRkXQdcmK5YQmW3ghiJ5qMw5cX++aadYOcj4Te3kUgeGVpTuH84LPsGxugaDBFpuEw50dzsOrTN8xMLJtW98vplMOVhP53pzUbLvmnpCERkCxbZpNCvYzAx8Z/+OfTHPqSpyOliNxH56YpsUliy9aEAuL1PD0rCkkJIWTx5ZHqNQUSkESKbFLq0z6PItaGstKTulVMoGYjIT1dkk0LXdq3paJvInv5Cw15Y2Xyk5CAiPz0RTgq+S2r2xkIoLqp/c5CajUTkJyyySaFL21aJmadPJvTIP2xcpHhNoWyjv8Atbtl3cOdQ2LSmSeMUEWlOkU0KXdu14tnyg/3Moi/DawDPnwVLv61SmLTeO1clpif8AwpnJK6MFhHZAkU6KWRZ/Ae+lquU7zkgdb6mLqlZ2cHyis2OTUSkpUQ2KbRvnUMWwQ98bVc1JxvTCW7dLXyZBUkhVo+kcPOufuC95rZpDbx/LVSUN/+2RWSLENmkYGbMivmBWStatWezexOVbvDP9TkRvW6xH3ivub39d/jwRvj+lebftohsESKbFACGnno1AIVdBm9er6Il02D2W366riueW7L3Utkm/6yagojUINJJYY++XZka256S4k2Nf5OyYrj3oMS8q4CVP9T8w1tX89LVXWHcyY2Pp17qSEzOpe/e1SXrdDJeJINFOil0aZtLRVZrFheupnB9Q69sDly3Ver8qh/hX/nw3tXh69d1ItpVwPevwnXBLapjMf9oiqN7q8ew3xtWwrOj4Joum7+9MC+cC4/+BtYtS8/7i8hmSdvQ2VsCM2NdRS6dbANlRaub5lYJ64Ibxs3/pPqyTWtgRlJ7/vpCWDPf/1i/eQUce3diWVlwT4RrulJ5ZH/pbGjfk1CxCt+Ftj7e+hvseUL18oVfwIOH1u89GmtZ0MW3fDNqZyKSNpFOCgAV2a0ZxLSme8OvHvfP5cW+t9LxD8IeI3zZSxfAzNcS6943DIoKEvP/yg95w6SmnrUFNSeFdUvguxfrCC7IehuCu6A+PgK22x8OusTPL51ax+ubQNWWq9XzfM+tzn3D1haRZhbp5iOAg7Zrl543jh8RP38WfHCjb6dfMz91neSEUB/xayHChN1tLVYB5bU0i815J7WZq1lPggcJ6va94Lbdm3G7IlKbyCeF3A7d07+RCdfC1Z2hdP3mvU9N3VinPAp37lO9/MkT4NqefriO4rU0uNvtvI9g3dK61/viQX9yvT6K43eE0xhSIpko8s1HDP87fPtc82xr4+rNe33BF/5ofupTsOvRvjby0K+gfa/q6zoHc9710/8XJL6cvIZt75GjoP1WcOmsmteJVcBrl0DbbnDZ3Lrfs2RtIj4RyThKCh23ab5t7TAMpr9c//WnPl297LsX4aXzoXBm4krs9SFH81d3rl4Wv+c0+JPK9bG+jl5CsaBX1MaVwTZKoWwDtAnpvfTs6Ylp3cFOJCNFvvmInNbNt621ixq2/sR/VC977gz/XF7ij84bK6yXUWOO3mNVusqOGwnX90vMT3vGX5fgXOqJ8LDrNWa+4a/7qK8nT4QnT2pQuBJi5hu+U0R9mwDlJ01JoTmVFDVw/VrOQSz9Blq137x4kjkHs99u2GuWTPMXoyWLN1ktmw535MML5/jrEv57c5XtVfh14gqmwFMnwVtX1m/b5aUw602Y9UairKLMJ4pFX4a/Zuq46P7wlZf44d3DxHvMLas6IrBEkZIC0DQXKNRDeQOOggE2rqh52fyPIKdVzcsbaupTvjdSbWIxeHeM70a6abW/kvul8xPL1yb1pnrhHFiV9ANctdksVuETW9ymVf559Y+J9dcvh+Xfh8cy8/XqZStm+UTx0gXhr3nx93DvweHLfupeuwTu3j+840A8sTflQcaWrGQ9XNMdvg/5H4sAJQWAP3wBJzfDyeY1C5r2/f57a9O8z+f3136NQ1FwQd6KmfDRrb4b6V37+bIf3k+slzyCbNWjzuzc1PmHDofxf6i+rU2rYdqz8MxpcNMAuOtnicEGk5UldcF9d4xv/rh7fz9ftetu4Uy/HHwPsOIqNbZYBUwfX735bPn3tdfWwpRuyMyrtRd85p+r1uwgsX9z21RfNu9j/zdJp1gFTHkk/KZWLWHVDxArC2++jQAlBYDuA2DAL1PLLvq63i/frfjBJg6ontY2UZJ5/dLam45evQReuRjG/S5Rtm5Jw7aRVaVPQ+m61CHL49tf/BW8cHbquhP/6ZPWijnwyp+C6y+Sal0fVUmOy75NTSR37pu6fGxfP5zHmE6+O+/n98Ezp8K0pBP7sQqfkJ6uYxyqb5/37xV311C4eafaX9MUKsrggxsSXXyv7QXvX1fz+rWdL4oPvfLBDTA7qbZYVgyPHAlPjdz8eGvz5aP+/2vSPendTkNFtIOckkKyv8z0z0fdAl37J8rPfKvWl3Xq1IUFHcOuRv6JWPyVP5JbVY8upzVZOKn25Z/fV/OyT/7ley69eC5MeRiWToNX/1z7+714nn/+poYa4LOj/PMrF8Gbo/10ck1u3kf+ee5EmHRv6o/qhpV+xNmixfDcmYn3WjQl8R4Tko4yv30els+oHsOGlTWPaeVc7R0T5n8CE66D8Rf5+fJN8OENNa9fm/hnmzsBnhiRKI93IlgSXOm+cVXNzXn12cb65eHL4kk1qreyXTIVihp4kJVGSgrJOvSCMWthn2AMoXgb6zb5MHoB9P95Yt380yonP7niEPpc+Bor8//YjME2nxJXy5XUzSn+xVlQR4IBmDEe/tm35vGgwsam+uwuX3v45N/w2NGJ8jcuSzS/ANy4va993LKrn186DWa+CYuTapcfXO9/RDeu8onjrqGp2yrb5N/nzcv9SeD4+69b6o/Qv3wUbh2Y+p7JsoPzSWsWhI9ou2FFeHlojaGGQ+JY0JwTK/cn6O//ha89NcbkB31zYNXkOPMNf3EngNXyc7RkWs1JJW76eHj5D755cLOaouLnGOuoKqxZAM+fXXuPufp0bLj3YLhll3pHB6S1SU9JoTZnvwuHj/UndPM6wajx8Ltn/LI9UgeUy2rdlm5HX9sCQaZf6w0N7EqbLvHBBt+8vH7r19bbK2y02vgX7f2Qv2P8HEb8jnnJtYritfDUifDJHamvuaG/f4TZEHQimPYMPHCovwhxzUK4eWc/8m58O6uq/KjM/xQePdpfCwKwdiHMTTqvc8tAuPsAuHEH3+xW1V1Dq/9Q1dS0FK/FVJT6cblWz0ssi8V8T7Pb9/LnpMIkn9SeE8S4aIrvORb34u8T07UlhXsPSjQDrlvmm/diMbh9kK+JgW8C/Oo/vnnw6VP9j3VZLQMvjjsZZtXeCgD4/TPhn/7cFMB3L/m/1et/hW+eTT2vluzz+/1+q6m2WtW7NYysXNV3L/pu3wVT6rd+Aykp1KbnrjD0/NSynX7laxP9DoTctjD8f+p+n+OTzjns8uva173sR+i0bcNjDVF8+eImeZ/IiJ/3CBvBtWwjPH9O7XfMS/7RrM2YTonxnmIVvqYBqWNAxXtmZbfyP0pzP/AniV84B378IBHHhkJ4/PjE64oWJU7yf3iDH4LkzaRuvq7Cn4NJuU6kSlIY0wme+l3Nvd/eucrXpB4/3n/m1y/15SXr/DmfTWugYLJPcPELMOPDtr98ITww3H+mD29KGvYEnxTWLEjU4pyDz+5JrLNptW9qunkn35tq6VTfW+3lkBr6rDf8/ryuFzx2LEy8PrUHXEW5H6L+yRN8TW38HxPNdWsXpr7XptXwwVj4z3Gw9FvfXPjIUTUnU+d8zPH9svir8PWq+uiW2pfPetvv37kT/XyaBrDUFc2NZQZ/C2kHPP5B3wxx9nuJq4p3P97/420/LPUod6cj/D/v4FN8X3HLhrZd4Y9T4NoeifV67el/OA66FP57U80x5eQlTsAedh15bdI02N9PVdUL8ZI9fcrmv3+8B1SyspCeVbVtNy/4n6pvAnotGAG3dcdEWUWpb8rZuBJOGx/eSjLztdQRfZN9fHt4+Yc3+XM+uW2hV5Dg5rwLe52Y+gO69Bt/lF71/YvXwG17+OnRC/1Fj29e7nuXxcVrFlMe8Q/w+3BGyC1mNxT657kT/AP8Qdlvbk/taTX7bfjyMVg933+H4ndRXPYtjN3OtxaAT7j3HOCn18xPGg0h6bNtXOVHP04e/DL5s8diPpF126F6vMnWLfUHBG26JBLqk7/1z/mjqr9vE1JSaGp7jEgMlX3lYsjK9X/UwUEvln4H+3/gi6dBXkd/JLX36XDMnYn3yGkF5070/xg7H+HLCmdC952gzz5+ZNPl0+HIm/zQ13mdfBtqx96JZNK2q3/ObZto+shtB7+40lep+x8ML50HB/3Ft2cXzoSCzx/voZwAAA6sSURBVNO8c2SzFTfyZGxyU1pyL6uvHqdJutm8cnHiR/qzO+G3wXTZRt+cVbWLcljC+eyuxPRdQ/2PMKTW3Gq6lqa+Sfv7V6HbjnDAxYmy+PmHHz+ovn7xGv89CVMQDBWzZJpvDtx7lK9FVB0N+bM7Ez0F2wdNgwOPhV1/k0hcybFk5/paVlyPXeDCSanrpJGSQjq1CjlS3/ccf+SUFxw1Dq3hH26bwanzPYJ/kp0Phx2G+y/HLkdVf91Rt/ijw77BCcHL5gLmj4Z2+lXqsB4XBdXawUlfqOnjfdts647+h2Tb/WFB0knZA/+c2gX0iBv8idi4jn0SQ4JvvVei58q5E/0RVLITH6f8tb+Ssz49PS8uKzuHv+Y8Qw9bW/fKUVW6vmmOOOMJIe6rJ/zzoi8T54IaoiiN57HKNqV2h443xzRUvGb5QVCT6Puzmm81W7UmM/0l/6jqtb/AwGNSywq/Tz0PlOYbVJnbgkerHDJkiJs8eXJLh5FZYjE/EmnYgHQN4Zw/InEx35Nnh+H+n3O7A+DDG313SIC/L/fTu4/wo80Ov8q/5qXzYdgVvm31uxfgsGvhtj0TR0wDfgUnP+N7lHzxAEWrV7Bq1qeU7XEi6/oOJ/buNQwpqn5UeEPZCVyW60/2/6PiNK7Mfqxy2QWlF9HfljLb9ebtmB9KvCMbmJZ3Tq0f9YnyQxicNYeBWalHeGeX/oUHWt1cw6vCvVIxlN9kf1b3iiKb66hbEj0lG8jMpjjnhoQuU1KQRhnTqe5htauaeL2/SvRP3/rX1jVMxw8TfNV5xiv+qOzTf8M5E3yz26Ip0Kkv3L4ntO/FosGXcOfa/ShcX8o5B23P3tt1YX1JOU9OWsCeC5/ggB9u5u6skzi4+zp2KvqM3GLfN/7F/mN4ZN0+DBvQhb6L3mTEgmsqN9+v+Am+bP17KsjmirKzKxPETWW/5e3YEN5undoL6tnyg/lr+XnMy0tc5Pez4n9zes5bnJ/jjxSnxAawd9bsyuX/WzaKCrK4NvdhAO4vP5Jzcl7nurLf8XTFLyoT2mrXnhJy6WXVuyJudK25sOwiHm51Y33/EvJTcNTNsM/Zda8XQklBmt6GFb4pqnWH+r/GOf/jXnXIi80Rq6j9jnTx7VaUJprOKsqD7qeu+u1Nnz/Hd/k777++95lzYEZJeQWtzVG8sYjJS2O0a53Nrj1aU7F2ERUVFXS8/2csOuFNxkzOZdCad7hw1ViWHvccxb33Z+LM5cyaNYNOq6ay0/BT2b/8C7Z67XQA9uAZ/jh8R0rmfcGy0tY8PieRKLu2a8U1pTcyPdaPuyqOYYh9T/+spfS3pUyO7cQHsb2oIPWz51LO4Vmf824sHwOm551Zuexf5cfyx5zqTRZfxXZkcNacOnf1xxW78X5sMP+T+3id6zbENWWnclXuf2pcPjPWh52zEuNq3VV+NBfkjG/SGBprY1Z72sY28+ZZjeSOvBnbV0khhZKCbLGmPg1bDYReezTq5ZtKK2jTKjUhlFfEcEDRpjK6tmuFmfmTmm+Mpvy3jzKr00H0yllH0ccPUFK0ku7rZ7Jku18zrccxDJn8F3Yq9EONjN76AU7dZgm7TUl0t7607PfM63Msk+evYl6e7zSxIrsnC8s6piSU6bHtuKV8BP/MvZ8elnqdSMwZWZb4vSlybZkU24Vzyi4l32ZxdPYnPF9xMGfmvMFx2R8DcEDx7SyiB3mUUEw8YRozW4+itSVOuD5c/ivmuN4My/qaVpTz82zfzbfCGdnmeLp8GCfmTKy2H9+u2JvDsqfwRWwn/qfsTMrJ4rycVxmRXcO5gSp2Ln6EXWwBL7e+CoC9i++mp63hjdZXVFv3qJJ/8EirsSn7Jay5sci14YzSy1hH22q10WQzBl/FrsfU0kW6FkoKItJw370E2+4HCz71nRriNbxnT/ddO/cYQfz3w6zKSMPFRX7k21U/wjaDoGQ9m4o30nrpV2S5cn/9wZlvUJzVlgWrNrLTVr7GGYs5srKMWMlGJv24ih1792Dp2mI2lVWwc68OzFuxgZ17dWDVu7exzaRrKD7gMnKGX8HGsgrmr9jIqo2lDOxmLB9/NRVDziavR3+mzV/BssKlXDj5CAq3Gc78wx6k10d/p8+cJ5h20ueUtenBD4UbuP/DuWzXrS2nd/iCA6ddwWVt/w+AQV2KGTNvd+7Z/mOGL/x35Uc8s/RS2ux+FL07t2HRvFm069yD+euMtq2ysU2r+feqc/i4ZAduLj+BYnKZ57amJ6v5PO9CAGbEtuWI0rHs0qsD69at47ayMUyoGMxdFcewffd2zF2xAXAcnfUJb8b2pZRc/pTzHItdNwa238jg4/7EXrs0bpytLSYpmNnhwO1ANvCAc25sbesrKYhEVOkGP77UsNH1b8KcO9H36ov3/IvFIKuG63fXLfXD3qTLqrnQtrs/P5ZkQ0k5bXKzycpK73D+W0RSMLNsYBbwS6AA+AIY6ZybXtNrlBRERBqutqSQScNc7AvMcc7Ndc6VAuOAY+p4jYiINKFMSgq9geRBRwqCshRmdq6ZTTazyYWFhVUXi4jIZsikpBDWiFatbcs5d59zbohzbkiPHj1CXiIiIo2VSUmhAOibNN8H0DCfIiLNKJOSwhfAADPrb2atgJOAzLhCRUQkIjJmQDznXLmZ/QF4C98l9SHn3HctHJaISKRkTFIAcM69Drze0nGIiERVJjUfiYhIC8uYi9caw8wKgfl1rhiuO1DD/QYzhmLcfJkeH2R+jJkeHyjGhtrOORfafXOLTgqbw8wm13RFX6ZQjJsv0+ODzI8x0+MDxdiU1HwkIiKVlBRERKRSlJPCfS0dQD0oxs2X6fFB5seY6fGBYmwykT2nICIi1UW5piAiIlUoKYiISKVIJgUzO9zMZprZHDMb3UIx9DWzCWY2w8y+M7OLg/KuZvaOmc0OnrsE5WZmdwQxTzOz/GaMNdvMvjKzV4P5/mY2KYjx6WCsKsysdTA/J1jerxli62xmz5nZ98G+3C/T9qGZ/Tn4G39rZk+ZWV5L70Mze8jMlpvZt0llDd5vZjYqWH+2mY1Kc3w3Bn/naWb2opl1Tlp2RRDfTDP7VVJ52r7rYTEmLbvUzJyZdQ/mm30fNppzLlIP/LhKPwDbA62AqcDAFohjayA/mO6Av+vcQOAGYHRQPhq4Ppg+EngDP8T4UGBSM8Z6CfAk8Gow/wxwUjB9D3B+MH0BcE8wfRLwdDPE9ihwdjDdCuicSfsQf0+QH4E2Sfvu9Jbeh8DBQD7wbVJZg/Yb0BWYGzx3Caa7pDG+w4CcYPr6pPgGBt/j1kD/4Pudne7veliMQXlf/Bhu84HuLbUPG/25WnLjLfKBYT/graT5K4ArMiCul/G3Ip0JbB2UbQ3MDKbvxd+eNL5+5XppjqsP8B4wHHg1+KdekfTlrNyfwRdhv2A6J1jP0hhbx+AH16qUZ8w+JHHzqK7BPnkV+FUm7EOgX5Uf3QbtN2AkcG9Secp6TR1flWXHAU8E0ynf4fg+bI7veliMwHPAXsA8EkmhRfZhYx5RbD6q1x3emlPQRDAYmARs5ZxbAhA89wxWa6m4bwMuA2LBfDdgjXOuPCSOyhiD5WuD9dNle6AQeDho3nrAzNqRQfvQObcIuAlYACzB75MpZM4+TNbQ/daS36Uz8Ufe1BJHs8dnZkcDi5xzU6ssypgY6xLFpFCvO7w1FzNrDzwP/Mk5V1TbqiFlaY3bzH4NLHfOTalnHM0dYw6++n63c24wsAHf7FGTltiHXfD3Gu8PbAO0A46oJY6M+v8M1BRTi8RqZn8DyoEn4kU1xNGs8ZlZW+BvwFVhi2uIJeP+3lFMChlzhzczy8UnhCeccy8ExcvMbOtg+dbA8qC8JeI+ADjazOYB4/BNSLcBnc0sPux6chyVMQbLOwGr0hhfAVDgnJsUzD+HTxKZtA8PBX50zhU658qAF4D9yZx9mKyh+63Z92dwIvbXwMkuaG/JoPh2wCf/qcF3pg/wpZn1yqAY6xTFpJARd3gzMwMeBGY4525JWjQeiPdAGIU/1xAvPy3oxTAUWBuv6qeLc+4K51wf51w//H563zl3MjABGFFDjPHYRwTrp+2oxzm3FFhoZjsHRYcA08mgfYhvNhpqZm2Dv3k8xozYh1U0dL+9BRxmZl2CGtFhQVlamNnhwOXA0c65jVXiPinoudUfGAB8TjN/151z3zjnejrn+gXfmQJ8Z5KlZMg+rJeWPKHRUg98T4BZ+J4Jf2uhGA7EVxOnAV8HjyPx7cfvAbOD567B+gbcGcT8DTCkmeMdRqL30fb4L90c4FmgdVCeF8zPCZZv3wxxDQImB/vxJXwPjozah8DVwPfAt8B/8L1kWnQfAk/hz3GU4X+8zmrMfsO37c8JHmekOb45+Pb3+PflnqT1/xbENxM4Iqk8bd/1sBirLJ9H4kRzs+/Dxj40zIWIiFSKYvORiIjUQElBREQqKSmIiEglJQUREamkpCAiIpWUFERqYWYVZvZ10qPJRto0s35hI2yKtKSculcRibRNzrlBLR2ESHNRTUGkEcxsnpldb2afB48dg/LtzOy9YMz898xs26B8q+AeAFODx/7BW2Wb2f3m77fwtpm1abEPJYKSgkhd2lRpPjoxaVmRc25f4N/4MaEIph9zzu2JH7DtjqD8DuAD59xe+PGZvgvKBwB3Oud2A9YAx6f584jUSlc0i9TCzNY759qHlM8Dhjvn5gYDGy51znUzsxX4exKUBeVLnHPdzawQ6OOcK0l6j37AO865AcH85UCuc+7a9H8ykXCqKYg0nqthuqZ1wpQkTVeg83zSwpQURBrvxKTnT4PpT/CjcQKcDHwUTL8HnA+V97zu2FxBijSEjkpEatfGzL5Omn/TORfvltrazCbhD65GBmUXAQ+Z2V/xd4U7Iyi/GLjPzM7C1wjOx4+wKZJRdE5BpBGCcwpDnHMrWjoWkaak5iMREamkmoKIiFRSTUFERCopKYiISCUlBRERqaSkICIilZQURESk0v8HgOLcKHsjYmIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"modelden.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"modelden.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "arr = []\n",
    "for x in range(len(X_scale)):\n",
    "    Xnew = array([[X_scale[x][0], X_scale[x][1] , X_scale[x][2], X_scale[x][3], X_scale[x][4], X_scale[x][5]]])\n",
    "    ynew = model.predict(Xnew)\n",
    "    #print(ynew[0][0])\n",
    "    arr.append(ynew[0][0])\n",
    "array = np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9760889628573626"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(Y.tolist(), array.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('tf': conda)",
   "language": "python",
   "name": "python37764bittfconda6cc65eca183d4342a640aa08d3d7781d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
