{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Interpolation/QLYS/InterpolatedDenWeekQLYS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATES</th>\n",
       "      <th>D Revenue</th>\n",
       "      <th>U CR</th>\n",
       "      <th>D OE</th>\n",
       "      <th>U NOI</th>\n",
       "      <th>U CAPEX</th>\n",
       "      <th>U WK</th>\n",
       "      <th>D FCF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>4479.720772</td>\n",
       "      <td>1283.851030</td>\n",
       "      <td>2201.862589</td>\n",
       "      <td>165.498382</td>\n",
       "      <td>2075.336663</td>\n",
       "      <td>23013.204073</td>\n",
       "      <td>4489.072600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-08</td>\n",
       "      <td>4451.483282</td>\n",
       "      <td>1294.720243</td>\n",
       "      <td>2188.701161</td>\n",
       "      <td>166.321882</td>\n",
       "      <td>2083.350715</td>\n",
       "      <td>22872.363692</td>\n",
       "      <td>4514.461229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-15</td>\n",
       "      <td>4423.245793</td>\n",
       "      <td>1305.589456</td>\n",
       "      <td>2175.539732</td>\n",
       "      <td>167.145382</td>\n",
       "      <td>2091.364766</td>\n",
       "      <td>22731.523312</td>\n",
       "      <td>4539.849859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-22</td>\n",
       "      <td>4395.008303</td>\n",
       "      <td>1316.458670</td>\n",
       "      <td>2162.378304</td>\n",
       "      <td>167.968883</td>\n",
       "      <td>2099.378817</td>\n",
       "      <td>22590.682931</td>\n",
       "      <td>4565.238488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-29</td>\n",
       "      <td>4366.770814</td>\n",
       "      <td>1327.327883</td>\n",
       "      <td>2149.216875</td>\n",
       "      <td>168.792383</td>\n",
       "      <td>2107.392868</td>\n",
       "      <td>22449.842550</td>\n",
       "      <td>4590.627117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>5784.971103</td>\n",
       "      <td>882.718109</td>\n",
       "      <td>2632.808061</td>\n",
       "      <td>334.189988</td>\n",
       "      <td>2125.110319</td>\n",
       "      <td>12126.998352</td>\n",
       "      <td>5656.224349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>5813.800870</td>\n",
       "      <td>863.462381</td>\n",
       "      <td>2641.668669</td>\n",
       "      <td>335.172784</td>\n",
       "      <td>2125.572740</td>\n",
       "      <td>11921.914455</td>\n",
       "      <td>5685.640889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>5842.630638</td>\n",
       "      <td>844.206653</td>\n",
       "      <td>2650.529277</td>\n",
       "      <td>336.155581</td>\n",
       "      <td>2126.035162</td>\n",
       "      <td>11716.830559</td>\n",
       "      <td>5715.057429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>5871.460405</td>\n",
       "      <td>824.950925</td>\n",
       "      <td>2659.389885</td>\n",
       "      <td>337.138378</td>\n",
       "      <td>2126.497583</td>\n",
       "      <td>11511.746663</td>\n",
       "      <td>5744.473970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>5900.290173</td>\n",
       "      <td>805.695197</td>\n",
       "      <td>2668.250494</td>\n",
       "      <td>338.121174</td>\n",
       "      <td>2126.960004</td>\n",
       "      <td>11306.662766</td>\n",
       "      <td>5773.890510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DATES    D Revenue         U CR         D OE       U NOI  \\\n",
       "0    2017-01-01  4479.720772  1283.851030  2201.862589  165.498382   \n",
       "1    2017-01-08  4451.483282  1294.720243  2188.701161  166.321882   \n",
       "2    2017-01-15  4423.245793  1305.589456  2175.539732  167.145382   \n",
       "3    2017-01-22  4395.008303  1316.458670  2162.378304  167.968883   \n",
       "4    2017-01-29  4366.770814  1327.327883  2149.216875  168.792383   \n",
       "..          ...          ...          ...          ...         ...   \n",
       "166  2020-03-08  5784.971103   882.718109  2632.808061  334.189988   \n",
       "167  2020-03-15  5813.800870   863.462381  2641.668669  335.172784   \n",
       "168  2020-03-22  5842.630638   844.206653  2650.529277  336.155581   \n",
       "169  2020-03-29  5871.460405   824.950925  2659.389885  337.138378   \n",
       "170  2020-04-05  5900.290173   805.695197  2668.250494  338.121174   \n",
       "\n",
       "         U CAPEX          U WK        D FCF  \n",
       "0    2075.336663  23013.204073  4489.072600  \n",
       "1    2083.350715  22872.363692  4514.461229  \n",
       "2    2091.364766  22731.523312  4539.849859  \n",
       "3    2099.378817  22590.682931  4565.238488  \n",
       "4    2107.392868  22449.842550  4590.627117  \n",
       "..           ...           ...          ...  \n",
       "166  2125.110319  12126.998352  5656.224349  \n",
       "167  2125.572740  11921.914455  5685.640889  \n",
       "168  2126.035162  11716.830559  5715.057429  \n",
       "169  2126.497583  11511.746663  5744.473970  \n",
       "170  2126.960004  11306.662766  5773.890510  \n",
       "\n",
       "[171 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4156.8376594786005"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"D FCF\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2017-01-01', 4479.7207719281, 1283.8510297798, ...,\n",
       "        2075.33666345166, 23013.204073189903, 4489.07260016184],\n",
       "       ['2017-01-08', 4451.483282441685, 1294.7202430567231, ...,\n",
       "        2083.3507145508997, 22872.363692428706, 4514.461229361381],\n",
       "       ['2017-01-15', 4423.24579295527, 1305.5894563336462, ...,\n",
       "        2091.3647656501403, 22731.5233116675, 4539.849858560922],\n",
       "       ...,\n",
       "       ['2020-03-22', 5842.630637818996, 844.2066529984876, ...,\n",
       "        2126.035161544405, 11716.830558986809, 5715.057429384644],\n",
       "       ['2020-03-29', 5871.460405384058, 824.9509248537581, ...,\n",
       "        2126.4975825990928, 11511.746662509153, 5744.473969587522],\n",
       "       ['2020-04-05', 5900.29017294912, 805.6951967090289, ...,\n",
       "        2126.9600036537804, 11306.662766031499, 5773.890509790401]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,1:7]\n",
    "Y = dataset[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20534555, 0.40299777, 0.30503239, 0.        , 0.        ,\n",
       "        0.48249751],\n",
       "       [0.18954974, 0.41215852, 0.29419379, 0.00477052, 0.00838259,\n",
       "        0.47669263],\n",
       "       [0.17375393, 0.42131928, 0.2833552 , 0.00954104, 0.01676519,\n",
       "        0.47088774],\n",
       "       ...,\n",
       "       [0.96774575, 0.0324581 , 0.67451487, 0.98861336, 0.05302997,\n",
       "        0.0169055 ],\n",
       "       [0.98387287, 0.01622905, 0.68181169, 0.99430668, 0.05351366,\n",
       "        0.00845275],\n",
       "       [1.        , 0.        , 0.68910851, 1.        , 0.05399735,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(136, 6) (17, 6) (18, 6) (136,) (17,) (18,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.2)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(6, activation='elu', input_shape=(6,)),\n",
    "    Dense(64, activation='elu'),\n",
    "    Dense(64, activation='elu'),\n",
    "    Dense(64, activation='elu'),\n",
    "    Dense(64, activation='elu'),\n",
    "    Dense(64, activation='elu'),\n",
    "    Dense(64, activation='elu'),\n",
    "    Dense(1, activation='elu'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 136 samples, validate on 17 samples\n",
      "Epoch 1/1500\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 3386.4113 - val_loss: 764.0494\n",
      "Epoch 2/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 940.1392 - val_loss: 721.5158\n",
      "Epoch 3/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 928.8570 - val_loss: 656.9634\n",
      "Epoch 4/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 860.4105 - val_loss: 648.3533\n",
      "Epoch 5/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 795.6092 - val_loss: 608.3031\n",
      "Epoch 6/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 744.7668 - val_loss: 491.6479\n",
      "Epoch 7/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 678.9880 - val_loss: 465.8151\n",
      "Epoch 8/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 607.1269 - val_loss: 417.4922\n",
      "Epoch 9/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 497.9994 - val_loss: 347.0086\n",
      "Epoch 10/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 418.0187 - val_loss: 292.1318\n",
      "Epoch 11/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 361.1412 - val_loss: 288.6280\n",
      "Epoch 12/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 339.3941 - val_loss: 271.5697\n",
      "Epoch 13/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 311.8319 - val_loss: 388.4617\n",
      "Epoch 14/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 303.1298 - val_loss: 327.6895\n",
      "Epoch 15/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 285.1221 - val_loss: 257.1720\n",
      "Epoch 16/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 281.5333 - val_loss: 296.7707\n",
      "Epoch 17/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 256.6498 - val_loss: 395.5312\n",
      "Epoch 18/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 240.3887 - val_loss: 372.1030\n",
      "Epoch 19/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 250.2833 - val_loss: 281.1549\n",
      "Epoch 20/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 224.0670 - val_loss: 266.3202\n",
      "Epoch 21/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 248.1876 - val_loss: 217.4892\n",
      "Epoch 22/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 235.0771 - val_loss: 251.1545\n",
      "Epoch 23/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 223.2288 - val_loss: 247.9535\n",
      "Epoch 24/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 233.5026 - val_loss: 240.3043\n",
      "Epoch 25/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 227.2518 - val_loss: 250.8701\n",
      "Epoch 26/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 225.4064 - val_loss: 217.9949\n",
      "Epoch 27/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 228.8904 - val_loss: 289.1869\n",
      "Epoch 28/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 224.2728 - val_loss: 415.1165\n",
      "Epoch 29/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 210.9327 - val_loss: 217.7009\n",
      "Epoch 30/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 218.8892 - val_loss: 231.3250\n",
      "Epoch 31/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 209.8083 - val_loss: 328.0184\n",
      "Epoch 32/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 221.3508 - val_loss: 231.3729\n",
      "Epoch 33/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 218.6986 - val_loss: 424.8678\n",
      "Epoch 34/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 208.3988 - val_loss: 372.0829\n",
      "Epoch 35/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 207.0972 - val_loss: 236.3136\n",
      "Epoch 36/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 200.4424 - val_loss: 165.5480\n",
      "Epoch 37/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 207.5304 - val_loss: 483.4715\n",
      "Epoch 38/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 218.6919 - val_loss: 213.0215\n",
      "Epoch 39/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 214.7902 - val_loss: 203.8227\n",
      "Epoch 40/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 210.8820 - val_loss: 368.6780\n",
      "Epoch 41/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 203.4639 - val_loss: 194.1125\n",
      "Epoch 42/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 197.8678 - val_loss: 190.2705\n",
      "Epoch 43/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 203.3861 - val_loss: 339.0299\n",
      "Epoch 44/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 200.7103 - val_loss: 158.0787\n",
      "Epoch 45/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 207.2251 - val_loss: 181.3640\n",
      "Epoch 46/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 198.3833 - val_loss: 168.4054\n",
      "Epoch 47/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 195.9365 - val_loss: 437.8753\n",
      "Epoch 48/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 187.4750 - val_loss: 194.2069\n",
      "Epoch 49/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 186.6187 - val_loss: 220.5063\n",
      "Epoch 50/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 203.2345 - val_loss: 232.1871\n",
      "Epoch 51/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 189.7718 - val_loss: 184.6328\n",
      "Epoch 52/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 195.6504 - val_loss: 281.2183\n",
      "Epoch 53/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 176.4065 - val_loss: 161.3673\n",
      "Epoch 54/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 183.7844 - val_loss: 164.3118\n",
      "Epoch 55/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 187.4101 - val_loss: 257.3122\n",
      "Epoch 56/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 181.2744 - val_loss: 139.7917\n",
      "Epoch 57/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 184.6166 - val_loss: 149.7849\n",
      "Epoch 58/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 170.7494 - val_loss: 198.9395\n",
      "Epoch 59/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 167.1514 - val_loss: 132.2573\n",
      "Epoch 60/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 170.2549 - val_loss: 238.3646\n",
      "Epoch 61/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 166.3256 - val_loss: 113.0477\n",
      "Epoch 62/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 169.4366 - val_loss: 150.9229\n",
      "Epoch 63/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 160.2757 - val_loss: 230.6071\n",
      "Epoch 64/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 165.7361 - val_loss: 139.5117\n",
      "Epoch 65/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 158.5441 - val_loss: 151.0547\n",
      "Epoch 66/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 162.5273 - val_loss: 187.3043\n",
      "Epoch 67/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 161.3722 - val_loss: 180.1951\n",
      "Epoch 68/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 167.4293 - val_loss: 215.5768\n",
      "Epoch 69/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 157.4684 - val_loss: 125.5104\n",
      "Epoch 70/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 163.0255 - val_loss: 213.1854\n",
      "Epoch 71/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 151.0940 - val_loss: 165.0585\n",
      "Epoch 72/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 158.8038 - val_loss: 217.8087\n",
      "Epoch 73/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 168.3126 - val_loss: 106.0212\n",
      "Epoch 74/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 158.7198 - val_loss: 154.3698\n",
      "Epoch 75/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 154.2886 - val_loss: 146.7866\n",
      "Epoch 76/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 159.2695 - val_loss: 143.6586\n",
      "Epoch 77/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 156.2510 - val_loss: 154.2024\n",
      "Epoch 78/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 158.1419 - val_loss: 179.4034\n",
      "Epoch 79/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 156.6314 - val_loss: 215.2939\n",
      "Epoch 80/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 149.9064 - val_loss: 105.0518\n",
      "Epoch 81/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 152.7459 - val_loss: 214.6659\n",
      "Epoch 82/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 152.0368 - val_loss: 188.6234\n",
      "Epoch 83/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 150.7512 - val_loss: 187.3685\n",
      "Epoch 84/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 156.8381 - val_loss: 118.3480\n",
      "Epoch 85/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 153.4830 - val_loss: 161.7960\n",
      "Epoch 86/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 138.2613 - val_loss: 209.4335\n",
      "Epoch 87/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 144.3509 - val_loss: 177.8671\n",
      "Epoch 88/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 150.1373 - val_loss: 122.3292\n",
      "Epoch 89/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 151.9339 - val_loss: 149.6530\n",
      "Epoch 90/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 142.7476 - val_loss: 150.8278\n",
      "Epoch 91/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 155.3657 - val_loss: 192.1309\n",
      "Epoch 92/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 155.7382 - val_loss: 108.9030\n",
      "Epoch 93/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 146.4665 - val_loss: 165.9110\n",
      "Epoch 94/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 143.3390 - val_loss: 114.4427\n",
      "Epoch 95/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 132.7351 - val_loss: 146.3334\n",
      "Epoch 96/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 138.8562 - val_loss: 119.4251\n",
      "Epoch 97/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 146.3678 - val_loss: 105.4907\n",
      "Epoch 98/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 140.3794 - val_loss: 166.8326\n",
      "Epoch 99/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 139.6061 - val_loss: 165.7168\n",
      "Epoch 100/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 141.8487 - val_loss: 116.3391\n",
      "Epoch 101/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 153.0591 - val_loss: 217.1373\n",
      "Epoch 102/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 140.0974 - val_loss: 142.5850\n",
      "Epoch 103/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 139.0028 - val_loss: 123.7262\n",
      "Epoch 104/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 142.7327 - val_loss: 156.3168\n",
      "Epoch 105/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 148.6490 - val_loss: 98.4179\n",
      "Epoch 106/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 138.2115 - val_loss: 273.5604\n",
      "Epoch 107/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 140.5710 - val_loss: 158.4945\n",
      "Epoch 108/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 138.9861 - val_loss: 197.1487\n",
      "Epoch 109/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 148.1328 - val_loss: 106.4623\n",
      "Epoch 110/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 136.6507 - val_loss: 132.1916\n",
      "Epoch 111/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 140.3522 - val_loss: 144.3778\n",
      "Epoch 112/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 143.8718 - val_loss: 146.0486\n",
      "Epoch 113/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 126.8233 - val_loss: 136.7939\n",
      "Epoch 114/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 139.6487 - val_loss: 172.2418\n",
      "Epoch 115/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 144.0352 - val_loss: 102.5789\n",
      "Epoch 116/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 134.0281 - val_loss: 192.7550\n",
      "Epoch 117/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 141.5856 - val_loss: 96.2980\n",
      "Epoch 118/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 136.7026 - val_loss: 146.0257\n",
      "Epoch 119/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 143.7304 - val_loss: 122.2375\n",
      "Epoch 120/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 134.5107 - val_loss: 192.7518\n",
      "Epoch 121/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 138.7084 - val_loss: 151.5407\n",
      "Epoch 122/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 137.9310 - val_loss: 150.2115\n",
      "Epoch 123/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 148.9761 - val_loss: 125.8639\n",
      "Epoch 124/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 131.3554 - val_loss: 214.4301\n",
      "Epoch 125/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 141.0694 - val_loss: 130.6753\n",
      "Epoch 126/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 136.0026 - val_loss: 129.7324\n",
      "Epoch 127/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 139.7524 - val_loss: 158.4497\n",
      "Epoch 128/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 139.9003 - val_loss: 91.2128\n",
      "Epoch 129/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 125.2841 - val_loss: 152.4704\n",
      "Epoch 130/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 135.2517 - val_loss: 97.3416\n",
      "Epoch 131/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 135.0037 - val_loss: 120.5288\n",
      "Epoch 132/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 127.1311 - val_loss: 164.0580\n",
      "Epoch 133/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 128.0683 - val_loss: 127.4480\n",
      "Epoch 134/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 130.3586 - val_loss: 184.3197\n",
      "Epoch 135/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 144.2377 - val_loss: 104.6286\n",
      "Epoch 136/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 133.5900 - val_loss: 119.8544\n",
      "Epoch 137/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 122.3892 - val_loss: 140.4316\n",
      "Epoch 138/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 136.9798 - val_loss: 175.7864\n",
      "Epoch 139/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 128.0423 - val_loss: 87.8119\n",
      "Epoch 140/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 129.5483 - val_loss: 94.5809\n",
      "Epoch 141/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 125.1347 - val_loss: 131.5435\n",
      "Epoch 142/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 137.4749 - val_loss: 88.8436\n",
      "Epoch 143/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 120.5956 - val_loss: 139.1322\n",
      "Epoch 144/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 134.1606 - val_loss: 115.5808\n",
      "Epoch 145/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 134.5779 - val_loss: 119.5127\n",
      "Epoch 146/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 125.2247 - val_loss: 214.4562\n",
      "Epoch 147/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 134.2447 - val_loss: 105.9931\n",
      "Epoch 148/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 129.2172 - val_loss: 138.2213\n",
      "Epoch 149/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 126.2116 - val_loss: 117.3350\n",
      "Epoch 150/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 131.5028 - val_loss: 151.4433\n",
      "Epoch 151/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 139.4981 - val_loss: 97.0594\n",
      "Epoch 152/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 130.9333 - val_loss: 108.2242\n",
      "Epoch 153/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 137.9371 - val_loss: 134.0349\n",
      "Epoch 154/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 140.6804 - val_loss: 159.4435\n",
      "Epoch 155/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 133.7002 - val_loss: 107.4483\n",
      "Epoch 156/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 129.4535 - val_loss: 117.7438\n",
      "Epoch 157/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 138.3418 - val_loss: 103.8435\n",
      "Epoch 158/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 135.3812 - val_loss: 97.6878\n",
      "Epoch 159/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 125.6421 - val_loss: 117.5111\n",
      "Epoch 160/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 126.2110 - val_loss: 104.5379\n",
      "Epoch 161/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 122.0784 - val_loss: 111.6727\n",
      "Epoch 162/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 124.0808 - val_loss: 100.4112\n",
      "Epoch 163/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 128.6007 - val_loss: 104.8435\n",
      "Epoch 164/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 138.8856 - val_loss: 161.2174\n",
      "Epoch 165/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 138.1157 - val_loss: 94.5110\n",
      "Epoch 166/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 138.9518 - val_loss: 127.8089\n",
      "Epoch 167/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 129.2664 - val_loss: 93.4673\n",
      "Epoch 168/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 130.8956 - val_loss: 119.5785\n",
      "Epoch 169/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 126.3618 - val_loss: 238.9783\n",
      "Epoch 170/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 125.1175 - val_loss: 96.7517\n",
      "Epoch 171/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 139.6370 - val_loss: 106.5161\n",
      "Epoch 172/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 127.9408 - val_loss: 278.3507\n",
      "Epoch 173/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 129.8359 - val_loss: 96.4911\n",
      "Epoch 174/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 131.7602 - val_loss: 92.3528\n",
      "Epoch 175/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 121.8112 - val_loss: 127.3616\n",
      "Epoch 176/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 132.7293 - val_loss: 110.7560\n",
      "Epoch 177/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 131.5177 - val_loss: 113.8647\n",
      "Epoch 178/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 113.5963 - val_loss: 104.5101\n",
      "Epoch 179/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 126.1341 - val_loss: 117.1283\n",
      "Epoch 180/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 131.3855 - val_loss: 157.4828\n",
      "Epoch 181/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 134.1602 - val_loss: 91.9624\n",
      "Epoch 182/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 136.2690 - val_loss: 104.7379\n",
      "Epoch 183/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 124.7900 - val_loss: 93.0802\n",
      "Epoch 184/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 129.1955 - val_loss: 222.8637\n",
      "Epoch 185/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 120.8320 - val_loss: 194.3804\n",
      "Epoch 186/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 124.7858 - val_loss: 109.6151\n",
      "Epoch 187/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 122.9447 - val_loss: 102.1879\n",
      "Epoch 188/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 130.7684 - val_loss: 90.9584\n",
      "Epoch 189/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 135.1002 - val_loss: 112.2904\n",
      "Epoch 190/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 125.4579 - val_loss: 107.5627\n",
      "Epoch 191/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 127.0508 - val_loss: 226.4493\n",
      "Epoch 192/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 126.1565 - val_loss: 118.4529\n",
      "Epoch 193/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 127.2829 - val_loss: 204.8222\n",
      "Epoch 194/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 135.7486 - val_loss: 126.5684\n",
      "Epoch 195/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 128.3993 - val_loss: 86.2525\n",
      "Epoch 196/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 124.3165 - val_loss: 145.9689\n",
      "Epoch 197/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 125.8433 - val_loss: 91.6513\n",
      "Epoch 198/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 126.7507 - val_loss: 151.7932\n",
      "Epoch 199/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 119.4780 - val_loss: 109.5459\n",
      "Epoch 200/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 127.5822 - val_loss: 127.8287\n",
      "Epoch 201/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 125.2740 - val_loss: 262.7239\n",
      "Epoch 202/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 129.8424 - val_loss: 115.3044\n",
      "Epoch 203/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 121.4898 - val_loss: 145.4561\n",
      "Epoch 204/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 134.8027 - val_loss: 104.2666\n",
      "Epoch 205/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 126.9428 - val_loss: 228.3149\n",
      "Epoch 206/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 125.6397 - val_loss: 103.7596\n",
      "Epoch 207/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 123.7387 - val_loss: 129.8126\n",
      "Epoch 208/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 124.9528 - val_loss: 167.0244\n",
      "Epoch 209/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 118.2471 - val_loss: 110.5543\n",
      "Epoch 210/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 122.6069 - val_loss: 162.6214\n",
      "Epoch 211/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 124.4174 - val_loss: 80.3965\n",
      "Epoch 212/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 116.1449 - val_loss: 147.3931\n",
      "Epoch 213/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 132.1268 - val_loss: 82.9831\n",
      "Epoch 214/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 127.3335 - val_loss: 101.0481\n",
      "Epoch 215/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 119.3742 - val_loss: 91.7455\n",
      "Epoch 216/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 126.3403 - val_loss: 87.6756\n",
      "Epoch 217/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 121.4130 - val_loss: 115.1964\n",
      "Epoch 218/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 123.2932 - val_loss: 132.3327\n",
      "Epoch 219/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 116.0662 - val_loss: 138.2016\n",
      "Epoch 220/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 127.0018 - val_loss: 79.9142\n",
      "Epoch 221/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 119.4771 - val_loss: 90.5444\n",
      "Epoch 222/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 127.4896 - val_loss: 83.3383\n",
      "Epoch 223/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 115.4222 - val_loss: 79.2798\n",
      "Epoch 224/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 125.2382 - val_loss: 119.8605\n",
      "Epoch 225/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 122.3547 - val_loss: 156.5226\n",
      "Epoch 226/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 121.7830 - val_loss: 140.7927\n",
      "Epoch 227/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 123.5935 - val_loss: 109.8506\n",
      "Epoch 228/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 126.5320 - val_loss: 154.9642\n",
      "Epoch 229/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 112.9030 - val_loss: 91.0866\n",
      "Epoch 230/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 118.8922 - val_loss: 120.7652\n",
      "Epoch 231/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 117.5456 - val_loss: 80.4148\n",
      "Epoch 232/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 124.4895 - val_loss: 83.9125\n",
      "Epoch 233/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 116.0577 - val_loss: 82.0573\n",
      "Epoch 234/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 122.5613 - val_loss: 84.3806\n",
      "Epoch 235/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 116.8927 - val_loss: 164.8539\n",
      "Epoch 236/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 120.8811 - val_loss: 81.9320\n",
      "Epoch 237/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 112.4634 - val_loss: 170.7609\n",
      "Epoch 238/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 118.4518 - val_loss: 93.2276\n",
      "Epoch 239/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 119.6079 - val_loss: 117.4265\n",
      "Epoch 240/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 109.5658 - val_loss: 73.7294\n",
      "Epoch 241/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 118.5214 - val_loss: 125.1077\n",
      "Epoch 242/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 113.2084 - val_loss: 89.3523\n",
      "Epoch 243/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 112.2969 - val_loss: 80.3766\n",
      "Epoch 244/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 116.2717 - val_loss: 86.3588\n",
      "Epoch 245/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 119.0406 - val_loss: 130.7940\n",
      "Epoch 246/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 115.3166 - val_loss: 110.2268\n",
      "Epoch 247/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 113.3806 - val_loss: 185.8320\n",
      "Epoch 248/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 115.4936 - val_loss: 81.6021\n",
      "Epoch 249/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 115.9915 - val_loss: 160.7154\n",
      "Epoch 250/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 121.7621 - val_loss: 66.8807\n",
      "Epoch 251/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 110.1202 - val_loss: 74.4697\n",
      "Epoch 252/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 105.7836 - val_loss: 75.0233\n",
      "Epoch 253/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 117.0127 - val_loss: 107.9647\n",
      "Epoch 254/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 117.0540 - val_loss: 134.4412\n",
      "Epoch 255/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 119.9575 - val_loss: 165.9339\n",
      "Epoch 256/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 113.5369 - val_loss: 91.5966\n",
      "Epoch 257/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 109.8418 - val_loss: 112.9881\n",
      "Epoch 258/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 112.9443 - val_loss: 96.3355\n",
      "Epoch 259/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 113.4236 - val_loss: 87.9686\n",
      "Epoch 260/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 110.6370 - val_loss: 189.4439\n",
      "Epoch 261/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 111.1498 - val_loss: 187.7924\n",
      "Epoch 262/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 115.3846 - val_loss: 74.7909\n",
      "Epoch 263/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 108.0275 - val_loss: 121.7460\n",
      "Epoch 264/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 111.7038 - val_loss: 86.9064\n",
      "Epoch 265/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 111.2163 - val_loss: 155.6284\n",
      "Epoch 266/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 106.9168 - val_loss: 127.0119\n",
      "Epoch 267/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 108.2692 - val_loss: 140.6874\n",
      "Epoch 268/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 102.8953 - val_loss: 78.0839\n",
      "Epoch 269/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 108.4317 - val_loss: 97.2543\n",
      "Epoch 270/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 119.5486 - val_loss: 77.8612\n",
      "Epoch 271/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 108.5200 - val_loss: 79.1669\n",
      "Epoch 272/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 105.6803 - val_loss: 102.2297\n",
      "Epoch 273/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 109.3028 - val_loss: 99.4326\n",
      "Epoch 274/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 109.6191 - val_loss: 96.1065\n",
      "Epoch 275/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 104.4357 - val_loss: 149.7426\n",
      "Epoch 276/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 107.2526 - val_loss: 102.0379\n",
      "Epoch 277/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 97.8365 - val_loss: 80.2290\n",
      "Epoch 278/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 103.7435 - val_loss: 78.2406\n",
      "Epoch 279/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 96.2086 - val_loss: 72.2492\n",
      "Epoch 280/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 99.7630 - val_loss: 167.8662\n",
      "Epoch 281/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 96.8617 - val_loss: 182.3735\n",
      "Epoch 282/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 97.4432 - val_loss: 140.1849\n",
      "Epoch 283/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 99.4598 - val_loss: 91.1252\n",
      "Epoch 284/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 100.2820 - val_loss: 76.8565\n",
      "Epoch 285/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 100.6745 - val_loss: 99.1884\n",
      "Epoch 286/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 104.7484 - val_loss: 76.9526\n",
      "Epoch 287/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 98.0592 - val_loss: 72.7451\n",
      "Epoch 288/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 95.9980 - val_loss: 71.6895\n",
      "Epoch 289/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 96.6409 - val_loss: 90.4777\n",
      "Epoch 290/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 97.3412 - val_loss: 76.6263\n",
      "Epoch 291/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 97.9732 - val_loss: 109.1641\n",
      "Epoch 292/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 96.0401 - val_loss: 102.8383\n",
      "Epoch 293/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 93.8348 - val_loss: 144.7287\n",
      "Epoch 294/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 91.1693 - val_loss: 72.7118\n",
      "Epoch 295/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 97.2362 - val_loss: 91.5847\n",
      "Epoch 296/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 87.3010 - val_loss: 74.0944\n",
      "Epoch 297/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 93.7139 - val_loss: 114.0560\n",
      "Epoch 298/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 91.8748 - val_loss: 77.2414\n",
      "Epoch 299/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 95.4875 - val_loss: 89.9946\n",
      "Epoch 300/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 85.0607 - val_loss: 152.7112\n",
      "Epoch 301/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 99.6216 - val_loss: 61.6426\n",
      "Epoch 302/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 90.8321 - val_loss: 85.2351\n",
      "Epoch 303/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 86.0101 - val_loss: 59.4636\n",
      "Epoch 304/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 85.6142 - val_loss: 70.7789\n",
      "Epoch 305/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 90.5872 - val_loss: 81.7064\n",
      "Epoch 306/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 96.3852 - val_loss: 62.7052\n",
      "Epoch 307/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 92.0377 - val_loss: 168.5525\n",
      "Epoch 308/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 92.3076 - val_loss: 77.0933\n",
      "Epoch 309/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 95.5036 - val_loss: 70.1423\n",
      "Epoch 310/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 84.3448 - val_loss: 92.4430\n",
      "Epoch 311/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 92.4304 - val_loss: 74.1511\n",
      "Epoch 312/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 83.7674 - val_loss: 105.7257\n",
      "Epoch 313/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 90.8483 - val_loss: 105.4266\n",
      "Epoch 314/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 93.3352 - val_loss: 88.4185\n",
      "Epoch 315/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 86.0110 - val_loss: 157.5161\n",
      "Epoch 316/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 87.4191 - val_loss: 97.6519\n",
      "Epoch 317/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 87.2388 - val_loss: 69.7394\n",
      "Epoch 318/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 83.3970 - val_loss: 46.5051\n",
      "Epoch 319/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 90.7335 - val_loss: 84.1810\n",
      "Epoch 320/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 90.9044 - val_loss: 57.3701\n",
      "Epoch 321/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 82.5511 - val_loss: 56.5090\n",
      "Epoch 322/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 93.2316 - val_loss: 78.1915\n",
      "Epoch 323/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 88.9060 - val_loss: 77.7941\n",
      "Epoch 324/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 83.6852 - val_loss: 68.1785\n",
      "Epoch 325/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 85.3217 - val_loss: 70.8648\n",
      "Epoch 326/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 88.3186 - val_loss: 68.5086\n",
      "Epoch 327/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 81.6981 - val_loss: 58.5656\n",
      "Epoch 328/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 90.2943 - val_loss: 60.3157\n",
      "Epoch 329/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 83.7585 - val_loss: 85.0721\n",
      "Epoch 330/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 82.4272 - val_loss: 126.4262\n",
      "Epoch 331/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 89.9912 - val_loss: 60.0229\n",
      "Epoch 332/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 84.8890 - val_loss: 76.6136\n",
      "Epoch 333/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 84.3925 - val_loss: 70.4164\n",
      "Epoch 334/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 80.3345 - val_loss: 199.5573\n",
      "Epoch 335/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 87.4884 - val_loss: 75.0839\n",
      "Epoch 336/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 85.3713 - val_loss: 66.2657\n",
      "Epoch 337/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 80.4709 - val_loss: 70.6564\n",
      "Epoch 338/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 85.5666 - val_loss: 71.1305\n",
      "Epoch 339/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 82.3636 - val_loss: 61.8360\n",
      "Epoch 340/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 71.8140 - val_loss: 46.5765\n",
      "Epoch 341/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 89.4181 - val_loss: 91.3701\n",
      "Epoch 342/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 88.0322 - val_loss: 108.0562\n",
      "Epoch 343/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 81.3205 - val_loss: 96.5884\n",
      "Epoch 344/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 79.8615 - val_loss: 77.1854\n",
      "Epoch 345/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 83.8458 - val_loss: 65.8995\n",
      "Epoch 346/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 85.1604 - val_loss: 84.5997\n",
      "Epoch 347/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 79.1824 - val_loss: 60.1595\n",
      "Epoch 348/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 83.2016 - val_loss: 114.8118\n",
      "Epoch 349/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 79.4659 - val_loss: 65.6605\n",
      "Epoch 350/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 83.1872 - val_loss: 59.6167\n",
      "Epoch 351/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 80.5064 - val_loss: 118.2870\n",
      "Epoch 352/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.9304 - val_loss: 62.3428\n",
      "Epoch 353/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 85.6355 - val_loss: 67.7893\n",
      "Epoch 354/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.1475 - val_loss: 97.4533\n",
      "Epoch 355/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 81.4401 - val_loss: 96.8859\n",
      "Epoch 356/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 85.1869 - val_loss: 116.7220\n",
      "Epoch 357/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 83.7411 - val_loss: 73.0768\n",
      "Epoch 358/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 85.9643 - val_loss: 50.2536\n",
      "Epoch 359/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.7533 - val_loss: 113.0779\n",
      "Epoch 360/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 82.9643 - val_loss: 63.0515\n",
      "Epoch 361/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 79.9930 - val_loss: 99.8266\n",
      "Epoch 362/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 82.1285 - val_loss: 139.1481\n",
      "Epoch 363/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 80.7885 - val_loss: 76.5382\n",
      "Epoch 364/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 81.2617 - val_loss: 57.1361\n",
      "Epoch 365/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 82.8450 - val_loss: 62.9536\n",
      "Epoch 366/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 76.8884 - val_loss: 93.5525\n",
      "Epoch 367/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 74.2725 - val_loss: 59.7990\n",
      "Epoch 368/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 81.5325 - val_loss: 94.9212\n",
      "Epoch 369/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.7971 - val_loss: 68.0019\n",
      "Epoch 370/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 78.3864 - val_loss: 135.3041\n",
      "Epoch 371/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 82.5508 - val_loss: 76.9179\n",
      "Epoch 372/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 80.5236 - val_loss: 84.1308\n",
      "Epoch 373/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 81.2464 - val_loss: 103.9135\n",
      "Epoch 374/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 79.9212 - val_loss: 65.8191\n",
      "Epoch 375/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 84.5830 - val_loss: 55.0994\n",
      "Epoch 376/1500\n",
      "136/136 [==============================] - ETA: 0s - loss: 77.43 - 0s 1ms/step - loss: 74.7663 - val_loss: 47.6726\n",
      "Epoch 377/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 76.8626 - val_loss: 74.7956\n",
      "Epoch 378/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 76.9915 - val_loss: 66.7689\n",
      "Epoch 379/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 76.9319 - val_loss: 119.1678\n",
      "Epoch 380/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.6329 - val_loss: 74.2701\n",
      "Epoch 381/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.7031 - val_loss: 146.3550\n",
      "Epoch 382/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 82.6842 - val_loss: 56.7295\n",
      "Epoch 383/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.3498 - val_loss: 59.6877\n",
      "Epoch 384/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 76.7936 - val_loss: 51.3470\n",
      "Epoch 385/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 82.3172 - val_loss: 70.0844\n",
      "Epoch 386/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 76.0588 - val_loss: 82.2408\n",
      "Epoch 387/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 68.0281 - val_loss: 76.5269\n",
      "Epoch 388/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.7721 - val_loss: 141.3074\n",
      "Epoch 389/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.3709 - val_loss: 44.7135\n",
      "Epoch 390/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 74.9842 - val_loss: 81.1396\n",
      "Epoch 391/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 78.7909 - val_loss: 78.4267\n",
      "Epoch 392/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 74.9575 - val_loss: 82.9181\n",
      "Epoch 393/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 76.7535 - val_loss: 63.1466\n",
      "Epoch 394/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 72.5833 - val_loss: 53.2898\n",
      "Epoch 395/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 74.4306 - val_loss: 104.2278\n",
      "Epoch 396/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 80.2311 - val_loss: 102.0845\n",
      "Epoch 397/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 77.3353 - val_loss: 49.9016\n",
      "Epoch 398/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 78.7169 - val_loss: 96.4433\n",
      "Epoch 399/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.8998 - val_loss: 49.5740\n",
      "Epoch 400/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 81.0286 - val_loss: 123.3745\n",
      "Epoch 401/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.3365 - val_loss: 68.7469\n",
      "Epoch 402/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 74.9570 - val_loss: 66.0127\n",
      "Epoch 403/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 79.7491 - val_loss: 72.4692\n",
      "Epoch 404/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 71.9063 - val_loss: 100.0302\n",
      "Epoch 405/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 78.4032 - val_loss: 65.2254\n",
      "Epoch 406/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 73.7277 - val_loss: 183.1637\n",
      "Epoch 407/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 80.6374 - val_loss: 44.1433\n",
      "Epoch 408/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 73.9164 - val_loss: 62.5271\n",
      "Epoch 409/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 69.8771 - val_loss: 72.2920\n",
      "Epoch 410/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.9640 - val_loss: 44.6808\n",
      "Epoch 411/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 73.5261 - val_loss: 78.8277\n",
      "Epoch 412/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 74.4800 - val_loss: 123.6983\n",
      "Epoch 413/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 71.9628 - val_loss: 58.0008\n",
      "Epoch 414/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 78.3103 - val_loss: 71.6073\n",
      "Epoch 415/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 72.5240 - val_loss: 48.5453\n",
      "Epoch 416/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 69.4005 - val_loss: 58.1607\n",
      "Epoch 417/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 74.5072 - val_loss: 72.4657\n",
      "Epoch 418/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.1166 - val_loss: 142.3497\n",
      "Epoch 419/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 78.3906 - val_loss: 53.8958\n",
      "Epoch 420/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 79.3315 - val_loss: 65.2424\n",
      "Epoch 421/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 73.9864 - val_loss: 49.5679\n",
      "Epoch 422/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 77.3541 - val_loss: 63.5873\n",
      "Epoch 423/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 76.1495 - val_loss: 47.1262\n",
      "Epoch 424/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 76.0838 - val_loss: 67.1400\n",
      "Epoch 425/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 69.7711 - val_loss: 40.5673\n",
      "Epoch 426/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 81.1328 - val_loss: 57.0003\n",
      "Epoch 427/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 70.7201 - val_loss: 111.3463\n",
      "Epoch 428/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 73.7145 - val_loss: 56.6882\n",
      "Epoch 429/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 78.1636 - val_loss: 100.4265\n",
      "Epoch 430/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 71.0507 - val_loss: 78.5782\n",
      "Epoch 431/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.2070 - val_loss: 65.2475\n",
      "Epoch 432/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 71.5641 - val_loss: 79.9012\n",
      "Epoch 433/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 71.1512 - val_loss: 108.4684\n",
      "Epoch 434/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 79.8713 - val_loss: 76.4326\n",
      "Epoch 435/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.0096 - val_loss: 43.7452\n",
      "Epoch 436/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 73.3534 - val_loss: 31.3775\n",
      "Epoch 437/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 72.0154 - val_loss: 76.4539\n",
      "Epoch 438/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 67.5071 - val_loss: 91.7975\n",
      "Epoch 439/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 69.9157 - val_loss: 46.6006\n",
      "Epoch 440/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 67.4202 - val_loss: 71.2019\n",
      "Epoch 441/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.9800 - val_loss: 91.8036\n",
      "Epoch 442/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 73.8572 - val_loss: 87.9632\n",
      "Epoch 443/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.9005 - val_loss: 34.3830\n",
      "Epoch 444/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 69.1628 - val_loss: 56.2366\n",
      "Epoch 445/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 76.3813 - val_loss: 41.8996\n",
      "Epoch 446/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 71.0033 - val_loss: 95.5658\n",
      "Epoch 447/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 73.0901 - val_loss: 78.6140\n",
      "Epoch 448/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 69.7239 - val_loss: 131.4557\n",
      "Epoch 449/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 73.0770 - val_loss: 53.6382\n",
      "Epoch 450/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 69.7282 - val_loss: 109.6345\n",
      "Epoch 451/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 71.1771 - val_loss: 38.4375\n",
      "Epoch 452/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 68.3084 - val_loss: 110.0375\n",
      "Epoch 453/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 69.8536 - val_loss: 51.8876\n",
      "Epoch 454/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 74.0335 - val_loss: 48.1613\n",
      "Epoch 455/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 73.3434 - val_loss: 136.4301\n",
      "Epoch 456/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.1578 - val_loss: 72.9795\n",
      "Epoch 457/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 73.1800 - val_loss: 62.7424\n",
      "Epoch 458/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 66.8813 - val_loss: 53.3849\n",
      "Epoch 459/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 64.8122 - val_loss: 43.4415\n",
      "Epoch 460/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 70.0758 - val_loss: 54.4004\n",
      "Epoch 461/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 73.1870 - val_loss: 94.0656\n",
      "Epoch 462/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 67.9549 - val_loss: 54.4977\n",
      "Epoch 463/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 74.6528 - val_loss: 109.5698\n",
      "Epoch 464/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 74.3377 - val_loss: 70.5032\n",
      "Epoch 465/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 68.4663 - val_loss: 82.9112\n",
      "Epoch 466/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 71.4250 - val_loss: 53.2159\n",
      "Epoch 467/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 74.0261 - val_loss: 65.3885\n",
      "Epoch 468/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 65.1095 - val_loss: 48.0325\n",
      "Epoch 469/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 72.0079 - val_loss: 95.7945\n",
      "Epoch 470/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 67.9193 - val_loss: 164.5393\n",
      "Epoch 471/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 72.7615 - val_loss: 61.6639\n",
      "Epoch 472/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 71.8600 - val_loss: 37.8347\n",
      "Epoch 473/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 66.7180 - val_loss: 86.4269\n",
      "Epoch 474/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 69.9026 - val_loss: 102.0149\n",
      "Epoch 475/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 71.6925 - val_loss: 87.5947\n",
      "Epoch 476/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 64.6624 - val_loss: 64.6974\n",
      "Epoch 477/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 64.1015 - val_loss: 59.3302\n",
      "Epoch 478/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 68.8872 - val_loss: 30.4455\n",
      "Epoch 479/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 63.8905 - val_loss: 84.2415\n",
      "Epoch 480/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 72.3640 - val_loss: 74.7227\n",
      "Epoch 481/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 73.9678 - val_loss: 104.9248\n",
      "Epoch 482/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 75.2231 - val_loss: 32.4545\n",
      "Epoch 483/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 70.2006 - val_loss: 43.8525\n",
      "Epoch 484/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 68.2382 - val_loss: 91.2283\n",
      "Epoch 485/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 69.3928 - val_loss: 64.7917\n",
      "Epoch 486/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 69.1148 - val_loss: 66.0179\n",
      "Epoch 487/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 66.9464 - val_loss: 132.1490\n",
      "Epoch 488/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 72.3243 - val_loss: 72.0841\n",
      "Epoch 489/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 71.2103 - val_loss: 44.3698\n",
      "Epoch 490/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 68.4267 - val_loss: 59.9834\n",
      "Epoch 491/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 64.4934 - val_loss: 92.2852\n",
      "Epoch 492/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 66.9843 - val_loss: 40.9040\n",
      "Epoch 493/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 68.3458 - val_loss: 66.9232\n",
      "Epoch 494/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 66.6815 - val_loss: 68.4970\n",
      "Epoch 495/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 68.6458 - val_loss: 31.4059\n",
      "Epoch 496/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 70.9384 - val_loss: 71.7817\n",
      "Epoch 497/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 65.2133 - val_loss: 71.7168\n",
      "Epoch 498/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 64.7332 - val_loss: 121.7969\n",
      "Epoch 499/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 66.1981 - val_loss: 54.7014\n",
      "Epoch 500/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 68.3677 - val_loss: 111.7297\n",
      "Epoch 501/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 70.5980 - val_loss: 57.3882\n",
      "Epoch 502/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 70.2582 - val_loss: 75.8294\n",
      "Epoch 503/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 64.3097 - val_loss: 45.0383\n",
      "Epoch 504/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 71.6147 - val_loss: 49.7650\n",
      "Epoch 505/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 64.8745 - val_loss: 49.9107\n",
      "Epoch 506/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 69.8708 - val_loss: 97.8496\n",
      "Epoch 507/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 67.7847 - val_loss: 45.0354\n",
      "Epoch 508/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 65.4248 - val_loss: 35.1851\n",
      "Epoch 509/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 64.2342 - val_loss: 82.3079\n",
      "Epoch 510/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 70.1449 - val_loss: 53.6772\n",
      "Epoch 511/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 68.4055 - val_loss: 51.0287\n",
      "Epoch 512/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 65.7445 - val_loss: 95.8310\n",
      "Epoch 513/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 70.6915 - val_loss: 36.8412\n",
      "Epoch 514/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 62.2389 - val_loss: 26.9248\n",
      "Epoch 515/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 69.3120 - val_loss: 43.5885\n",
      "Epoch 516/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 64.6573 - val_loss: 35.5213\n",
      "Epoch 517/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 66.7923 - val_loss: 61.2142\n",
      "Epoch 518/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 67.9430 - val_loss: 46.2513\n",
      "Epoch 519/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 63.5796 - val_loss: 47.8854\n",
      "Epoch 520/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 62.9892 - val_loss: 43.4642\n",
      "Epoch 521/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 66.2088 - val_loss: 103.3327\n",
      "Epoch 522/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 69.4069 - val_loss: 64.9392\n",
      "Epoch 523/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 62.0556 - val_loss: 52.3003\n",
      "Epoch 524/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 63.1187 - val_loss: 60.8928\n",
      "Epoch 525/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 66.8552 - val_loss: 29.2951\n",
      "Epoch 526/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 63.6764 - val_loss: 46.7216\n",
      "Epoch 527/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 59.8976 - val_loss: 122.6018\n",
      "Epoch 528/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 68.7385 - val_loss: 26.0128\n",
      "Epoch 529/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 63.8209 - val_loss: 55.5568\n",
      "Epoch 530/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 65.1138 - val_loss: 31.9287\n",
      "Epoch 531/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 64.7148 - val_loss: 43.3928\n",
      "Epoch 532/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 65.8758 - val_loss: 74.0321\n",
      "Epoch 533/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 64.1773 - val_loss: 46.2359\n",
      "Epoch 534/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 66.9715 - val_loss: 56.4986\n",
      "Epoch 535/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 63.9939 - val_loss: 38.7163\n",
      "Epoch 536/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 61.6313 - val_loss: 56.6766\n",
      "Epoch 537/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 66.4180 - val_loss: 42.6872\n",
      "Epoch 538/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 68.9023 - val_loss: 40.3700\n",
      "Epoch 539/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 68.0971 - val_loss: 36.8892\n",
      "Epoch 540/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 62.6456 - val_loss: 41.1950\n",
      "Epoch 541/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 63.4961 - val_loss: 40.9407\n",
      "Epoch 542/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 63.0047 - val_loss: 30.4203\n",
      "Epoch 543/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 62.2594 - val_loss: 41.3428\n",
      "Epoch 544/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 68.4434 - val_loss: 44.8682\n",
      "Epoch 545/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 64.5273 - val_loss: 49.4593\n",
      "Epoch 546/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 65.3092 - val_loss: 65.8467\n",
      "Epoch 547/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 65.2266 - val_loss: 58.8407\n",
      "Epoch 548/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.5040 - val_loss: 122.3067\n",
      "Epoch 549/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 61.1112 - val_loss: 50.5598\n",
      "Epoch 550/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 63.8002 - val_loss: 43.5904\n",
      "Epoch 551/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 64.6786 - val_loss: 60.2787\n",
      "Epoch 552/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 61.5715 - val_loss: 81.4462\n",
      "Epoch 553/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 63.3557 - val_loss: 32.5609\n",
      "Epoch 554/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 62.2299 - val_loss: 79.4970\n",
      "Epoch 555/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 66.8904 - val_loss: 108.4256\n",
      "Epoch 556/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 64.9614 - val_loss: 61.2212\n",
      "Epoch 557/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.1294 - val_loss: 56.8828\n",
      "Epoch 558/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 62.6536 - val_loss: 34.8569\n",
      "Epoch 559/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 62.9781 - val_loss: 82.9643\n",
      "Epoch 560/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 62.8241 - val_loss: 89.7631\n",
      "Epoch 561/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 65.5059 - val_loss: 98.2499\n",
      "Epoch 562/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 64.0363 - val_loss: 35.2831\n",
      "Epoch 563/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.9458 - val_loss: 47.5827\n",
      "Epoch 564/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 64.3869 - val_loss: 30.2721\n",
      "Epoch 565/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 66.2481 - val_loss: 42.8515\n",
      "Epoch 566/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 62.8560 - val_loss: 74.4959\n",
      "Epoch 567/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 61.0831 - val_loss: 35.7369\n",
      "Epoch 568/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.4232 - val_loss: 35.0725\n",
      "Epoch 569/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 62.2173 - val_loss: 120.2349\n",
      "Epoch 570/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 64.1548 - val_loss: 66.2396\n",
      "Epoch 571/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.1840 - val_loss: 42.5187\n",
      "Epoch 572/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 62.9940 - val_loss: 31.3427\n",
      "Epoch 573/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 65.1186 - val_loss: 38.6821\n",
      "Epoch 574/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 66.5276 - val_loss: 55.0279\n",
      "Epoch 575/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 62.7963 - val_loss: 25.7482\n",
      "Epoch 576/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.0854 - val_loss: 79.2237\n",
      "Epoch 577/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 65.8181 - val_loss: 63.1224\n",
      "Epoch 578/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 61.2967 - val_loss: 56.5147\n",
      "Epoch 579/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 61.8622 - val_loss: 31.6292\n",
      "Epoch 580/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 64.0265 - val_loss: 66.6578\n",
      "Epoch 581/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.9349 - val_loss: 123.9578\n",
      "Epoch 582/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.3852 - val_loss: 81.6193\n",
      "Epoch 583/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 62.0518 - val_loss: 41.2024\n",
      "Epoch 584/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.9237 - val_loss: 50.0406\n",
      "Epoch 585/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 61.3122 - val_loss: 33.5573\n",
      "Epoch 586/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.3099 - val_loss: 45.8114\n",
      "Epoch 587/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 62.8350 - val_loss: 28.0515\n",
      "Epoch 588/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.2829 - val_loss: 58.7255\n",
      "Epoch 589/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 63.9536 - val_loss: 30.1105\n",
      "Epoch 590/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.8570 - val_loss: 44.5131\n",
      "Epoch 591/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 61.7191 - val_loss: 56.6692\n",
      "Epoch 592/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 62.1981 - val_loss: 71.3613\n",
      "Epoch 593/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 62.6511 - val_loss: 45.5519\n",
      "Epoch 594/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 62.1047 - val_loss: 24.6034\n",
      "Epoch 595/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.9329 - val_loss: 54.4669\n",
      "Epoch 596/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 59.5946 - val_loss: 86.0330\n",
      "Epoch 597/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.9676 - val_loss: 83.4871\n",
      "Epoch 598/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 62.9866 - val_loss: 50.1730\n",
      "Epoch 599/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 62.4721 - val_loss: 33.3124\n",
      "Epoch 600/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 62.4844 - val_loss: 48.0506\n",
      "Epoch 601/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 62.2816 - val_loss: 101.3020\n",
      "Epoch 602/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 57.2755 - val_loss: 30.3838\n",
      "Epoch 603/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.8132 - val_loss: 64.4608\n",
      "Epoch 604/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.8852 - val_loss: 99.2171\n",
      "Epoch 605/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.6330 - val_loss: 31.2023\n",
      "Epoch 606/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.2578 - val_loss: 55.2044\n",
      "Epoch 607/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 58.6925 - val_loss: 20.0920\n",
      "Epoch 608/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 61.6626 - val_loss: 45.5718\n",
      "Epoch 609/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 61.7941 - val_loss: 81.6479\n",
      "Epoch 610/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.8236 - val_loss: 113.2487\n",
      "Epoch 611/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.5267 - val_loss: 31.2577\n",
      "Epoch 612/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 61.1623 - val_loss: 37.1093\n",
      "Epoch 613/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 60.9654 - val_loss: 40.2292\n",
      "Epoch 614/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 61.6487 - val_loss: 113.7877\n",
      "Epoch 615/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.0630 - val_loss: 118.3544\n",
      "Epoch 616/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 61.9157 - val_loss: 48.2589\n",
      "Epoch 617/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.7114 - val_loss: 36.7844\n",
      "Epoch 618/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.5762 - val_loss: 26.5314\n",
      "Epoch 619/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.4975 - val_loss: 29.6684\n",
      "Epoch 620/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 61.3100 - val_loss: 68.0305\n",
      "Epoch 621/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.0402 - val_loss: 86.1104\n",
      "Epoch 622/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.8044 - val_loss: 93.2965\n",
      "Epoch 623/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.7918 - val_loss: 60.4646\n",
      "Epoch 624/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.6869 - val_loss: 37.2468\n",
      "Epoch 625/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 59.9088 - val_loss: 46.0206\n",
      "Epoch 626/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.3059 - val_loss: 105.6839\n",
      "Epoch 627/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 60.8551 - val_loss: 36.0462\n",
      "Epoch 628/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 58.3205 - val_loss: 102.4848\n",
      "Epoch 629/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 56.1856 - val_loss: 46.9631\n",
      "Epoch 630/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 61.0139 - val_loss: 74.1640\n",
      "Epoch 631/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 56.7351 - val_loss: 32.8354\n",
      "Epoch 632/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 58.6409 - val_loss: 36.7923\n",
      "Epoch 633/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 58.0238 - val_loss: 43.9329\n",
      "Epoch 634/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 61.1822 - val_loss: 39.9698\n",
      "Epoch 635/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.4239 - val_loss: 34.4044\n",
      "Epoch 636/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.2540 - val_loss: 29.3003\n",
      "Epoch 637/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 56.0941 - val_loss: 50.2280\n",
      "Epoch 638/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.8900 - val_loss: 70.5904\n",
      "Epoch 639/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.1870 - val_loss: 33.1998\n",
      "Epoch 640/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.8567 - val_loss: 40.0154\n",
      "Epoch 641/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.9214 - val_loss: 19.8288\n",
      "Epoch 642/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.7673 - val_loss: 45.7479\n",
      "Epoch 643/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.4085 - val_loss: 90.0094\n",
      "Epoch 644/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.1728 - val_loss: 32.4902\n",
      "Epoch 645/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.4700 - val_loss: 35.7374\n",
      "Epoch 646/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.2889 - val_loss: 28.1127\n",
      "Epoch 647/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.0195 - val_loss: 68.9868\n",
      "Epoch 648/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 61.2231 - val_loss: 74.0363\n",
      "Epoch 649/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 57.7914 - val_loss: 81.7016\n",
      "Epoch 650/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.0694 - val_loss: 38.7754\n",
      "Epoch 651/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.9191 - val_loss: 56.4931\n",
      "Epoch 652/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.7965 - val_loss: 86.7711\n",
      "Epoch 653/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.2987 - val_loss: 45.1609\n",
      "Epoch 654/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.9545 - val_loss: 80.1568\n",
      "Epoch 655/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 62.5230 - val_loss: 23.8342\n",
      "Epoch 656/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 61.4563 - val_loss: 40.3743\n",
      "Epoch 657/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.4681 - val_loss: 45.9596\n",
      "Epoch 658/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.8550 - val_loss: 37.9907\n",
      "Epoch 659/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.5302 - val_loss: 57.5870\n",
      "Epoch 660/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.8976 - val_loss: 87.8075\n",
      "Epoch 661/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.5960 - val_loss: 43.4833\n",
      "Epoch 662/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.8540 - val_loss: 30.5585\n",
      "Epoch 663/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.0826 - val_loss: 51.0404\n",
      "Epoch 664/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.2028 - val_loss: 35.9871\n",
      "Epoch 665/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 61.4021 - val_loss: 22.9016\n",
      "Epoch 666/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.1483 - val_loss: 43.5035\n",
      "Epoch 667/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.7492 - val_loss: 63.1934\n",
      "Epoch 668/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.0002 - val_loss: 116.6848\n",
      "Epoch 669/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 61.0195 - val_loss: 41.4515\n",
      "Epoch 670/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.3501 - val_loss: 69.3679\n",
      "Epoch 671/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 56.5653 - val_loss: 76.8453\n",
      "Epoch 672/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 62.1402 - val_loss: 24.0174\n",
      "Epoch 673/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.5007 - val_loss: 105.5134\n",
      "Epoch 674/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.9557 - val_loss: 104.6010\n",
      "Epoch 675/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 64.2409 - val_loss: 41.4143\n",
      "Epoch 676/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.4533 - val_loss: 43.0682\n",
      "Epoch 677/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.3416 - val_loss: 80.0437\n",
      "Epoch 678/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.1277 - val_loss: 78.1522\n",
      "Epoch 679/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.2241 - val_loss: 70.5166\n",
      "Epoch 680/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.3775 - val_loss: 74.4540\n",
      "Epoch 681/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 61.8487 - val_loss: 43.7655\n",
      "Epoch 682/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.5464 - val_loss: 34.8015\n",
      "Epoch 683/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 56.2801 - val_loss: 26.6750\n",
      "Epoch 684/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.0165 - val_loss: 72.9812\n",
      "Epoch 685/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.3947 - val_loss: 34.4950\n",
      "Epoch 686/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.6071 - val_loss: 67.2628\n",
      "Epoch 687/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.9506 - val_loss: 53.6775\n",
      "Epoch 688/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.0108 - val_loss: 57.2406\n",
      "Epoch 689/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.3563 - val_loss: 54.2251\n",
      "Epoch 690/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 57.1148 - val_loss: 56.2410\n",
      "Epoch 691/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.2936 - val_loss: 45.2428\n",
      "Epoch 692/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.6200 - val_loss: 38.9676\n",
      "Epoch 693/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 60.5657 - val_loss: 49.0525\n",
      "Epoch 694/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 56.7300 - val_loss: 79.1083\n",
      "Epoch 695/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.4212 - val_loss: 32.5869\n",
      "Epoch 696/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.5572 - val_loss: 55.8216\n",
      "Epoch 697/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.5371 - val_loss: 57.8054\n",
      "Epoch 698/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.7501 - val_loss: 29.9817\n",
      "Epoch 699/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.0066 - val_loss: 54.4237\n",
      "Epoch 700/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.5366 - val_loss: 48.8324\n",
      "Epoch 701/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.4891 - val_loss: 38.2767\n",
      "Epoch 702/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.9052 - val_loss: 36.3905\n",
      "Epoch 703/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.3053 - val_loss: 46.3944\n",
      "Epoch 704/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.6364 - val_loss: 53.9265\n",
      "Epoch 705/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 59.5610 - val_loss: 29.2974\n",
      "Epoch 706/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.7561 - val_loss: 40.5764\n",
      "Epoch 707/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.4021 - val_loss: 55.0886\n",
      "Epoch 708/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 56.5857 - val_loss: 43.6303\n",
      "Epoch 709/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.4230 - val_loss: 60.5268\n",
      "Epoch 710/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.4954 - val_loss: 73.1973\n",
      "Epoch 711/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.8543 - val_loss: 76.0806\n",
      "Epoch 712/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.1347 - val_loss: 48.5944\n",
      "Epoch 713/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.9282 - val_loss: 38.5879\n",
      "Epoch 714/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 55.9648 - val_loss: 72.6559\n",
      "Epoch 715/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 57.6545 - val_loss: 86.0041\n",
      "Epoch 716/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.9333 - val_loss: 75.8111\n",
      "Epoch 717/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 59.8334 - val_loss: 60.7246\n",
      "Epoch 718/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 58.3461 - val_loss: 39.3629\n",
      "Epoch 719/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 58.1711 - val_loss: 52.5209\n",
      "Epoch 720/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 58.4842 - val_loss: 64.3672\n",
      "Epoch 721/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 56.6400 - val_loss: 60.2865\n",
      "Epoch 722/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 61.2338 - val_loss: 20.3960\n",
      "Epoch 723/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.2092 - val_loss: 94.4330\n",
      "Epoch 724/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 53.5596 - val_loss: 37.2079\n",
      "Epoch 725/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.1123 - val_loss: 121.3339\n",
      "Epoch 726/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 58.5670 - val_loss: 39.2350\n",
      "Epoch 727/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 55.0998 - val_loss: 43.2741\n",
      "Epoch 728/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 54.0170 - val_loss: 23.4520\n",
      "Epoch 729/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.1485 - val_loss: 75.7380\n",
      "Epoch 730/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.4122 - val_loss: 51.0954\n",
      "Epoch 731/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 56.1824 - val_loss: 95.6003\n",
      "Epoch 732/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.8270 - val_loss: 34.0521\n",
      "Epoch 733/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.0866 - val_loss: 67.8724\n",
      "Epoch 734/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.5852 - val_loss: 26.6398\n",
      "Epoch 735/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.3798 - val_loss: 54.3019\n",
      "Epoch 736/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 57.8965 - val_loss: 36.2219\n",
      "Epoch 737/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.6975 - val_loss: 80.4320\n",
      "Epoch 738/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 57.3679 - val_loss: 78.4553\n",
      "Epoch 739/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 54.8676 - val_loss: 25.0184\n",
      "Epoch 740/1500\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 55.8759 - val_loss: 55.6439\n",
      "Epoch 741/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 57.6012 - val_loss: 84.3333\n",
      "Epoch 742/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 54.5444 - val_loss: 48.5642\n",
      "Epoch 743/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 52.7696 - val_loss: 105.9137\n",
      "Epoch 744/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 60.3382 - val_loss: 34.3904\n",
      "Epoch 745/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 57.7527 - val_loss: 28.6098\n",
      "Epoch 746/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 57.7578 - val_loss: 55.3133\n",
      "Epoch 747/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 56.1282 - val_loss: 24.1319\n",
      "Epoch 748/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 56.3966 - val_loss: 29.2153\n",
      "Epoch 749/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 54.1557 - val_loss: 50.0671\n",
      "Epoch 750/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 58.3891 - val_loss: 29.6483\n",
      "Epoch 751/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 57.3170 - val_loss: 30.8014\n",
      "Epoch 752/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 54.0930 - val_loss: 22.0426\n",
      "Epoch 753/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 56.0603 - val_loss: 39.5678\n",
      "Epoch 754/1500\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 54.0730 - val_loss: 77.0695\n",
      "Epoch 755/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 58.4877 - val_loss: 44.8446\n",
      "Epoch 756/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 52.3697 - val_loss: 27.4643\n",
      "Epoch 757/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 58.6639 - val_loss: 31.5220\n",
      "Epoch 758/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 54.0677 - val_loss: 21.8856\n",
      "Epoch 759/1500\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 54.7664 - val_loss: 49.8182\n",
      "Epoch 760/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 57.2194 - val_loss: 43.4189\n",
      "Epoch 761/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 54.3258 - val_loss: 30.7655\n",
      "Epoch 762/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 53.5216 - val_loss: 82.9637\n",
      "Epoch 763/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 59.2199 - val_loss: 33.8984\n",
      "Epoch 764/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 54.1077 - val_loss: 32.7927\n",
      "Epoch 765/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 56.5226 - val_loss: 74.2820\n",
      "Epoch 766/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 54.9130 - val_loss: 106.9614\n",
      "Epoch 767/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 55.7214 - val_loss: 31.6531\n",
      "Epoch 768/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 53.8218 - val_loss: 88.2181\n",
      "Epoch 769/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 52.4449 - val_loss: 102.8953\n",
      "Epoch 770/1500\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 56.8622 - val_loss: 64.7197\n",
      "Epoch 771/1500\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 52.2171 - val_loss: 103.3072\n",
      "Epoch 772/1500\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 58.0441 - val_loss: 29.0463\n",
      "Epoch 773/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 55.9412 - val_loss: 39.4173\n",
      "Epoch 774/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 56.8840 - val_loss: 72.0896\n",
      "Epoch 775/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 53.9286 - val_loss: 29.2870\n",
      "Epoch 776/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 61.5476 - val_loss: 27.3438\n",
      "Epoch 777/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 52.7135 - val_loss: 115.5555\n",
      "Epoch 778/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 55.9127 - val_loss: 89.9269\n",
      "Epoch 779/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 56.3681 - val_loss: 38.0701\n",
      "Epoch 780/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.3313 - val_loss: 26.6282\n",
      "Epoch 781/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 59.1683 - val_loss: 55.3732\n",
      "Epoch 782/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 55.7630 - val_loss: 25.8850\n",
      "Epoch 783/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 56.1220 - val_loss: 54.9570\n",
      "Epoch 784/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.5986 - val_loss: 93.3351\n",
      "Epoch 785/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 55.0844 - val_loss: 103.8317\n",
      "Epoch 786/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.5311 - val_loss: 62.4519\n",
      "Epoch 787/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.0408 - val_loss: 29.3278\n",
      "Epoch 788/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.5006 - val_loss: 51.1843\n",
      "Epoch 789/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.7850 - val_loss: 86.5653\n",
      "Epoch 790/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.2648 - val_loss: 36.0896\n",
      "Epoch 791/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.7679 - val_loss: 79.5590\n",
      "Epoch 792/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.7988 - val_loss: 106.9947\n",
      "Epoch 793/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.8891 - val_loss: 33.8806\n",
      "Epoch 794/1500\n",
      "136/136 [==============================] - 0s 948us/step - loss: 52.4684 - val_loss: 71.7607\n",
      "Epoch 795/1500\n",
      "136/136 [==============================] - 0s 919us/step - loss: 55.7210 - val_loss: 36.9470\n",
      "Epoch 796/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.8657 - val_loss: 37.5867\n",
      "Epoch 797/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.0444 - val_loss: 34.7765\n",
      "Epoch 798/1500\n",
      "136/136 [==============================] - 0s 956us/step - loss: 57.0554 - val_loss: 43.7701\n",
      "Epoch 799/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.6083 - val_loss: 108.8864\n",
      "Epoch 800/1500\n",
      "136/136 [==============================] - 0s 912us/step - loss: 54.6439 - val_loss: 21.5832\n",
      "Epoch 801/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.8692 - val_loss: 46.3345\n",
      "Epoch 802/1500\n",
      "136/136 [==============================] - 0s 942us/step - loss: 55.3390 - val_loss: 20.3877\n",
      "Epoch 803/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 56.0341 - val_loss: 44.3259\n",
      "Epoch 804/1500\n",
      "136/136 [==============================] - 0s 993us/step - loss: 54.4589 - val_loss: 62.8368\n",
      "Epoch 805/1500\n",
      "136/136 [==============================] - 0s 912us/step - loss: 54.8135 - val_loss: 55.3261\n",
      "Epoch 806/1500\n",
      "136/136 [==============================] - 0s 912us/step - loss: 53.1683 - val_loss: 38.3229\n",
      "Epoch 807/1500\n",
      "136/136 [==============================] - 0s 904us/step - loss: 53.8127 - val_loss: 23.5229\n",
      "Epoch 808/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 57.8028 - val_loss: 60.9277\n",
      "Epoch 809/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.4359 - val_loss: 36.4033\n",
      "Epoch 810/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.7900 - val_loss: 48.2834\n",
      "Epoch 811/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.3870 - val_loss: 101.3142\n",
      "Epoch 812/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.6642 - val_loss: 46.9836\n",
      "Epoch 813/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 53.6681 - val_loss: 148.5330\n",
      "Epoch 814/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 52.3702 - val_loss: 25.9015\n",
      "Epoch 815/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 52.3171 - val_loss: 67.7121\n",
      "Epoch 816/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 56.4104 - val_loss: 23.8526\n",
      "Epoch 817/1500\n",
      "136/136 [==============================] - 0s 3ms/step - loss: 54.9634 - val_loss: 38.3463\n",
      "Epoch 818/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 55.2937 - val_loss: 89.9405\n",
      "Epoch 819/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 50.8247 - val_loss: 52.8086\n",
      "Epoch 820/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 54.4896 - val_loss: 30.9020\n",
      "Epoch 821/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.8755 - val_loss: 56.7578\n",
      "Epoch 822/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.2331 - val_loss: 63.5265\n",
      "Epoch 823/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.0595 - val_loss: 41.1993\n",
      "Epoch 824/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.6916 - val_loss: 84.3975\n",
      "Epoch 825/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.8019 - val_loss: 24.2284\n",
      "Epoch 826/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.7341 - val_loss: 56.9661\n",
      "Epoch 827/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.5902 - val_loss: 41.3133\n",
      "Epoch 828/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.7368 - val_loss: 30.7935\n",
      "Epoch 829/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.7716 - val_loss: 33.6645\n",
      "Epoch 830/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.9669 - val_loss: 118.8200\n",
      "Epoch 831/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 52.9234 - val_loss: 68.7671\n",
      "Epoch 832/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 55.2821 - val_loss: 34.1872\n",
      "Epoch 833/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.9148 - val_loss: 45.8645\n",
      "Epoch 834/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.8459 - val_loss: 41.4212\n",
      "Epoch 835/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 51.6222 - val_loss: 138.3971\n",
      "Epoch 836/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 55.1337 - val_loss: 35.4760\n",
      "Epoch 837/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 50.4509 - val_loss: 136.9922\n",
      "Epoch 838/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 55.6872 - val_loss: 86.2603\n",
      "Epoch 839/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 54.4449 - val_loss: 33.6388\n",
      "Epoch 840/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.4181 - val_loss: 118.4913\n",
      "Epoch 841/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.5993 - val_loss: 61.7333\n",
      "Epoch 842/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.4908 - val_loss: 18.7298\n",
      "Epoch 843/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.0308 - val_loss: 39.2604\n",
      "Epoch 844/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 2ms/step - loss: 52.6309 - val_loss: 28.0725\n",
      "Epoch 845/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.9656 - val_loss: 25.2031\n",
      "Epoch 846/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 49.6512 - val_loss: 62.2133\n",
      "Epoch 847/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 53.4607 - val_loss: 23.4821\n",
      "Epoch 848/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 54.1816 - val_loss: 32.2569\n",
      "Epoch 849/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 53.2200 - val_loss: 83.0550\n",
      "Epoch 850/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 56.5864 - val_loss: 37.7910\n",
      "Epoch 851/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.7616 - val_loss: 103.8288\n",
      "Epoch 852/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 54.6238 - val_loss: 45.6588\n",
      "Epoch 853/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.3015 - val_loss: 27.7557\n",
      "Epoch 854/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 51.3072 - val_loss: 25.5059\n",
      "Epoch 855/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 55.0720 - val_loss: 37.8657\n",
      "Epoch 856/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.5462 - val_loss: 34.8633\n",
      "Epoch 857/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.9169 - val_loss: 46.5859\n",
      "Epoch 858/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 58.6440 - val_loss: 21.6662\n",
      "Epoch 859/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 48.0922 - val_loss: 39.3773\n",
      "Epoch 860/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 53.2376 - val_loss: 31.7510\n",
      "Epoch 861/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 54.7210 - val_loss: 67.3915\n",
      "Epoch 862/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 53.7024 - val_loss: 65.2308\n",
      "Epoch 863/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 53.5741 - val_loss: 27.6238\n",
      "Epoch 864/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 57.1051 - val_loss: 46.8867\n",
      "Epoch 865/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 53.4914 - val_loss: 29.9320\n",
      "Epoch 866/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 52.9533 - val_loss: 24.3116\n",
      "Epoch 867/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 53.1838 - val_loss: 39.3001\n",
      "Epoch 868/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 53.6615 - val_loss: 69.4228\n",
      "Epoch 869/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 51.8498 - val_loss: 27.1755\n",
      "Epoch 870/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 48.8873 - val_loss: 113.7075\n",
      "Epoch 871/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 54.4464 - val_loss: 74.4513\n",
      "Epoch 872/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 55.0463 - val_loss: 21.8717\n",
      "Epoch 873/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 54.4432 - val_loss: 54.6052\n",
      "Epoch 874/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.3661 - val_loss: 49.7624\n",
      "Epoch 875/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.2558 - val_loss: 17.0184\n",
      "Epoch 876/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.1183 - val_loss: 43.2089\n",
      "Epoch 877/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.1391 - val_loss: 22.4576\n",
      "Epoch 878/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.4198 - val_loss: 26.0712\n",
      "Epoch 879/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.4908 - val_loss: 42.1656\n",
      "Epoch 880/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.4592 - val_loss: 62.0805\n",
      "Epoch 881/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.5593 - val_loss: 55.7744\n",
      "Epoch 882/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.9071 - val_loss: 58.6745\n",
      "Epoch 883/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.0152 - val_loss: 32.0151\n",
      "Epoch 884/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.1618 - val_loss: 69.5259\n",
      "Epoch 885/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.8599 - val_loss: 25.5292\n",
      "Epoch 886/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.3021 - val_loss: 33.1728\n",
      "Epoch 887/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.0237 - val_loss: 38.9272\n",
      "Epoch 888/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.5988 - val_loss: 55.6011\n",
      "Epoch 889/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.8487 - val_loss: 35.8238\n",
      "Epoch 890/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.0629 - val_loss: 45.5561\n",
      "Epoch 891/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.5661 - val_loss: 29.0688\n",
      "Epoch 892/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.5875 - val_loss: 28.2403\n",
      "Epoch 893/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 56.2228 - val_loss: 47.0094\n",
      "Epoch 894/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.4241 - val_loss: 62.2668\n",
      "Epoch 895/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.6167 - val_loss: 53.4316\n",
      "Epoch 896/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.8443 - val_loss: 44.8060\n",
      "Epoch 897/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.7167 - val_loss: 50.3091\n",
      "Epoch 898/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.2836 - val_loss: 40.6652\n",
      "Epoch 899/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.7431 - val_loss: 20.1148\n",
      "Epoch 900/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.8783 - val_loss: 44.8935\n",
      "Epoch 901/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.2297 - val_loss: 48.1889\n",
      "Epoch 902/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.0042 - val_loss: 50.9586\n",
      "Epoch 903/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.3257 - val_loss: 35.4823\n",
      "Epoch 904/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.7195 - val_loss: 28.6138\n",
      "Epoch 905/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.3116 - val_loss: 117.6001\n",
      "Epoch 906/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.0433 - val_loss: 45.4655\n",
      "Epoch 907/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.4104 - val_loss: 116.4192\n",
      "Epoch 908/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.1036 - val_loss: 29.5127\n",
      "Epoch 909/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.5761 - val_loss: 91.8801\n",
      "Epoch 910/1500\n",
      "136/136 [==============================] - 0s 985us/step - loss: 53.5051 - val_loss: 26.3954\n",
      "Epoch 911/1500\n",
      "136/136 [==============================] - 0s 978us/step - loss: 51.3756 - val_loss: 104.8178\n",
      "Epoch 912/1500\n",
      "136/136 [==============================] - 0s 934us/step - loss: 51.8371 - val_loss: 58.1846\n",
      "Epoch 913/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.8146 - val_loss: 44.8936\n",
      "Epoch 914/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.6471 - val_loss: 50.0023\n",
      "Epoch 915/1500\n",
      "136/136 [==============================] - 0s 993us/step - loss: 53.6237 - val_loss: 22.8935\n",
      "Epoch 916/1500\n",
      "136/136 [==============================] - 0s 978us/step - loss: 50.9460 - val_loss: 42.5605\n",
      "Epoch 917/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.4724 - val_loss: 37.6794\n",
      "Epoch 918/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.1999 - val_loss: 28.0624\n",
      "Epoch 919/1500\n",
      "136/136 [==============================] - 0s 985us/step - loss: 48.6322 - val_loss: 84.0349\n",
      "Epoch 920/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.9052 - val_loss: 56.4836\n",
      "Epoch 921/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 54.8661 - val_loss: 54.7471\n",
      "Epoch 922/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.7907 - val_loss: 22.5217\n",
      "Epoch 923/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.9488 - val_loss: 42.8874\n",
      "Epoch 924/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.3888 - val_loss: 39.0495\n",
      "Epoch 925/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.8034 - val_loss: 59.9031\n",
      "Epoch 926/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.8900 - val_loss: 84.4615\n",
      "Epoch 927/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.4164 - val_loss: 60.9788\n",
      "Epoch 928/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.5054 - val_loss: 27.3419\n",
      "Epoch 929/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.6766 - val_loss: 58.9619\n",
      "Epoch 930/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.5095 - val_loss: 81.1103\n",
      "Epoch 931/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.3575 - val_loss: 79.6739\n",
      "Epoch 932/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.6185 - val_loss: 45.5548\n",
      "Epoch 933/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.9498 - val_loss: 21.7484\n",
      "Epoch 934/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.4992 - val_loss: 33.5293\n",
      "Epoch 935/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.1877 - val_loss: 25.5791\n",
      "Epoch 936/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.8723 - val_loss: 52.9759\n",
      "Epoch 937/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.7302 - val_loss: 115.6117\n",
      "Epoch 938/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.5639 - val_loss: 80.9785\n",
      "Epoch 939/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.5182 - val_loss: 73.9327\n",
      "Epoch 940/1500\n",
      "136/136 [==============================] - 0s 1000us/step - loss: 51.2884 - val_loss: 75.1341\n",
      "Epoch 941/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.1162 - val_loss: 46.8005\n",
      "Epoch 942/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.3574 - val_loss: 33.4498\n",
      "Epoch 943/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.3949 - val_loss: 48.5478\n",
      "Epoch 944/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.6068 - val_loss: 24.9144\n",
      "Epoch 945/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.0692 - val_loss: 28.0460\n",
      "Epoch 946/1500\n",
      "136/136 [==============================] - 0s 978us/step - loss: 50.6717 - val_loss: 127.4920\n",
      "Epoch 947/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.0519 - val_loss: 48.3232\n",
      "Epoch 948/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.3098 - val_loss: 62.5561\n",
      "Epoch 949/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.3655 - val_loss: 49.6309\n",
      "Epoch 950/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.3100 - val_loss: 36.4349\n",
      "Epoch 951/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.7754 - val_loss: 86.5594\n",
      "Epoch 952/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.5353 - val_loss: 33.7603\n",
      "Epoch 953/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.6764 - val_loss: 43.2482\n",
      "Epoch 954/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 55.9956 - val_loss: 26.6871\n",
      "Epoch 955/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.0628 - val_loss: 114.9459\n",
      "Epoch 956/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.5232 - val_loss: 23.8237\n",
      "Epoch 957/1500\n",
      "136/136 [==============================] - 0s 1000us/step - loss: 53.1907 - val_loss: 136.6663\n",
      "Epoch 958/1500\n",
      "136/136 [==============================] - 0s 1000us/step - loss: 51.2961 - val_loss: 37.5237\n",
      "Epoch 959/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.1492 - val_loss: 27.0854\n",
      "Epoch 960/1500\n",
      "136/136 [==============================] - 0s 985us/step - loss: 49.9075 - val_loss: 35.9159\n",
      "Epoch 961/1500\n",
      "136/136 [==============================] - 0s 978us/step - loss: 51.3760 - val_loss: 37.6374\n",
      "Epoch 962/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.2140 - val_loss: 36.2792\n",
      "Epoch 963/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.5263 - val_loss: 94.9529\n",
      "Epoch 964/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.2034 - val_loss: 97.9227\n",
      "Epoch 965/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.3993 - val_loss: 52.7198\n",
      "Epoch 966/1500\n",
      "136/136 [==============================] - 0s 971us/step - loss: 52.9135 - val_loss: 18.7751\n",
      "Epoch 967/1500\n",
      "136/136 [==============================] - 0s 978us/step - loss: 51.3121 - val_loss: 35.5082\n",
      "Epoch 968/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.6728 - val_loss: 22.3527\n",
      "Epoch 969/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.8049 - val_loss: 60.7115\n",
      "Epoch 970/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.4376 - val_loss: 47.7845\n",
      "Epoch 971/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.2583 - val_loss: 38.4445\n",
      "Epoch 972/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.6967 - val_loss: 30.9517\n",
      "Epoch 973/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.5626 - val_loss: 62.4482\n",
      "Epoch 974/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.3403 - val_loss: 55.1552\n",
      "Epoch 975/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.0428 - val_loss: 104.5926\n",
      "Epoch 976/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.5075 - val_loss: 62.8098\n",
      "Epoch 977/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.2020 - val_loss: 35.0009\n",
      "Epoch 978/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.5594 - val_loss: 18.1643\n",
      "Epoch 979/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.9946 - val_loss: 118.9077\n",
      "Epoch 980/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.5332 - val_loss: 48.5674\n",
      "Epoch 981/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.9303 - val_loss: 34.2618\n",
      "Epoch 982/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.3893 - val_loss: 59.8602\n",
      "Epoch 983/1500\n",
      "136/136 [==============================] - 0s 1000us/step - loss: 52.9447 - val_loss: 18.9992\n",
      "Epoch 984/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.1595 - val_loss: 68.6830\n",
      "Epoch 985/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.1902 - val_loss: 36.6757\n",
      "Epoch 986/1500\n",
      "136/136 [==============================] - 0s 993us/step - loss: 47.6192 - val_loss: 92.9201\n",
      "Epoch 987/1500\n",
      "136/136 [==============================] - 0s 956us/step - loss: 50.3311 - val_loss: 23.7588\n",
      "Epoch 988/1500\n",
      "136/136 [==============================] - 0s 985us/step - loss: 52.6399 - val_loss: 48.4339\n",
      "Epoch 989/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.2662 - val_loss: 69.8394\n",
      "Epoch 990/1500\n",
      "136/136 [==============================] - 0s 987us/step - loss: 51.4557 - val_loss: 21.1063\n",
      "Epoch 991/1500\n",
      "136/136 [==============================] - 0s 998us/step - loss: 54.0912 - val_loss: 42.0428\n",
      "Epoch 992/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.9147 - val_loss: 31.1192\n",
      "Epoch 993/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.2932 - val_loss: 49.2887\n",
      "Epoch 994/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.0308 - val_loss: 84.9797\n",
      "Epoch 995/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.7554 - val_loss: 56.6094\n",
      "Epoch 996/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 54.4424 - val_loss: 19.4500\n",
      "Epoch 997/1500\n",
      "136/136 [==============================] - 0s 1000us/step - loss: 46.0955 - val_loss: 56.2226\n",
      "Epoch 998/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 50.7617 - val_loss: 38.2654\n",
      "Epoch 999/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.8452 - val_loss: 57.9247\n",
      "Epoch 1000/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.0715 - val_loss: 45.0377\n",
      "Epoch 1001/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.4247 - val_loss: 42.8360\n",
      "Epoch 1002/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.4071 - val_loss: 88.8692\n",
      "Epoch 1003/1500\n",
      "136/136 [==============================] - 0s 963us/step - loss: 53.9514 - val_loss: 23.4071\n",
      "Epoch 1004/1500\n",
      "136/136 [==============================] - 0s 993us/step - loss: 48.5988 - val_loss: 25.7480\n",
      "Epoch 1005/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.6573 - val_loss: 39.5681\n",
      "Epoch 1006/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.0742 - val_loss: 58.8413\n",
      "Epoch 1007/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.3935 - val_loss: 20.2540\n",
      "Epoch 1008/1500\n",
      "136/136 [==============================] - 0s 993us/step - loss: 47.9298 - val_loss: 45.7486\n",
      "Epoch 1009/1500\n",
      "136/136 [==============================] - 0s 963us/step - loss: 48.8112 - val_loss: 60.7883\n",
      "Epoch 1010/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.5357 - val_loss: 49.7142\n",
      "Epoch 1011/1500\n",
      "136/136 [==============================] - 0s 992us/step - loss: 49.9794 - val_loss: 88.6692\n",
      "Epoch 1012/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.1738 - val_loss: 43.2209\n",
      "Epoch 1013/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.2143 - val_loss: 104.4525\n",
      "Epoch 1014/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.0617 - val_loss: 76.2090\n",
      "Epoch 1015/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.3757 - val_loss: 30.6784\n",
      "Epoch 1016/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.0507 - val_loss: 65.1882\n",
      "Epoch 1017/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.9265 - val_loss: 133.4565\n",
      "Epoch 1018/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.6027 - val_loss: 70.9127\n",
      "Epoch 1019/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.4289 - val_loss: 39.2789\n",
      "Epoch 1020/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.4319 - val_loss: 39.9494\n",
      "Epoch 1021/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.1447 - val_loss: 37.7287\n",
      "Epoch 1022/1500\n",
      "136/136 [==============================] - 0s 926us/step - loss: 47.5836 - val_loss: 112.9505\n",
      "Epoch 1023/1500\n",
      "136/136 [==============================] - 0s 926us/step - loss: 51.8686 - val_loss: 29.6707\n",
      "Epoch 1024/1500\n",
      "136/136 [==============================] - 0s 934us/step - loss: 52.3637 - val_loss: 103.8126\n",
      "Epoch 1025/1500\n",
      "136/136 [==============================] - 0s 963us/step - loss: 51.2579 - val_loss: 92.6266\n",
      "Epoch 1026/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.1587 - val_loss: 52.6462\n",
      "Epoch 1027/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.8859 - val_loss: 28.9812\n",
      "Epoch 1028/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.5120 - val_loss: 43.5189\n",
      "Epoch 1029/1500\n",
      "136/136 [==============================] - 0s 978us/step - loss: 50.0809 - val_loss: 93.8393\n",
      "Epoch 1030/1500\n",
      "136/136 [==============================] - 0s 927us/step - loss: 51.4409 - val_loss: 27.2190\n",
      "Epoch 1031/1500\n",
      "136/136 [==============================] - 0s 956us/step - loss: 49.7006 - val_loss: 22.2906\n",
      "Epoch 1032/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 52.4171 - val_loss: 20.4208\n",
      "Epoch 1033/1500\n",
      "136/136 [==============================] - 0s 978us/step - loss: 52.1413 - val_loss: 46.7441\n",
      "Epoch 1034/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.4833 - val_loss: 30.9526\n",
      "Epoch 1035/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.2384 - val_loss: 38.6168\n",
      "Epoch 1036/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.8025 - val_loss: 25.2554\n",
      "Epoch 1037/1500\n",
      "136/136 [==============================] - 0s 978us/step - loss: 49.9963 - val_loss: 66.4344\n",
      "Epoch 1038/1500\n",
      "136/136 [==============================] - 0s 971us/step - loss: 49.9681 - val_loss: 20.9768\n",
      "Epoch 1039/1500\n",
      "136/136 [==============================] - 0s 941us/step - loss: 51.2582 - val_loss: 35.0497\n",
      "Epoch 1040/1500\n",
      "136/136 [==============================] - 0s 926us/step - loss: 47.4279 - val_loss: 97.4977\n",
      "Epoch 1041/1500\n",
      "136/136 [==============================] - 0s 949us/step - loss: 51.2566 - val_loss: 65.6325\n",
      "Epoch 1042/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.9738 - val_loss: 54.6221\n",
      "Epoch 1043/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.3934 - val_loss: 25.5851\n",
      "Epoch 1044/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.3633 - val_loss: 37.1354\n",
      "Epoch 1045/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.9016 - val_loss: 53.7105\n",
      "Epoch 1046/1500\n",
      "136/136 [==============================] - 0s 963us/step - loss: 46.5556 - val_loss: 43.6669\n",
      "Epoch 1047/1500\n",
      "136/136 [==============================] - 0s 956us/step - loss: 50.3186 - val_loss: 50.0232\n",
      "Epoch 1048/1500\n",
      "136/136 [==============================] - 0s 956us/step - loss: 47.6412 - val_loss: 96.2455\n",
      "Epoch 1049/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.4195 - val_loss: 55.6615\n",
      "Epoch 1050/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.5218 - val_loss: 62.3848\n",
      "Epoch 1051/1500\n",
      "136/136 [==============================] - 0s 978us/step - loss: 48.6873 - val_loss: 49.0220\n",
      "Epoch 1052/1500\n",
      "136/136 [==============================] - 0s 941us/step - loss: 48.1168 - val_loss: 39.0455\n",
      "Epoch 1053/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.8036 - val_loss: 48.3346\n",
      "Epoch 1054/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.9444 - val_loss: 28.4425\n",
      "Epoch 1055/1500\n",
      "136/136 [==============================] - 0s 978us/step - loss: 48.6749 - val_loss: 60.7836\n",
      "Epoch 1056/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.8834 - val_loss: 103.1686\n",
      "Epoch 1057/1500\n",
      "136/136 [==============================] - 0s 993us/step - loss: 47.0854 - val_loss: 78.2694\n",
      "Epoch 1058/1500\n",
      "136/136 [==============================] - 0s 985us/step - loss: 49.1098 - val_loss: 44.1762\n",
      "Epoch 1059/1500\n",
      "136/136 [==============================] - 0s 941us/step - loss: 50.5796 - val_loss: 75.8061\n",
      "Epoch 1060/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.1123 - val_loss: 92.7886\n",
      "Epoch 1061/1500\n",
      "136/136 [==============================] - 0s 978us/step - loss: 49.5350 - val_loss: 29.0035\n",
      "Epoch 1062/1500\n",
      "136/136 [==============================] - 0s 956us/step - loss: 51.9394 - val_loss: 34.8075\n",
      "Epoch 1063/1500\n",
      "136/136 [==============================] - 0s 978us/step - loss: 45.7866 - val_loss: 72.0391\n",
      "Epoch 1064/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.3698 - val_loss: 31.3020\n",
      "Epoch 1065/1500\n",
      "136/136 [==============================] - 0s 985us/step - loss: 50.6267 - val_loss: 49.6712\n",
      "Epoch 1066/1500\n",
      "136/136 [==============================] - 0s 912us/step - loss: 50.8527 - val_loss: 52.4827\n",
      "Epoch 1067/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.2733 - val_loss: 23.2080\n",
      "Epoch 1068/1500\n",
      "136/136 [==============================] - 0s 966us/step - loss: 49.8988 - val_loss: 34.1440\n",
      "Epoch 1069/1500\n",
      "136/136 [==============================] - 0s 963us/step - loss: 49.5666 - val_loss: 89.6957\n",
      "Epoch 1070/1500\n",
      "136/136 [==============================] - 0s 997us/step - loss: 49.6322 - val_loss: 59.3253\n",
      "Epoch 1071/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.8693 - val_loss: 53.2254\n",
      "Epoch 1072/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.8573 - val_loss: 22.2460\n",
      "Epoch 1073/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.1668 - val_loss: 43.7766\n",
      "Epoch 1074/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 48.2088 - val_loss: 47.0310\n",
      "Epoch 1075/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 51.7952 - val_loss: 77.0324\n",
      "Epoch 1076/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.9018 - val_loss: 17.9698\n",
      "Epoch 1077/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.7258 - val_loss: 64.6352\n",
      "Epoch 1078/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.3494 - val_loss: 26.8317\n",
      "Epoch 1079/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.7295 - val_loss: 51.3760\n",
      "Epoch 1080/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.8463 - val_loss: 84.9968\n",
      "Epoch 1081/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 48.3232 - val_loss: 46.4425\n",
      "Epoch 1082/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.8739 - val_loss: 18.1982\n",
      "Epoch 1083/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.8533 - val_loss: 103.7577\n",
      "Epoch 1084/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.3443 - val_loss: 41.9740\n",
      "Epoch 1085/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.3648 - val_loss: 31.4654\n",
      "Epoch 1086/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.6575 - val_loss: 28.5509\n",
      "Epoch 1087/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.1553 - val_loss: 36.7861\n",
      "Epoch 1088/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.7256 - val_loss: 41.4003\n",
      "Epoch 1089/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.6546 - val_loss: 55.5061\n",
      "Epoch 1090/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.7496 - val_loss: 20.0374\n",
      "Epoch 1091/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.7111 - val_loss: 84.5966\n",
      "Epoch 1092/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.7819 - val_loss: 14.8092\n",
      "Epoch 1093/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 53.7246 - val_loss: 30.2894\n",
      "Epoch 1094/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.7124 - val_loss: 30.3663\n",
      "Epoch 1095/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.6104 - val_loss: 89.3209\n",
      "Epoch 1096/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.3277 - val_loss: 90.6657\n",
      "Epoch 1097/1500\n",
      "136/136 [==============================] - 0s 1000us/step - loss: 46.7885 - val_loss: 38.7043\n",
      "Epoch 1098/1500\n",
      "136/136 [==============================] - 0s 993us/step - loss: 48.3668 - val_loss: 82.1065\n",
      "Epoch 1099/1500\n",
      "136/136 [==============================] - 0s 978us/step - loss: 47.9409 - val_loss: 22.1961\n",
      "Epoch 1100/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.8985 - val_loss: 32.3725\n",
      "Epoch 1101/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.3774 - val_loss: 49.8714\n",
      "Epoch 1102/1500\n",
      "136/136 [==============================] - 0s 985us/step - loss: 48.7421 - val_loss: 89.0287\n",
      "Epoch 1103/1500\n",
      "136/136 [==============================] - 0s 985us/step - loss: 49.6228 - val_loss: 44.5080\n",
      "Epoch 1104/1500\n",
      "136/136 [==============================] - 0s 934us/step - loss: 47.3548 - val_loss: 29.0394\n",
      "Epoch 1105/1500\n",
      "136/136 [==============================] - 0s 935us/step - loss: 47.0811 - val_loss: 42.0851\n",
      "Epoch 1106/1500\n",
      "136/136 [==============================] - 0s 941us/step - loss: 49.3119 - val_loss: 85.6223\n",
      "Epoch 1107/1500\n",
      "136/136 [==============================] - 0s 978us/step - loss: 47.9664 - val_loss: 26.5388\n",
      "Epoch 1108/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.8265 - val_loss: 68.7694\n",
      "Epoch 1109/1500\n",
      "136/136 [==============================] - 0s 985us/step - loss: 48.6654 - val_loss: 38.9486\n",
      "Epoch 1110/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.1596 - val_loss: 84.6131\n",
      "Epoch 1111/1500\n",
      "136/136 [==============================] - 0s 963us/step - loss: 47.9741 - val_loss: 31.9689\n",
      "Epoch 1112/1500\n",
      "136/136 [==============================] - 0s 934us/step - loss: 49.7677 - val_loss: 79.2443\n",
      "Epoch 1113/1500\n",
      "136/136 [==============================] - 0s 963us/step - loss: 49.3347 - val_loss: 29.2372\n",
      "Epoch 1114/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.1101 - val_loss: 29.2873\n",
      "Epoch 1115/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.2000 - val_loss: 33.9987\n",
      "Epoch 1116/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.1236 - val_loss: 25.5657\n",
      "Epoch 1117/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.5962 - val_loss: 96.8128\n",
      "Epoch 1118/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 51.1864 - val_loss: 23.5803\n",
      "Epoch 1119/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.3400 - val_loss: 38.0593\n",
      "Epoch 1120/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.3874 - val_loss: 48.6882\n",
      "Epoch 1121/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.6624 - val_loss: 30.8187\n",
      "Epoch 1122/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.3214 - val_loss: 33.7102\n",
      "Epoch 1123/1500\n",
      "136/136 [==============================] - 0s 1000us/step - loss: 52.0347 - val_loss: 37.1169\n",
      "Epoch 1124/1500\n",
      "136/136 [==============================] - 0s 941us/step - loss: 48.1418 - val_loss: 17.1582\n",
      "Epoch 1125/1500\n",
      "136/136 [==============================] - 0s 926us/step - loss: 48.2109 - val_loss: 46.4637\n",
      "Epoch 1126/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.3452 - val_loss: 50.7254\n",
      "Epoch 1127/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.2386 - val_loss: 44.6018\n",
      "Epoch 1128/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.2867 - val_loss: 33.1011\n",
      "Epoch 1129/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.1756 - val_loss: 24.7433\n",
      "Epoch 1130/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 47.0527 - val_loss: 33.7952\n",
      "Epoch 1131/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.1719 - val_loss: 42.3763\n",
      "Epoch 1132/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.3089 - val_loss: 59.0259\n",
      "Epoch 1133/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.5478 - val_loss: 30.0107\n",
      "Epoch 1134/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.5308 - val_loss: 54.7679\n",
      "Epoch 1135/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.5033 - val_loss: 24.2401\n",
      "Epoch 1136/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.9832 - val_loss: 58.4044\n",
      "Epoch 1137/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.5284 - val_loss: 151.6358\n",
      "Epoch 1138/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.4498 - val_loss: 55.9979\n",
      "Epoch 1139/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.7006 - val_loss: 16.7401\n",
      "Epoch 1140/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.3544 - val_loss: 69.4544\n",
      "Epoch 1141/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 47.4995 - val_loss: 18.3370\n",
      "Epoch 1142/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 44.1659 - val_loss: 56.7887\n",
      "Epoch 1143/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.3026 - val_loss: 42.9355\n",
      "Epoch 1144/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.3436 - val_loss: 23.0892\n",
      "Epoch 1145/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.1760 - val_loss: 59.2078\n",
      "Epoch 1146/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.8739 - val_loss: 36.7836\n",
      "Epoch 1147/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.1622 - val_loss: 29.7864\n",
      "Epoch 1148/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.8323 - val_loss: 32.1824\n",
      "Epoch 1149/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.2054 - val_loss: 39.9646\n",
      "Epoch 1150/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 50.2342 - val_loss: 10.2760\n",
      "Epoch 1151/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.6780 - val_loss: 18.8286\n",
      "Epoch 1152/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.7552 - val_loss: 45.9265\n",
      "Epoch 1153/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.0748 - val_loss: 42.8622\n",
      "Epoch 1154/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.7084 - val_loss: 73.8534\n",
      "Epoch 1155/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 49.7690 - val_loss: 19.7024\n",
      "Epoch 1156/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 45.2356 - val_loss: 42.1129\n",
      "Epoch 1157/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 48.7252 - val_loss: 47.3786\n",
      "Epoch 1158/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.3275 - val_loss: 40.0075\n",
      "Epoch 1159/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.7717 - val_loss: 85.8862\n",
      "Epoch 1160/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.9290 - val_loss: 40.2444\n",
      "Epoch 1161/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.6824 - val_loss: 42.8147\n",
      "Epoch 1162/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.3274 - val_loss: 16.6387\n",
      "Epoch 1163/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 48.3753 - val_loss: 23.0356\n",
      "Epoch 1164/1500\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 48.6725 - val_loss: 30.3472\n",
      "Epoch 1165/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.1907 - val_loss: 32.8021\n",
      "Epoch 1166/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.9636 - val_loss: 50.3902\n",
      "Epoch 1167/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.3864 - val_loss: 16.3437\n",
      "Epoch 1168/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.3391 - val_loss: 76.0473\n",
      "Epoch 1169/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.2856 - val_loss: 47.8075\n",
      "Epoch 1170/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.0828 - val_loss: 44.1172\n",
      "Epoch 1171/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.4273 - val_loss: 25.9784\n",
      "Epoch 1172/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.9369 - val_loss: 94.5214\n",
      "Epoch 1173/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.4037 - val_loss: 44.8539\n",
      "Epoch 1174/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.8999 - val_loss: 82.9001\n",
      "Epoch 1175/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.2313 - val_loss: 73.3442\n",
      "Epoch 1176/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.8142 - val_loss: 33.6621\n",
      "Epoch 1177/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.1657 - val_loss: 49.9743\n",
      "Epoch 1178/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.3607 - val_loss: 58.3831\n",
      "Epoch 1179/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.4478 - val_loss: 52.0759\n",
      "Epoch 1180/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.5963 - val_loss: 19.4054\n",
      "Epoch 1181/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.6180 - val_loss: 19.6255\n",
      "Epoch 1182/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.8018 - val_loss: 38.0429\n",
      "Epoch 1183/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.3811 - val_loss: 30.3758\n",
      "Epoch 1184/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.6982 - val_loss: 58.5072\n",
      "Epoch 1185/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.3474 - val_loss: 21.9377\n",
      "Epoch 1186/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.9195 - val_loss: 33.3933\n",
      "Epoch 1187/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.2076 - val_loss: 65.5475\n",
      "Epoch 1188/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.3158 - val_loss: 61.5539\n",
      "Epoch 1189/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.6953 - val_loss: 38.8962\n",
      "Epoch 1190/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.3847 - val_loss: 36.6556\n",
      "Epoch 1191/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.9704 - val_loss: 18.4925\n",
      "Epoch 1192/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.6416 - val_loss: 16.4228\n",
      "Epoch 1193/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.2568 - val_loss: 62.5878\n",
      "Epoch 1194/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.5159 - val_loss: 72.1190\n",
      "Epoch 1195/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.7891 - val_loss: 26.7216\n",
      "Epoch 1196/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.8925 - val_loss: 23.4654\n",
      "Epoch 1197/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.6161 - val_loss: 20.9300\n",
      "Epoch 1198/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.3591 - val_loss: 39.1111\n",
      "Epoch 1199/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.4687 - val_loss: 76.2577\n",
      "Epoch 1200/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.9315 - val_loss: 26.1217\n",
      "Epoch 1201/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.1229 - val_loss: 29.3350\n",
      "Epoch 1202/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.3489 - val_loss: 23.3847\n",
      "Epoch 1203/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.2202 - val_loss: 21.7718\n",
      "Epoch 1204/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.0440 - val_loss: 56.6203\n",
      "Epoch 1205/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.6316 - val_loss: 29.4680\n",
      "Epoch 1206/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.1398 - val_loss: 29.7183\n",
      "Epoch 1207/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.0624 - val_loss: 16.8280\n",
      "Epoch 1208/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.7891 - val_loss: 37.6744\n",
      "Epoch 1209/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.4632 - val_loss: 45.0543\n",
      "Epoch 1210/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.9423 - val_loss: 20.6901\n",
      "Epoch 1211/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.1097 - val_loss: 105.8571\n",
      "Epoch 1212/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.4288 - val_loss: 54.0655\n",
      "Epoch 1213/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.7447 - val_loss: 84.4831\n",
      "Epoch 1214/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.7815 - val_loss: 30.8858\n",
      "Epoch 1215/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.0005 - val_loss: 33.4479\n",
      "Epoch 1216/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.5313 - val_loss: 59.4286\n",
      "Epoch 1217/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.1095 - val_loss: 45.9302\n",
      "Epoch 1218/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.7569 - val_loss: 20.4570\n",
      "Epoch 1219/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.3437 - val_loss: 68.1551\n",
      "Epoch 1220/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.8090 - val_loss: 64.1331\n",
      "Epoch 1221/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.9437 - val_loss: 71.3879\n",
      "Epoch 1222/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.5261 - val_loss: 23.5661\n",
      "Epoch 1223/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.5190 - val_loss: 95.6168\n",
      "Epoch 1224/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.4578 - val_loss: 46.9808\n",
      "Epoch 1225/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.0581 - val_loss: 103.3599\n",
      "Epoch 1226/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 51.4541 - val_loss: 29.3889\n",
      "Epoch 1227/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.8117 - val_loss: 65.0968\n",
      "Epoch 1228/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.9654 - val_loss: 35.5070\n",
      "Epoch 1229/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.1736 - val_loss: 60.9302\n",
      "Epoch 1230/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.7688 - val_loss: 26.4333\n",
      "Epoch 1231/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.4313 - val_loss: 20.3884\n",
      "Epoch 1232/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.7261 - val_loss: 52.7563\n",
      "Epoch 1233/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.4295 - val_loss: 54.1549\n",
      "Epoch 1234/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.6668 - val_loss: 27.4012\n",
      "Epoch 1235/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.4156 - val_loss: 16.2916\n",
      "Epoch 1236/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.9069 - val_loss: 37.9798\n",
      "Epoch 1237/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.9674 - val_loss: 77.9107\n",
      "Epoch 1238/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.4597 - val_loss: 54.2094\n",
      "Epoch 1239/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.2718 - val_loss: 19.4555\n",
      "Epoch 1240/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.4790 - val_loss: 22.6597\n",
      "Epoch 1241/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.2122 - val_loss: 45.9956\n",
      "Epoch 1242/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.9330 - val_loss: 68.1952\n",
      "Epoch 1243/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.9294 - val_loss: 24.6688\n",
      "Epoch 1244/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.4640 - val_loss: 37.2861\n",
      "Epoch 1245/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.5696 - val_loss: 91.6615\n",
      "Epoch 1246/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.4737 - val_loss: 37.7956\n",
      "Epoch 1247/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.5044 - val_loss: 53.2760\n",
      "Epoch 1248/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.1903 - val_loss: 29.9593\n",
      "Epoch 1249/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 49.6119 - val_loss: 52.0930\n",
      "Epoch 1250/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.4582 - val_loss: 54.4035\n",
      "Epoch 1251/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.1263 - val_loss: 21.8642\n",
      "Epoch 1252/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.5643 - val_loss: 29.5889\n",
      "Epoch 1253/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.7817 - val_loss: 49.1421\n",
      "Epoch 1254/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.0077 - val_loss: 62.1876\n",
      "Epoch 1255/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.5581 - val_loss: 39.9877\n",
      "Epoch 1256/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.1062 - val_loss: 31.1128\n",
      "Epoch 1257/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.2178 - val_loss: 37.9230\n",
      "Epoch 1258/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.5974 - val_loss: 50.5290\n",
      "Epoch 1259/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.3220 - val_loss: 21.2501\n",
      "Epoch 1260/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.1997 - val_loss: 98.4749\n",
      "Epoch 1261/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 50.5743 - val_loss: 41.8824\n",
      "Epoch 1262/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.5234 - val_loss: 16.8924\n",
      "Epoch 1263/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.2874 - val_loss: 34.2742\n",
      "Epoch 1264/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.0281 - val_loss: 25.6007\n",
      "Epoch 1265/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.0325 - val_loss: 50.8109\n",
      "Epoch 1266/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.1177 - val_loss: 71.5232\n",
      "Epoch 1267/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.0537 - val_loss: 54.8839\n",
      "Epoch 1268/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.4695 - val_loss: 81.5897\n",
      "Epoch 1269/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.5674 - val_loss: 35.9874\n",
      "Epoch 1270/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.3656 - val_loss: 47.3793\n",
      "Epoch 1271/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.6728 - val_loss: 76.3934\n",
      "Epoch 1272/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.6440 - val_loss: 29.6025\n",
      "Epoch 1273/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.8119 - val_loss: 37.2668\n",
      "Epoch 1274/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.0707 - val_loss: 13.5439\n",
      "Epoch 1275/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.3197 - val_loss: 30.5420\n",
      "Epoch 1276/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.8738 - val_loss: 23.6716\n",
      "Epoch 1277/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.4858 - val_loss: 28.3379\n",
      "Epoch 1278/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.0422 - val_loss: 23.1607\n",
      "Epoch 1279/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.3120 - val_loss: 35.0307\n",
      "Epoch 1280/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.6164 - val_loss: 38.1384\n",
      "Epoch 1281/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.4545 - val_loss: 23.3304\n",
      "Epoch 1282/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.0662 - val_loss: 29.4981\n",
      "Epoch 1283/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.5598 - val_loss: 19.9210\n",
      "Epoch 1284/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.5113 - val_loss: 19.8690\n",
      "Epoch 1285/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.7116 - val_loss: 49.6885\n",
      "Epoch 1286/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.0344 - val_loss: 70.7162\n",
      "Epoch 1287/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.5585 - val_loss: 46.0137\n",
      "Epoch 1288/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.3167 - val_loss: 26.0084\n",
      "Epoch 1289/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.1247 - val_loss: 25.9466\n",
      "Epoch 1290/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.7611 - val_loss: 44.1574\n",
      "Epoch 1291/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.8563 - val_loss: 60.1345\n",
      "Epoch 1292/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.8796 - val_loss: 66.8341\n",
      "Epoch 1293/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.9233 - val_loss: 27.6321\n",
      "Epoch 1294/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.8964 - val_loss: 20.0608\n",
      "Epoch 1295/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.0218 - val_loss: 73.1429\n",
      "Epoch 1296/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.4962 - val_loss: 29.4070\n",
      "Epoch 1297/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.7568 - val_loss: 46.9640\n",
      "Epoch 1298/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.6167 - val_loss: 51.1531\n",
      "Epoch 1299/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.9670 - val_loss: 15.9947\n",
      "Epoch 1300/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.0080 - val_loss: 45.5092\n",
      "Epoch 1301/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.7129 - val_loss: 23.6457\n",
      "Epoch 1302/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 46.6373 - val_loss: 16.9778\n",
      "Epoch 1303/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.0353 - val_loss: 106.4292\n",
      "Epoch 1304/1500\n",
      "136/136 [==============================] - 0s 978us/step - loss: 45.0035 - val_loss: 35.9163\n",
      "Epoch 1305/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.5014 - val_loss: 43.3475\n",
      "Epoch 1306/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.5618 - val_loss: 30.3900\n",
      "Epoch 1307/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.8418 - val_loss: 68.4000\n",
      "Epoch 1308/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.8031 - val_loss: 39.1807\n",
      "Epoch 1309/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.7620 - val_loss: 24.8010\n",
      "Epoch 1310/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.9847 - val_loss: 20.7144\n",
      "Epoch 1311/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.6650 - val_loss: 23.1402\n",
      "Epoch 1312/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.1522 - val_loss: 54.3324\n",
      "Epoch 1313/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.2600 - val_loss: 24.7504\n",
      "Epoch 1314/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.5040 - val_loss: 19.0351\n",
      "Epoch 1315/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.7017 - val_loss: 25.2552\n",
      "Epoch 1316/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.0854 - val_loss: 42.0147\n",
      "Epoch 1317/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.8749 - val_loss: 34.7059\n",
      "Epoch 1318/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.7310 - val_loss: 62.6483\n",
      "Epoch 1319/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.6906 - val_loss: 112.9302\n",
      "Epoch 1320/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.7559 - val_loss: 34.3321\n",
      "Epoch 1321/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.8617 - val_loss: 72.9127\n",
      "Epoch 1322/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.0855 - val_loss: 13.7596\n",
      "Epoch 1323/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.7456 - val_loss: 35.5897\n",
      "Epoch 1324/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.5427 - val_loss: 27.5527\n",
      "Epoch 1325/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.6152 - val_loss: 85.9113\n",
      "Epoch 1326/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.7233 - val_loss: 104.2496\n",
      "Epoch 1327/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 47.0115 - val_loss: 50.3115\n",
      "Epoch 1328/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.9348 - val_loss: 51.4630\n",
      "Epoch 1329/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.5823 - val_loss: 53.4053\n",
      "Epoch 1330/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.6078 - val_loss: 35.4415\n",
      "Epoch 1331/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.8703 - val_loss: 30.7956\n",
      "Epoch 1332/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.0940 - val_loss: 25.1356\n",
      "Epoch 1333/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.4187 - val_loss: 20.4061\n",
      "Epoch 1334/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.6172 - val_loss: 38.6362\n",
      "Epoch 1335/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.1098 - val_loss: 23.5086\n",
      "Epoch 1336/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.8359 - val_loss: 62.6922\n",
      "Epoch 1337/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.6474 - val_loss: 26.2779\n",
      "Epoch 1338/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.3782 - val_loss: 36.3524\n",
      "Epoch 1339/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.1132 - val_loss: 52.5258\n",
      "Epoch 1340/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.1181 - val_loss: 80.6383\n",
      "Epoch 1341/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.3058 - val_loss: 40.1563\n",
      "Epoch 1342/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.1126 - val_loss: 40.9797\n",
      "Epoch 1343/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.7560 - val_loss: 29.0715\n",
      "Epoch 1344/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.4577 - val_loss: 57.2426\n",
      "Epoch 1345/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.6623 - val_loss: 16.7169\n",
      "Epoch 1346/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.1156 - val_loss: 35.4954\n",
      "Epoch 1347/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.7312 - val_loss: 31.3918\n",
      "Epoch 1348/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.5798 - val_loss: 42.3810\n",
      "Epoch 1349/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.4418 - val_loss: 28.5071\n",
      "Epoch 1350/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.6171 - val_loss: 126.2673\n",
      "Epoch 1351/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 48.1272 - val_loss: 71.9784\n",
      "Epoch 1352/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.1378 - val_loss: 68.6204\n",
      "Epoch 1353/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.7947 - val_loss: 70.2409\n",
      "Epoch 1354/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.9661 - val_loss: 24.8651\n",
      "Epoch 1355/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.4848 - val_loss: 26.9828\n",
      "Epoch 1356/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.9052 - val_loss: 23.9526\n",
      "Epoch 1357/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.9389 - val_loss: 19.1091\n",
      "Epoch 1358/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.6775 - val_loss: 47.8543\n",
      "Epoch 1359/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.4186 - val_loss: 52.7238\n",
      "Epoch 1360/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.9595 - val_loss: 33.3642\n",
      "Epoch 1361/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.1380 - val_loss: 71.0311\n",
      "Epoch 1362/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.4412 - val_loss: 45.5455\n",
      "Epoch 1363/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.4701 - val_loss: 106.9427\n",
      "Epoch 1364/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.3337 - val_loss: 30.6879\n",
      "Epoch 1365/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.7572 - val_loss: 35.5991\n",
      "Epoch 1366/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.3732 - val_loss: 34.8969\n",
      "Epoch 1367/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.4108 - val_loss: 25.9102\n",
      "Epoch 1368/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.5782 - val_loss: 38.3855\n",
      "Epoch 1369/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.4526 - val_loss: 52.9883\n",
      "Epoch 1370/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.4607 - val_loss: 41.2271\n",
      "Epoch 1371/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.7276 - val_loss: 63.4107\n",
      "Epoch 1372/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.6357 - val_loss: 38.8971\n",
      "Epoch 1373/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.2033 - val_loss: 61.2492\n",
      "Epoch 1374/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.7129 - val_loss: 21.8176\n",
      "Epoch 1375/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.3878 - val_loss: 28.3958\n",
      "Epoch 1376/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.0329 - val_loss: 19.4482\n",
      "Epoch 1377/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.8759 - val_loss: 26.8552\n",
      "Epoch 1378/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 43.2715 - val_loss: 21.8165\n",
      "Epoch 1379/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.0476 - val_loss: 61.4648\n",
      "Epoch 1380/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.4629 - val_loss: 37.7611\n",
      "Epoch 1381/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.5239 - val_loss: 32.1416\n",
      "Epoch 1382/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.2035 - val_loss: 27.9578\n",
      "Epoch 1383/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.7390 - val_loss: 19.8996\n",
      "Epoch 1384/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.8469 - val_loss: 41.4904\n",
      "Epoch 1385/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.8676 - val_loss: 72.1501\n",
      "Epoch 1386/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.3636 - val_loss: 91.1779\n",
      "Epoch 1387/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.4047 - val_loss: 13.5206\n",
      "Epoch 1388/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.1154 - val_loss: 39.5948\n",
      "Epoch 1389/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.2483 - val_loss: 47.6746\n",
      "Epoch 1390/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.0327 - val_loss: 42.2161\n",
      "Epoch 1391/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.7664 - val_loss: 42.9742\n",
      "Epoch 1392/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.4851 - val_loss: 46.0724\n",
      "Epoch 1393/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.9295 - val_loss: 27.7202\n",
      "Epoch 1394/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.4437 - val_loss: 30.5448\n",
      "Epoch 1395/1500\n",
      "136/136 [==============================] - 0s 985us/step - loss: 43.4548 - val_loss: 25.2024\n",
      "Epoch 1396/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.4907 - val_loss: 15.4555\n",
      "Epoch 1397/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.0168 - val_loss: 58.6081\n",
      "Epoch 1398/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.5521 - val_loss: 39.4278\n",
      "Epoch 1399/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.5628 - val_loss: 14.2412\n",
      "Epoch 1400/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.6064 - val_loss: 41.4684\n",
      "Epoch 1401/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.9869 - val_loss: 20.5537\n",
      "Epoch 1402/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.9460 - val_loss: 13.6221\n",
      "Epoch 1403/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.1190 - val_loss: 24.2346\n",
      "Epoch 1404/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.3356 - val_loss: 19.8182\n",
      "Epoch 1405/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 45.7816 - val_loss: 23.7557\n",
      "Epoch 1406/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.4336 - val_loss: 29.8173\n",
      "Epoch 1407/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.0380 - val_loss: 79.9329\n",
      "Epoch 1408/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.9920 - val_loss: 23.7311\n",
      "Epoch 1409/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.4688 - val_loss: 22.7607\n",
      "Epoch 1410/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.8306 - val_loss: 17.7473\n",
      "Epoch 1411/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.4549 - val_loss: 28.9686\n",
      "Epoch 1412/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.6320 - val_loss: 33.0328\n",
      "Epoch 1413/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.9832 - val_loss: 52.3085\n",
      "Epoch 1414/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.4024 - val_loss: 24.5828\n",
      "Epoch 1415/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.9900 - val_loss: 18.8330\n",
      "Epoch 1416/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.7685 - val_loss: 23.4291\n",
      "Epoch 1417/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.6614 - val_loss: 26.7479\n",
      "Epoch 1418/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.8526 - val_loss: 43.5521\n",
      "Epoch 1419/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 39.9091 - val_loss: 67.5116\n",
      "Epoch 1420/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.8909 - val_loss: 15.5494\n",
      "Epoch 1421/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.7142 - val_loss: 20.7746\n",
      "Epoch 1422/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.5080 - val_loss: 88.2366\n",
      "Epoch 1423/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.8561 - val_loss: 108.0267\n",
      "Epoch 1424/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.3665 - val_loss: 45.9327\n",
      "Epoch 1425/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 38.6217 - val_loss: 87.2698\n",
      "Epoch 1426/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 46.1021 - val_loss: 12.2462\n",
      "Epoch 1427/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.4313 - val_loss: 67.5756\n",
      "Epoch 1428/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.9628 - val_loss: 22.1951\n",
      "Epoch 1429/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.8412 - val_loss: 43.9996\n",
      "Epoch 1430/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.6037 - val_loss: 87.0401\n",
      "Epoch 1431/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.3388 - val_loss: 20.6100\n",
      "Epoch 1432/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.8812 - val_loss: 39.1058\n",
      "Epoch 1433/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.7433 - val_loss: 43.0111\n",
      "Epoch 1434/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.5338 - val_loss: 47.6357\n",
      "Epoch 1435/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.1770 - val_loss: 48.9450\n",
      "Epoch 1436/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.7584 - val_loss: 42.9315\n",
      "Epoch 1437/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.8499 - val_loss: 30.7112\n",
      "Epoch 1438/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 39.4122 - val_loss: 53.1450\n",
      "Epoch 1439/1500\n",
      "136/136 [==============================] - ETA: 0s - loss: 45.03 - 0s 1ms/step - loss: 44.4908 - val_loss: 12.4721\n",
      "Epoch 1440/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.9011 - val_loss: 18.4144\n",
      "Epoch 1441/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.7162 - val_loss: 44.6294\n",
      "Epoch 1442/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.1260 - val_loss: 27.0120\n",
      "Epoch 1443/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.9351 - val_loss: 26.2123\n",
      "Epoch 1444/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.8428 - val_loss: 54.0081\n",
      "Epoch 1445/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.7878 - val_loss: 43.9933\n",
      "Epoch 1446/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.0621 - val_loss: 34.2023\n",
      "Epoch 1447/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 39.4773 - val_loss: 21.8989\n",
      "Epoch 1448/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.6393 - val_loss: 29.7005\n",
      "Epoch 1449/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.6886 - val_loss: 29.5559\n",
      "Epoch 1450/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.8584 - val_loss: 76.5794\n",
      "Epoch 1451/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.2111 - val_loss: 93.4903\n",
      "Epoch 1452/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.5670 - val_loss: 37.2727\n",
      "Epoch 1453/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.7281 - val_loss: 60.5766\n",
      "Epoch 1454/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 42.4399 - val_loss: 70.9371\n",
      "Epoch 1455/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.8539 - val_loss: 47.8981\n",
      "Epoch 1456/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.3601 - val_loss: 21.1740\n",
      "Epoch 1457/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.4118 - val_loss: 42.4667\n",
      "Epoch 1458/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.4961 - val_loss: 28.9606\n",
      "Epoch 1459/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.1362 - val_loss: 64.3667\n",
      "Epoch 1460/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.4320 - val_loss: 50.7717\n",
      "Epoch 1461/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.7704 - val_loss: 23.8211\n",
      "Epoch 1462/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.4912 - val_loss: 20.9089\n",
      "Epoch 1463/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.6453 - val_loss: 22.4839\n",
      "Epoch 1464/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.6403 - val_loss: 56.9283\n",
      "Epoch 1465/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.9128 - val_loss: 33.7444\n",
      "Epoch 1466/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.0610 - val_loss: 24.0071\n",
      "Epoch 1467/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.7003 - val_loss: 43.4723\n",
      "Epoch 1468/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.4457 - val_loss: 15.8137\n",
      "Epoch 1469/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.1309 - val_loss: 31.6252\n",
      "Epoch 1470/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.2882 - val_loss: 34.6935\n",
      "Epoch 1471/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.5645 - val_loss: 17.8702\n",
      "Epoch 1472/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 38.9473 - val_loss: 50.1755\n",
      "Epoch 1473/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.2070 - val_loss: 24.8140\n",
      "Epoch 1474/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.7952 - val_loss: 51.3141\n",
      "Epoch 1475/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.0095 - val_loss: 20.9600\n",
      "Epoch 1476/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.6511 - val_loss: 20.2457\n",
      "Epoch 1477/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.1898 - val_loss: 29.0991\n",
      "Epoch 1478/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.2513 - val_loss: 33.4830\n",
      "Epoch 1479/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.8620 - val_loss: 65.1458\n",
      "Epoch 1480/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.9946 - val_loss: 21.0798\n",
      "Epoch 1481/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.7671 - val_loss: 20.0947\n",
      "Epoch 1482/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.0609 - val_loss: 19.7873\n",
      "Epoch 1483/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.0600 - val_loss: 24.8091\n",
      "Epoch 1484/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.8991 - val_loss: 13.2266\n",
      "Epoch 1485/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.7453 - val_loss: 22.8301\n",
      "Epoch 1486/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.5601 - val_loss: 44.4255\n",
      "Epoch 1487/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.9531 - val_loss: 63.2117\n",
      "Epoch 1488/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.6974 - val_loss: 26.2427\n",
      "Epoch 1489/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 44.2003 - val_loss: 33.8129\n",
      "Epoch 1490/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 40.3602 - val_loss: 37.5475\n",
      "Epoch 1491/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 39.1779 - val_loss: 37.9524\n",
      "Epoch 1492/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.2997 - val_loss: 61.9320\n",
      "Epoch 1493/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.5128 - val_loss: 24.5212\n",
      "Epoch 1494/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.2099 - val_loss: 32.5368\n",
      "Epoch 1495/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.2158 - val_loss: 66.1568\n",
      "Epoch 1496/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 41.6512 - val_loss: 39.1142\n",
      "Epoch 1497/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.0769 - val_loss: 34.1424\n",
      "Epoch 1498/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.2409 - val_loss: 61.1119\n",
      "Epoch 1499/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 42.3743 - val_loss: 46.7368\n",
      "Epoch 1500/1500\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 43.7937 - val_loss: 63.9855\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train,\n",
    "          batch_size=2, epochs=1500,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"Interpolation/QLYS/modeldenQLYS.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"Interpolation/QLYS/modeldenQLYS.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "arr = []\n",
    "for x in range(len(X_scale)):\n",
    "    Xnew = array([[X_scale[x][0], X_scale[x][1] , X_scale[x][2], X_scale[x][3], X_scale[x][4], X_scale[x][5]]])\n",
    "    ynew = model.predict(Xnew)\n",
    "    #print(ynew[0][0])\n",
    "    arr.append(ynew[0][0])\n",
    "array = np.array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.990577894314551"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(Y.tolist(), array.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "myText = open(r'C:\\Users\\alejo\\Documents\\Proyecto_Integrador_2\\AI_Value\\Combination\\Interpolation\\QLYS\\QLYS_R2ScoreDen.txt','w')\n",
    "myString = str(r2_score(Y.tolist(), array.tolist()))\n",
    "myText.write(myString)\n",
    "myText.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('tf': conda)",
   "language": "python",
   "name": "python37764bittfconda6cc65eca183d4342a640aa08d3d7781d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
